#!/usr/bin/env python3
"""
ì›ê²© ì„œë²„ ì–¼êµ´ í’ˆì§ˆ ê²€ì¦ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
- ì„œë²„ IPì™€ í¬íŠ¸ë¥¼ ëª…ë ¹ì¤„ ì¸ìë¡œ ì…ë ¥ ê°€ëŠ¥
- ë‹¤ì–‘í•œ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ì§€ì›
- ì‹¤ì‹œê°„ ì›¹ìº  í…ŒìŠ¤íŠ¸
- ë°°ì¹˜ í…ŒìŠ¤íŠ¸
- ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
"""
import requests
import json
import base64
import os
import cv2
import numpy as np
import time
from datetime import datetime
from typing import Dict, List, Tuple, Optional
import argparse
import matplotlib.pyplot as plt
from concurrent.futures import ThreadPoolExecutor, as_completed
import sys

class FaceQualityTester:
    def __init__(self, host: str = "localhost", port: int = 5002):
        """
        Args:
            host: ì„œë²„ í˜¸ìŠ¤íŠ¸ ì£¼ì†Œ (IP ë˜ëŠ” ë„ë©”ì¸)
            port: ì„œë²„ í¬íŠ¸ ë²ˆí˜¸
        """
        self.api_base_url = f"http://{host}:{port}"
        self.test_results = []
        print(f"ğŸŒ API ì„œë²„: {self.api_base_url}")
        
    def encode_image(self, image_path: str) -> str:
        """ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©"""
        with open(image_path, 'rb') as f:
            image_data = base64.b64encode(f.read()).decode()
        return f"data:image/jpeg;base64,{image_data}"
    
    def encode_cv2_image(self, image: np.ndarray) -> str:
        """OpenCV ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©"""
        _, buffer = cv2.imencode('.jpg', image)
        image_data = base64.b64encode(buffer).decode()
        return f"data:image/jpeg;base64,{image_data}"
    
    def test_connection(self) -> bool:
        """ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            print(f"\nğŸ” ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸ ì¤‘: {self.api_base_url}")
            # ê°„ë‹¨í•œ GET ìš”ì²­ìœ¼ë¡œ ì„œë²„ í™•ì¸ (404ì—¬ë„ ì—°ê²°ì€ ëœ ê²ƒ)
            response = requests.get(f"{self.api_base_url}/", timeout=5)
            print(f"âœ… ì„œë²„ ì—°ê²° ì„±ê³µ! (ìƒíƒœ ì½”ë“œ: {response.status_code})")
            return True
        except requests.exceptions.ConnectionError:
            print(f"âŒ ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.api_base_url}")
            print("   ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€, IPì™€ í¬íŠ¸ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
            return False
        except requests.exceptions.Timeout:
            print(f"â±ï¸  ì„œë²„ ì‘ë‹µ ì‹œê°„ ì´ˆê³¼: {self.api_base_url}")
            return False
        except Exception as e:
            print(f"âŒ ì—°ê²° ì˜¤ë¥˜: {str(e)}")
            return False
    
    def test_single_image(self, image_path: str, description: str = "") -> Dict:
        """ë‹¨ì¼ ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸"""
        try:
            # ì´ë¯¸ì§€ ì¸ì½”ë”©
            image_data = self.encode_image(image_path)
            
            # API í˜¸ì¶œ
            start_time = time.time()
            response = requests.post(
                f"{self.api_base_url}/api/face/detect_for_registration",
                json={"image": image_data},
                headers={"Content-Type": "application/json"},
                timeout=10
            )
            elapsed_time = (time.time() - start_time) * 1000  # ms
            
            result = response.json()
            result['actual_processing_time_ms'] = elapsed_time
            result['image_path'] = image_path
            result['description'] = description
            
            return result
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'image_path': image_path,
                'description': description
            }
    
    def test_realtime_webcam(self):
        """ì‹¤ì‹œê°„ ì›¹ìº  í…ŒìŠ¤íŠ¸"""
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            print("âŒ ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print("\nì‹¤ì‹œê°„ ì›¹ìº  í…ŒìŠ¤íŠ¸ ëª¨ë“œ")
        print("- 'q': ì¢…ë£Œ")
        print("- 's': í˜„ì¬ í”„ë ˆì„ ì €ì¥ ë° í…ŒìŠ¤íŠ¸")
        print("- 'c': ì—°ì† í…ŒìŠ¤íŠ¸ ëª¨ë“œ í† ê¸€")
        
        continuous_mode = False
        frame_count = 0
        fps_start_time = time.time()
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            display_frame = frame.copy()
            h, w = frame.shape[:2]
            
            # ê°€ì´ë“œë¼ì¸ ê·¸ë¦¬ê¸°
            guide_color = (0, 255, 0)
            cv2.rectangle(display_frame, (w//4, h//6), (3*w//4, 5*h//6), guide_color, 2)
            
            # FPS ê³„ì‚° ë° í‘œì‹œ
            frame_count += 1
            if frame_count % 30 == 0:
                fps = 30 / (time.time() - fps_start_time)
                fps_start_time = time.time()
                
            # ì—°ì† ëª¨ë“œì—ì„œ ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸
            if continuous_mode and frame_count % 15 == 0:  # 0.5ì´ˆë§ˆë‹¤
                try:
                    image_data = self.encode_cv2_image(frame)
                    response = requests.post(
                        f"{self.api_base_url}/api/face/detect_for_registration",
                        json={"image": image_data},
                        headers={"Content-Type": "application/json"},
                        timeout=2
                    )
                    result = response.json()
                    
                    # ê²°ê³¼ í‘œì‹œ
                    if result.get('success'):
                        suitable = result.get('suitable_for_registration', False)
                        color = (0, 255, 0) if suitable else (0, 0, 255)
                        status = "ì í•©" if suitable else "ë¶€ì í•©"
                        
                        cv2.putText(display_frame, f"ë“±ë¡ {status}", (10, 30),
                                  cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)
                        
                        if 'quality_details' in result:
                            quality = result['quality_details']
                            cv2.putText(display_frame, f"í’ˆì§ˆ: {quality.get('overall_quality_score', 0):.2f}", 
                                      (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
                        
                        if 'face_pose' in result:
                            pose = result['face_pose']
                            cv2.putText(display_frame, f"Yaw: {pose['yaw']:.1f}", 
                                      (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                            cv2.putText(display_frame, f"Pitch: {pose['pitch']:.1f}", 
                                      (10, 110), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                            cv2.putText(display_frame, f"Roll: {pose['roll']:.1f}", 
                                      (10, 130), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                        
                except Exception as e:
                    cv2.putText(display_frame, f"Error: {str(e)[:30]}", (10, 30),
                              cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            
            # ëª¨ë“œ í‘œì‹œ
            if continuous_mode:
                cv2.putText(display_frame, "ì—°ì† í…ŒìŠ¤íŠ¸ ëª¨ë“œ", (w-200, 30),
                          cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
            
            # ì„œë²„ ì •ë³´ í‘œì‹œ
            server_info = f"Server: {self.api_base_url}"
            cv2.putText(display_frame, server_info, (10, h-10),
                      cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
            
            cv2.imshow('ì‹¤ì‹œê°„ ì–¼êµ´ í’ˆì§ˆ í…ŒìŠ¤íŠ¸', display_frame)
            
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
            elif key == ord('s'):
                # í˜„ì¬ í”„ë ˆì„ ì €ì¥ ë° í…ŒìŠ¤íŠ¸
                filename = f"test_images/realtime_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jpg"
                os.makedirs("test_images", exist_ok=True)
                cv2.imwrite(filename, frame)
                print(f"\nâœ… ì´ë¯¸ì§€ ì €ì¥: {filename}")
                
                result = self.test_single_image(filename, "ì‹¤ì‹œê°„ ìº¡ì²˜")
                self.print_test_result(result)
                
            elif key == ord('c'):
                continuous_mode = not continuous_mode
                print(f"\nì—°ì† í…ŒìŠ¤íŠ¸ ëª¨ë“œ: {'ON' if continuous_mode else 'OFF'}")
        
        cap.release()
        cv2.destroyAllWindows()
    
    def test_batch_images(self, image_folder: str, max_images: int = 50):
        """í´ë” ë‚´ ëª¨ë“  ì´ë¯¸ì§€ ë°°ì¹˜ í…ŒìŠ¤íŠ¸"""
        if not os.path.exists(image_folder):
            print(f"âŒ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_folder}")
            return
        
        # ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°
        image_files = []
        for ext in ['.jpg', '.jpeg', '.png', '.bmp']:
            image_files.extend([f for f in os.listdir(image_folder) 
                              if f.lower().endswith(ext)])
        
        if not image_files:
            print(f"âŒ {image_folder}ì— ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        image_files = image_files[:max_images]
        print(f"\në°°ì¹˜ í…ŒìŠ¤íŠ¸: {len(image_files)}ê°œ ì´ë¯¸ì§€")
        
        # ë©€í‹°ìŠ¤ë ˆë“œë¡œ ë³‘ë ¬ ì²˜ë¦¬
        results = []
        with ThreadPoolExecutor(max_workers=5) as executor:
            future_to_image = {
                executor.submit(self.test_single_image, 
                              os.path.join(image_folder, img), img): img 
                for img in image_files
            }
            
            for future in as_completed(future_to_image):
                image_name = future_to_image[future]
                try:
                    result = future.result()
                    results.append(result)
                    
                    # ì§„í–‰ ìƒí™© í‘œì‹œ
                    status = "âœ…" if result.get('suitable_for_registration', False) else "âŒ"
                    print(f"{status} {image_name}")
                    
                except Exception as e:
                    print(f"âŒ {image_name}: {str(e)}")
        
        # ê²°ê³¼ ë¶„ì„
        self.analyze_batch_results(results)
        return results
    
    def analyze_batch_results(self, results: List[Dict]):
        """ë°°ì¹˜ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„"""
        if not results:
            return
        
        print("\n" + "="*60)
        print("ë°°ì¹˜ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„")
        print("="*60)
        
        # ê¸°ë³¸ í†µê³„
        total = len(results)
        successful = sum(1 for r in results if r.get('success', False))
        suitable = sum(1 for r in results if r.get('suitable_for_registration', False))
        
        print(f"ì´ ì´ë¯¸ì§€: {total}ê°œ")
        print(f"ê²€ì¶œ ì„±ê³µ: {successful}ê°œ ({successful/total*100:.1f}%)")
        print(f"ë“±ë¡ ì í•©: {suitable}ê°œ ({suitable/total*100:.1f}%)")
        
        # í’ˆì§ˆ ì ìˆ˜ í†µê³„
        quality_scores = [r.get('quality_score', 0) for r in results if r.get('success')]
        if quality_scores:
            print(f"\ní’ˆì§ˆ ì ìˆ˜:")
            print(f"  - í‰ê· : {np.mean(quality_scores):.2f}")
            print(f"  - ìµœì†Œ: {np.min(quality_scores):.2f}")
            print(f"  - ìµœëŒ€: {np.max(quality_scores):.2f}")
            print(f"  - í‘œì¤€í¸ì°¨: {np.std(quality_scores):.2f}")
        
        # ì²˜ë¦¬ ì‹œê°„ í†µê³„
        processing_times = [r.get('actual_processing_time_ms', 0) for r in results if r.get('success')]
        if processing_times:
            print(f"\nì²˜ë¦¬ ì‹œê°„ (ms):")
            print(f"  - í‰ê· : {np.mean(processing_times):.0f}")
            print(f"  - ìµœì†Œ: {np.min(processing_times):.0f}")
            print(f"  - ìµœëŒ€: {np.max(processing_times):.0f}")
        
        # ì‹¤íŒ¨ ì›ì¸ ë¶„ì„
        print(f"\nì£¼ìš” ê¶Œì¥ì‚¬í•­:")
        recommendations = {}
        for r in results:
            if r.get('recommendations'):
                for rec in r['recommendations']:
                    recommendations[rec] = recommendations.get(rec, 0) + 1
        
        for rec, count in sorted(recommendations.items(), key=lambda x: x[1], reverse=True)[:5]:
            print(f"  - {rec}: {count}íšŒ")
    
    def print_test_result(self, result: Dict):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì¶œë ¥"""
        print(f"\n{'='*60}")
        print(f"í…ŒìŠ¤íŠ¸: {result.get('description', 'N/A')}")
        print(f"ì´ë¯¸ì§€: {result.get('image_path', 'N/A')}")
        print(f"ì„œë²„: {self.api_base_url}")
        print(f"{'='*60}")
        
        print(f"\nìƒíƒœ ì½”ë“œ: {'200' if result.get('success') else '400'}")
        print(f"ì„±ê³µ ì—¬ë¶€: {result.get('success', False)}")
        print(f"ì–¼êµ´ ê°ì§€: {result.get('face_detected', False)}")
        print(f"ë“±ë¡ ì í•©ì„±: {result.get('suitable_for_registration', False)}")
        
        # ì–¼êµ´ í¬ì¦ˆ ì •ë³´
        if 'face_pose' in result:
            pose = result['face_pose']
            print(f"\n[ì–¼êµ´ ê°ë„]")
            print(f"  - Yaw (ì¢Œìš°): {pose['yaw']:.1f}ë„")
            print(f"  - Pitch (ìƒí•˜): {pose['pitch']:.1f}ë„")
            print(f"  - Roll (ê¸°ìš¸ê¸°): {pose['roll']:.1f}ë„")
            print(f"  - ì •ë©´ ì—¬ë¶€: {pose['is_frontal']}")
        
        # í’ˆì§ˆ ìƒì„¸ ì •ë³´
        if 'quality_details' in result:
            quality = result['quality_details']
            print(f"\n[í’ˆì§ˆ ì •ë³´]")
            print(f"  - ì–¼êµ´ í¬ê¸° ë¹„ìœ¨: {quality['face_size_ratio']:.2%}")
            print(f"  - ì¤‘ì•™ ìœ„ì¹˜: {quality['face_centered']}")
            print(f"  - ê²€ì¶œ ì‹ ë¢°ë„: {quality['detection_confidence']:.2f}")
            print(f"  - ì „ì²´ í’ˆì§ˆ ì ìˆ˜: {quality['overall_quality_score']:.2f}")
        
        # ê¶Œì¥ì‚¬í•­
        if result.get('recommendations'):
            print(f"\n[ê°œì„  ê¶Œì¥ì‚¬í•­]")
            for i, rec in enumerate(result['recommendations'], 1):
                print(f"  {i}. {rec}")
        else:
            print(f"\nâœ… ë“±ë¡ì— ì í•©í•œ ì´ë¯¸ì§€ì…ë‹ˆë‹¤!")
        
        # ì²˜ë¦¬ ì‹œê°„
        if 'actual_processing_time_ms' in result:
            print(f"\n[ì²˜ë¦¬ ì‹œê°„]")
            print(f"  - ì „ì²´: {result['actual_processing_time_ms']:.0f}ms")
            print(f"  - API: {result.get('processing_time_ms', 0):.0f}ms")
    
    def benchmark_performance(self, test_image: str, iterations: int = 100):
        """ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸"""
        if not os.path.exists(test_image):
            print(f"âŒ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {test_image}")
            return
        
        print(f"\nì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸")
        print(f"ì„œë²„: {self.api_base_url}")
        print(f"ì´ë¯¸ì§€: {test_image}")
        print(f"ë°˜ë³µ íšŸìˆ˜: {iterations}")
        print("-" * 60)
        
        # ì´ë¯¸ì§€ ë¯¸ë¦¬ ì¸ì½”ë”©
        image_data = self.encode_image(test_image)
        
        response_times = []
        errors = 0
        
        # ì›Œë°ì—…
        print("ì›Œë°ì—… ì¤‘...")
        for _ in range(5):
            try:
                requests.post(
                    f"{self.api_base_url}/api/face/detect_for_registration",
                    json={"image": image_data},
                    headers={"Content-Type": "application/json"},
                    timeout=10
                )
            except:
                pass
        
        # ì‹¤ì œ í…ŒìŠ¤íŠ¸
        print("ë²¤ì¹˜ë§ˆí¬ ì‹œì‘...")
        start_time = time.time()
        
        for i in range(iterations):
            try:
                req_start = time.time()
                response = requests.post(
                    f"{self.api_base_url}/api/face/detect_for_registration",
                    json={"image": image_data},
                    headers={"Content-Type": "application/json"},
                    timeout=10
                )
                req_time = (time.time() - req_start) * 1000  # ms
                
                if response.status_code == 200:
                    response_times.append(req_time)
                else:
                    errors += 1
                
                # ì§„í–‰ í‘œì‹œ
                if (i + 1) % 10 == 0:
                    print(f"  ì§„í–‰: {i + 1}/{iterations} ({(i + 1)/iterations*100:.0f}%)")
                    
            except Exception as e:
                errors += 1
                print(f"  ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        
        total_time = time.time() - start_time
        
        # ê²°ê³¼ ë¶„ì„
        print(f"\n{'='*60}")
        print("ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼")
        print(f"ì„œë²„: {self.api_base_url}")
        print(f"{'='*60}")
        
        if response_times:
            print(f"ì´ ì‹œê°„: {total_time:.2f}ì´ˆ")
            print(f"ì„±ê³µ: {len(response_times)}íšŒ")
            print(f"ì‹¤íŒ¨: {errors}íšŒ")
            print(f"ì²˜ë¦¬ëŸ‰: {len(response_times)/total_time:.1f} req/s")
            
            print(f"\nì‘ë‹µ ì‹œê°„ (ms):")
            print(f"  - í‰ê· : {np.mean(response_times):.1f}")
            print(f"  - ì¤‘ì•™ê°’: {np.median(response_times):.1f}")
            print(f"  - ìµœì†Œ: {np.min(response_times):.1f}")
            print(f"  - ìµœëŒ€: {np.max(response_times):.1f}")
            print(f"  - í‘œì¤€í¸ì°¨: {np.std(response_times):.1f}")
            print(f"  - 95 ë°±ë¶„ìœ„: {np.percentile(response_times, 95):.1f}")
            print(f"  - 99 ë°±ë¶„ìœ„: {np.percentile(response_times, 99):.1f}")
            
            # íˆìŠ¤í† ê·¸ë¨ ìƒì„±
            plt.figure(figsize=(10, 6))
            plt.hist(response_times, bins=50, alpha=0.7, color='blue', edgecolor='black')
            plt.axvline(np.mean(response_times), color='red', linestyle='dashed', linewidth=2, label=f'í‰ê· : {np.mean(response_times):.1f}ms')
            plt.axvline(np.median(response_times), color='green', linestyle='dashed', linewidth=2, label=f'ì¤‘ì•™ê°’: {np.median(response_times):.1f}ms')
            plt.xlabel('ì‘ë‹µ ì‹œê°„ (ms)')
            plt.ylabel('ë¹ˆë„')
            plt.title(f'API ì‘ë‹µ ì‹œê°„ ë¶„í¬\nì„œë²„: {self.api_base_url}')
            plt.legend()
            plt.grid(True, alpha=0.3)
            
            # ê·¸ë˜í”„ ì €ì¥
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f'benchmark_results_{timestamp}.png'
            plt.savefig(filename, dpi=300, bbox_inches='tight')
            print(f"\nğŸ“Š íˆìŠ¤í† ê·¸ë¨ ì €ì¥: {filename}")
            plt.close()

def main():
    parser = argparse.ArgumentParser(description='ì›ê²© ì„œë²„ ì–¼êµ´ í’ˆì§ˆ ê²€ì¦ í…ŒìŠ¤íŠ¸')
    
    # ì„œë²„ ì—°ê²° ì˜µì…˜
    parser.add_argument('--host', type=str, default='localhost', 
                       help='ì„œë²„ í˜¸ìŠ¤íŠ¸ ì£¼ì†Œ (IP ë˜ëŠ” ë„ë©”ì¸, ê¸°ë³¸ê°’: localhost)')
    parser.add_argument('--port', type=int, default=5002, 
                       help='ì„œë²„ í¬íŠ¸ ë²ˆí˜¸ (ê¸°ë³¸ê°’: 5002)')
    parser.add_argument('--server', type=str, 
                       help='ì„œë²„ ì£¼ì†Œ (ì˜ˆ: 192.168.0.48:5002)')
    
    # í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì˜µì…˜
    parser.add_argument('--mode', choices=['single', 'batch', 'realtime', 'benchmark'], 
                       default='single', help='í…ŒìŠ¤íŠ¸ ëª¨ë“œ')
    parser.add_argument('--image', type=str, help='í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ ê²½ë¡œ')
    parser.add_argument('--folder', type=str, default='test_images', 
                       help='ë°°ì¹˜ í…ŒìŠ¤íŠ¸ í´ë”')
    parser.add_argument('--iterations', type=int, default=100, 
                       help='ë²¤ì¹˜ë§ˆí¬ ë°˜ë³µ íšŸìˆ˜')
    
    args = parser.parse_args()
    
    # ì„œë²„ ì£¼ì†Œ íŒŒì‹±
    if args.server:
        # --server ì˜µì…˜ì´ ìˆìœ¼ë©´ ì´ë¥¼ ìš°ì„  ì‚¬ìš©
        if ':' in args.server:
            host, port = args.server.split(':')
            args.host = host
            args.port = int(port)
        else:
            args.host = args.server
    
    # í…ŒìŠ¤í„° ì´ˆê¸°í™”
    tester = FaceQualityTester(args.host, args.port)
    
    print("="*60)
    print("ì›ê²© ì„œë²„ ì–¼êµ´ í’ˆì§ˆ ê²€ì¦ í…ŒìŠ¤íŠ¸")
    print(f"ì„œë²„ ì£¼ì†Œ: {args.host}:{args.port}")
    print(f"í…ŒìŠ¤íŠ¸ ëª¨ë“œ: {args.mode}")
    print("="*60)
    
    # ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸
    if not tester.test_connection():
        print("\nâš ï¸  ì„œë²„ ì—°ê²° ì‹¤íŒ¨. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        print("\nì‚¬ìš© ì˜ˆì‹œ:")
        print("  python test_face_remote.py --host 192.168.0.48 --port 5002")
        print("  python test_face_remote.py --server 192.168.0.48:5002")
        print("  python test_face_remote.py --host localhost --mode single --image test.jpg")
        return
    
    # í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì‹¤í–‰
    if args.mode == 'single':
        if args.image:
            result = tester.test_single_image(args.image, "ì‚¬ìš©ì ì§€ì • ì´ë¯¸ì§€")
            tester.print_test_result(result)
        else:
            print("\nâŒ --image ì˜µì…˜ìœ¼ë¡œ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì§€ì •í•˜ì„¸ìš”.")
            print("ì˜ˆì‹œ: python test_face_remote.py --mode single --image test.jpg")
            
    elif args.mode == 'batch':
        tester.test_batch_images(args.folder)
        
    elif args.mode == 'realtime':
        tester.test_realtime_webcam()
        
    elif args.mode == 'benchmark':
        if args.image:
            tester.benchmark_performance(args.image, args.iterations)
        else:
            # ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì‚¬ìš©
            test_images = ['test_images/frontal_face.jpg', 'test.jpg', 'sample.jpg']
            for img in test_images:
                if os.path.exists(img):
                    tester.benchmark_performance(img, args.iterations)
                    break
            else:
                print("âŒ ë²¤ì¹˜ë§ˆí¬í•  ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                print("--image ì˜µì…˜ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
                print("ì˜ˆì‹œ: python test_face_remote.py --mode benchmark --image test.jpg")

if __name__ == "__main__":
    main()