#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
InsightFace ê¸°ë°˜ ì–¼êµ´ ì¸ì‹ ì„œë¹„ìŠ¤
SPOQ Plusë¥¼ ìœ„í•œ ê³ ì„±ëŠ¥ ì–¼êµ´ ì¸ì‹ êµ¬í˜„
"""

import os
import sys
import json
import base64
import numpy as np
from datetime import datetime
import logging
from typing import Dict, List, Tuple, Optional
import time
import secrets
import string

# InsightFace
import insightface
from insightface.app import FaceAnalysis

# ì´ë¯¸ì§€ ì²˜ë¦¬
import cv2
from PIL import Image
import io

# ì›¹ ì„œë²„
from flask import Flask, request, jsonify, render_template_string, abort
from flask_cors import CORS
import numpy as np
from functools import wraps
import ipaddress

# í™˜ê²½ ë³€ìˆ˜
from dotenv import load_dotenv

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('insightface_service.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ë°ì´í„°ë² ì´ìŠ¤ ëª¨ë“ˆ ì„í¬íŠ¸
import mysql.connector
from mysql.connector import pooling

# MSSQL ì§€ì›ì„ ìœ„í•œ pyodbc ì„í¬íŠ¸ (ì„ íƒì‚¬í•­)
try:
    import pyodbc
except ImportError:
    pyodbc = None
    logger.warning("pyodbc not installed. MSSQL support disabled.")

# ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ë¡œë“œ
DB_TYPE = None
DB_CONFIG = None

try:
    from config import Config
    config = Config()
    DB_TYPE = config.DB_TYPE
    DB_CONFIG = config.DB_CONFIG
    logger.info(f"config.pyì—ì„œ {DB_TYPE.upper()} ì„¤ì • ë¡œë“œ ì„±ê³µ")
except ImportError:
    # config.pyê°€ ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ì§ì ‘ ë¡œë“œ
    load_dotenv()  # .env íŒŒì¼ ìë™ íƒìƒ‰
    DB_TYPE = os.getenv('DB_TYPE', 'mariadb').lower()
    
    if DB_TYPE == 'mssql':
        DB_CONFIG = {
            'server': os.getenv('MSSQL_SERVER', 'localhost'),
            'database': os.getenv('MSSQL_DATABASE', 'spoqplus'),
            'username': os.getenv('MSSQL_USERNAME', 'sa'),
            'password': os.getenv('MSSQL_PASSWORD', ''),
            'driver': os.getenv('MSSQL_DRIVER', 'ODBC Driver 17 for SQL Server'),
            'port': int(os.getenv('MSSQL_PORT', '1433')),
            'timeout': int(os.getenv('MSSQL_TIMEOUT', '10')),
            'encrypt': os.getenv('MSSQL_ENCRYPT', 'yes'),
            'trust_server_certificate': os.getenv('MSSQL_TRUST_CERT', 'yes')
        }
    else:
        DB_CONFIG = {
            'host': os.getenv('DB_HOST', 'localhost'),
            'user': os.getenv('DB_USER', 'root'),
            'password': os.getenv('DB_PASSWORD', ''),
            'database': os.getenv('DB_NAME', 'spoqplus'),
            'charset': 'utf8mb4',
            'collation': 'utf8mb4_unicode_ci',
            'autocommit': True,
            'connection_timeout': 10
        }

# HTML í…ŒìŠ¤íŠ¸ ì¸í„°í˜ì´ìŠ¤
TEST_INTERFACE_HTML = """
<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <title>Face Recognition System</title>
    <style>
        * { 
            box-sizing: border-box;
            -webkit-tap-highlight-color: transparent;
        }
        
        body { 
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            margin: 0;
            padding: 0;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
        }
        
        .container { 
            max-width: 800px; 
            margin: 0 auto; 
            background: white; 
            min-height: 100vh;
            box-shadow: 0 0 20px rgba(0,0,0,0.1);
        }
        
        .header { 
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 20px;
            text-align: center;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        
        .header h1 {
            margin: 0;
            font-size: 24px;
            font-weight: 600;
        }
        
        .header p {
            margin: 5px 0 0 0;
            opacity: 0.9;
            font-size: 14px;
        }
        
        .content {
            padding: 20px;
        }
        
        .status-card { 
            background: #f8f9fa;
            padding: 15px;
            border-radius: 12px;
            margin-bottom: 20px;
            border: 1px solid #e9ecef;
        }
        
        .upload-section { 
            background: white;
            border: 2px solid #e9ecef;
            padding: 20px;
            text-align: center;
            margin: 20px 0;
            border-radius: 12px;
            transition: all 0.3s;
        }
        
        .upload-section:hover { 
            border-color: #667eea;
            box-shadow: 0 4px 12px rgba(102, 126, 234, 0.1);
        }
        
        .button-group { 
            display: flex;
            flex-direction: column;
            gap: 12px;
            margin: 20px 0;
        }
        
        button { 
            padding: 16px 24px;
            border: none;
            border-radius: 8px;
            cursor: pointer;
            font-weight: 600;
            font-size: 16px;
            transition: all 0.3s;
            width: 100%;
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 8px;
        }
        
        button:active {
            transform: scale(0.98);
        }
        
        .btn-primary { 
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
        }
        
        .btn-success { 
            background: linear-gradient(135deg, #56ab2f 0%, #a8e063 100%);
            color: white;
        }
        
        .btn-info { 
            background: linear-gradient(135deg, #2193b0 0%, #6dd5ed 100%);
            color: white;
        }
        
        .btn-danger { 
            background: linear-gradient(135deg, #eb3349 0%, #f45c43 100%);
            color: white;
        }
        
        .btn-warning {
            background: linear-gradient(135deg, #f7971e 0%, #ffd200 100%);
            color: white;
        }
        
        .result { 
            margin: 20px 0;
            padding: 15px;
            border-radius: 12px;
            font-family: 'Courier New', monospace;
            font-size: 14px;
            overflow-x: auto;
        }
        
        .success { 
            background: #d4edda;
            border: 1px solid #c3e6cb;
            color: #155724;
        }
        
        .error { 
            background: #f8d7da;
            border: 1px solid #f5c6cb;
            color: #721c24;
        }
        
        input[type="file"] { 
            display: none;
        }
        
        .file-label {
            display: inline-block;
            padding: 12px 24px;
            background: #f8f9fa;
            border: 2px dashed #dee2e6;
            border-radius: 8px;
            cursor: pointer;
            transition: all 0.3s;
            margin: 10px 0;
        }
        
        .file-label:hover {
            background: #e9ecef;
            border-color: #667eea;
        }
        
        /* ëª¨ë°”ì¼ ìµœì í™” */
        @media (max-width: 768px) {
            .header h1 {
                font-size: 20px;
            }
            
            .content {
                padding: 15px;
            }
            
            button {
                font-size: 15px;
                padding: 14px 20px;
            }
            
            .upload-section {
                padding: 15px;
            }
        }
        
        @media (min-width: 768px) {
            .button-group {
                flex-direction: row;
                flex-wrap: wrap;
            }
            
            button {
                width: auto;
                flex: 1;
            }
        }
        
        /* ì¹´ë©”ë¼ ì„¹ì…˜ ìŠ¤íƒ€ì¼ */
        #cameraSection {
            background: #f8f9fa;
            border-radius: 12px;
            padding: 20px;
            margin: 20px 0;
        }
        
        #videoElement {
            width: 100%;
            max-width: 640px;
            height: auto;
            border-radius: 12px;
            box-shadow: 0 4px 12px rgba(0,0,0,0.1);
        }
        
        #cameraStatus {
            margin-top: 15px;
            padding: 10px;
            background: white;
            border-radius: 8px;
            font-size: 14px;
            text-align: center;
        }
        
        .camera-controls {
            display: flex;
            gap: 10px;
            margin-top: 15px;
            flex-wrap: wrap;
        }
        
        .camera-controls button {
            flex: 1;
            min-width: 120px;
        }
        
        /* ë¡œë”© ì• ë‹ˆë©”ì´ì…˜ */
        .loading {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 3px solid rgba(255,255,255,.3);
            border-radius: 50%;
            border-top-color: white;
            animation: spin 1s ease-in-out infinite;
        }
        
        @keyframes spin {
            to { transform: rotate(360deg); }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ğŸ“· Face Recognition</h1>
            <p>ì–¼êµ´ ì¸ì‹ ì‹œìŠ¤í…œ</p>
        </div>
        
        <div class="content">
            <!-- ì‹œìŠ¤í…œ ìƒíƒœ -->
            <div class="status-card">
                <h3 style="margin-top: 0;">ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ</h3>
                <div id="systemStatus" style="margin: 10px 0;">í™•ì¸ ì¤‘...</div>
                <button class="btn-info" onclick="checkHealth()" style="width: 100%;">
                    ğŸ”„ ìƒíƒœ ìƒˆë¡œê³ ì¹¨
                </button>
            </div>
            
            <!-- ì¹´ë©”ë¼ ë¹ ë¥¸ ì•¡ì„¸ìŠ¤ -->
            <div class="upload-section" style="background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white;">
                <h3 style="margin-top: 0;">ğŸ“± ì¹´ë©”ë¼</h3>
                <div class="button-group">
                    <button class="btn-warning" onclick="startMobileCameraRecognition()">
                        ğŸ¯ ì–¼êµ´ ì¸ì‹ (ì¹´ë©”ë¼)
                    </button>
                    <button class="btn-success" onclick="startMobileCameraDetection()">
                        âœ… ë“±ë¡ ì í•©ì„± í…ŒìŠ¤íŠ¸ (ì¹´ë©”ë¼)
                    </button>
                </div>
            </div>
            
            <!-- íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜ -->
            <div class="upload-section">
                <h3 style="margin-top: 0;">ğŸ“ íŒŒì¼ ì—…ë¡œë“œ</h3>
                
                <!-- ì–¼êµ´ ì¸ì‹ -->
                <div style="margin-bottom: 15px;">
                    <label for="recognizeImage" class="file-label">
                        ğŸ” ì¸ì‹ìš© ì´ë¯¸ì§€ ì„ íƒ
                    </label>
                    <input type="file" id="recognizeImage" accept="image/*" capture="environment">
                    <button class="btn-primary" onclick="recognizeFace()" style="width: 100%; margin-top: 10px;">
                        ğŸ“· ì–¼êµ´ ì¸ì‹ ì‹¤í–‰
                    </button>
                </div>
                
                <!-- ì–¼êµ´ ê²€ì¶œ -->
                <div>
                    <label for="detectImage" class="file-label">
                        ğŸ” ê²€ì¶œìš© ì´ë¯¸ì§€ ì„ íƒ
                    </label>
                    <input type="file" id="detectImage" accept="image/*,video/*" capture="environment">
                    <button class="btn-info" onclick="detectFace()" style="width: 100%; margin-top: 10px;">
                        ë“±ë¡ ì í•©ì„± í…ŒìŠ¤íŠ¸
                    </button>
                </div>
            </div>
            
            <!-- ì¹´ë©”ë¼ í”„ë¦¬ë·° ì˜ì—­ -->
            <div id="cameraSection" style="display:none;">
                <h3 style="margin: 0 0 15px 0; text-align: center;">ğŸ“¸ ì¹´ë©”ë¼ í”„ë¦¬ë·°</h3>
                <video id="videoElement" autoplay playsinline></video>
                <canvas id="canvasElement" style="display:none;"></canvas>
                
                <div id="cameraStatus"></div>
                
                <div class="camera-controls">
                    <button class="btn-success" id="captureBtn" onclick="captureFromCamera()">
                        ğŸ“¸ ìº¡ì²˜
                    </button>
                    <button class="btn-warning" id="switchCameraBtn" onclick="switchCamera()">
                        ğŸ”„ ì¹´ë©”ë¼ ì „í™˜
                    </button>
                    <button class="btn-danger" onclick="stopCamera()">
                        â¹ï¸ ì¢…ë£Œ
                    </button>
                </div>
            </div>
            
            <!-- ê²°ê³¼ í‘œì‹œ ì˜ì—­ -->
            <div id="result"></div>
        </div>
    </div>
    
    <script>
        let cameraStream = null;
        let currentCameraMode = null; // 'recognition' or 'detection'
        let currentFacingMode = 'environment'; // 'user' or 'environment'
        let videoElement = null;
        let canvasElement = null;
        
        // ì´ˆê¸°í™”
        document.addEventListener('DOMContentLoaded', function() {
            videoElement = document.getElementById('videoElement');
            canvasElement = document.getElementById('canvasElement');
            
            // ëª¨ë°”ì¼ ì—¬ë¶€ ì²´í¬
            const isMobile = /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
            if (isMobile) {
                console.log('Mobile device detected');
            }
            
            // HTTPS/ë³´ì•ˆ ì—°ê²° ìƒíƒœ ì²´í¬
            const isSecure = location.protocol === 'https:' || location.hostname === 'localhost' || location.hostname === '127.0.0.1';
            if (!isSecure) {
                console.warn('HTTP connection detected - camera features may be limited');
                console.log('Current location:', location.protocol, location.hostname);
            }
            
            // ì¹´ë©”ë¼ API ë¯¸ë¦¬ í…ŒìŠ¤íŠ¸ (HTTPì—ì„œë„ ì²´í¬)
            console.log('Navigator check:', {
                mediaDevices: typeof navigator.mediaDevices,
                getUserMedia: typeof navigator.getUserMedia,
                webkitGetUserMedia: typeof navigator.webkitGetUserMedia,
                mozGetUserMedia: typeof navigator.mozGetUserMedia,
                mediaDevicesExists: !!navigator.mediaDevices,
                getUserMediaExists: !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia)
            });
            
            const hasModernAPI = !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia);
            const hasLegacyAPI = !!(navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia);
            console.log('Camera API support:', { modern: hasModernAPI, legacy: hasLegacyAPI, secure: isSecure });
            console.log('Final API check result:', { hasModern: hasModernAPI, hasLegacy: hasLegacyAPI, total: hasModernAPI || hasLegacyAPI });
            
            // HTTP í™˜ê²½ì´ë©´ ë ˆê±°ì‹œ APIë¼ë„ ì‹œë„í•´ë³´ê¸°
            if (!hasModernAPI && !hasLegacyAPI) {
                console.warn('ì¹´ë©”ë¼ API ì™„ì „ ë¯¸ì§€ì› - íŒŒì¼ ì—…ë¡œë“œë§Œ ì‚¬ìš© ê°€ëŠ¥');
                
                // ì¹´ë©”ë¼ ì„¹ì…˜ í—¤ë” ì—…ë°ì´íŠ¸
                const cameraHeader = document.querySelector('.upload-section h3');
                if (cameraHeader && cameraHeader.textContent.includes('ì¹´ë©”ë¼')) {
                    cameraHeader.innerHTML = 'ğŸ“± ì¹´ë©”ë¼ (ë¯¸ì§€ì›) - ğŸ“ íŒŒì¼ ì—…ë¡œë“œ ì‚¬ìš©';
                }
                
                // ì¹´ë©”ë¼ ë²„íŠ¼ì— ë¯¸ì§€ì› í‘œì‹œ
                setTimeout(() => {
                    checkCameraSupport();
                }, 100);
            } else {
                console.info('ì¹´ë©”ë¼ API ê°ì§€ë¨ - HTTPì—ì„œë„ ì‹œë„ ê°€ëŠ¥');
            }
            
            checkHealth();
        });
        
        async function checkHealth() {
            try {
                const response = await fetch('/api/face/health');
                const data = await response.json();
                document.getElementById('systemStatus').innerHTML = 
                    'âœ… ì„œë²„ ì˜¨ë¼ì¸ - ' + data.service + ' v' + data.version;
            } catch (error) {
                document.getElementById('systemStatus').innerHTML = 
                    'âŒ ì„œë²„ ì˜¤í”„ë¼ì¸ - ' + error.message;
            }
        }
        
        // ëª¨ë°”ì¼ ì¹´ë©”ë¼ ì‹œì‘ (í›„ë©´ ì¹´ë©”ë¼ ìš°ì„ )
        async function startMobileCamera(mode, facingMode = 'environment') {
            currentCameraMode = mode;
            currentFacingMode = facingMode;
            const cameraSection = document.getElementById('cameraSection');
            const cameraStatus = document.getElementById('cameraStatus');
            
            // ë” ê°•ë ¥í•œ ì¹´ë©”ë¼ API ê°ì§€
            const detectCameraAPIs = function() {
                const apis = {
                    modern: !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia),
                    webkit: !!(navigator.webkitGetUserMedia),
                    moz: !!(navigator.mozGetUserMedia),
                    ms: !!(navigator.msGetUserMedia),
                    legacy: !!(navigator.getUserMedia)
                };
                
                console.log('Camera API detection results:', apis);
                return apis;
            };
            
            const cameraAPIs = detectCameraAPIs();
            const hasModernAPI = cameraAPIs.modern;
            const hasLegacyAPI = cameraAPIs.webkit || cameraAPIs.moz || cameraAPIs.ms || cameraAPIs.legacy;
            
            // API ì‚¬ìš© ë¶ˆê°€ëŠ¥í•œ ê²½ìš° ì¦‰ì‹œ íŒŒì¼ ì—…ë¡œë“œë¡œ ì „í™˜
            if (!hasModernAPI && !hasLegacyAPI) {
                console.warn('ì¹´ë©”ë¼ API ì—†ìŒ - íŒŒì¼ ì—…ë¡œë“œë¡œ ì „í™˜');
                cameraStatus.innerHTML = 'âŒ ì¹´ë©”ë¼ APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.<br><br>' +
                    '<strong>íŒŒì¼ ì—…ë¡œë“œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”:</strong><br>' +
                    'ì•„ë˜ "íŒŒì¼ ì—…ë¡œë“œ" ì„¹ì…˜ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.<br><br>' +
                    '<strong>ë¸Œë¼ìš°ì € ì§€ì›:</strong><br>' +
                    'â€¢ Chrome 53+ (ê¶Œì¥)<br>' +
                    'â€¢ Firefox 36+<br>' +
                    'â€¢ Safari 11+<br>' +
                    'â€¢ Edge 12+';
                cameraSection.style.display = 'block';
                
                // íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜ìœ¼ë¡œ ìŠ¤í¬ë¡¤
                setTimeout(() => {
                    const uploadSection = document.querySelector('.upload-section');
                    if (uploadSection) {
                        uploadSection.scrollIntoView({ behavior: 'smooth', block: 'center' });
                        uploadSection.style.border = '3px solid #667eea';
                        uploadSection.style.boxShadow = '0 0 15px rgba(102, 126, 234, 0.3)';
                        
                        // 3ì´ˆ í›„ í•˜ì´ë¼ì´íŠ¸ ì œê±°
                        setTimeout(() => {
                            uploadSection.style.border = '2px solid #e9ecef';
                            uploadSection.style.boxShadow = '0 4px 12px rgba(102, 126, 234, 0.1)';
                        }, 3000);
                    }
                }, 500);
                
                return;
            }
            
            if (!hasModernAPI && hasLegacyAPI) {
                console.log('Using legacy getUserMedia API');
                cameraSection.style.display = 'block';
                return startLegacyCamera(mode, facingMode);
            }
            
            try {
                // ê¸°ì¡´ ìŠ¤íŠ¸ë¦¼ ì •ì§€
                if (cameraStream) {
                    stopCamera();
                }
                
                cameraStatus.innerHTML = '<span class="loading"></span> ì¹´ë©”ë¼ ì‹œì‘ ì¤‘...';
                
                // ì¹´ë©”ë¼ ì œì•½ ì¡°ê±´ ì„¤ì •
                const constraints = {
                    video: {
                        facingMode: facingMode, // 'user' = front, 'environment' = back
                        width: { ideal: 1280, max: 1920 },
                        height: { ideal: 720, max: 1080 }
                    },
                    audio: false
                };
                
                // ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ ê°€ì ¸ì˜¤ê¸° - HTTPì—ì„œë„ ì‹œë„
                console.log('Camera constraints:', constraints);
                cameraStream = await navigator.mediaDevices.getUserMedia(constraints);
                
                videoElement.srcObject = cameraStream;
                cameraSection.style.display = 'block';
                
                // ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„° ë¡œë“œ í›„ ìº”ë²„ìŠ¤ í¬ê¸° ì„¤ì •
                videoElement.onloadedmetadata = function() {
                    canvasElement.width = videoElement.videoWidth;
                    canvasElement.height = videoElement.videoHeight;
                    console.log('Camera resolution: ' + videoElement.videoWidth + 'x' + videoElement.videoHeight);
                };
                
                // ìº¡ì²˜ ë²„íŠ¼ í…ìŠ¤íŠ¸ ë³€ê²½
                const captureBtn = document.getElementById('captureBtn');
                if (mode === 'recognition') {
                    captureBtn.innerHTML = 'ğŸ¯ ì¸ì‹í•˜ê¸°';
                    cameraStatus.textContent = 'ì–¼êµ´ ì¸ì‹ ëª¨ë“œ';
                } else if (mode === 'detection') {
                    captureBtn.innerHTML = 'âœ… ê²€ì¶œí•˜ê¸°';
                    cameraStatus.textContent = 'ë“±ë¡ ì í•©ì„± í…ŒìŠ¤íŠ¸ ëª¨ë“œ';
                }
                
                // ì¹´ë©”ë¼ ì „í™˜ ë²„íŠ¼ í‘œì‹œ
                const switchBtn = document.getElementById('switchCameraBtn');
                switchBtn.style.display = 'inline-block';
                
                // ë¶€ë“œëŸ¬ìš´ ìŠ¤í¬ë¡¤
                setTimeout(() => {
                    cameraSection.scrollIntoView({ behavior: 'smooth', block: 'center' });
                }, 100);
                
            } catch (error) {
                console.error('ì¹´ë©”ë¼ ì˜¤ë¥˜:', error);
                console.error('ì—ëŸ¬ ìƒì„¸:', { name: error.name, message: error.message });
                
                // êµ¬í˜• APIë¡œ ë‹¤ì‹œ ì‹œë„
                if (hasLegacyAPI && hasModernAPI) {
                    console.log('Modern API failed, retrying with legacy API');
                    cameraStatus.innerHTML = '<span class="loading"></span> êµ¬í˜• APIë¡œ ì¬ì‹œë„ ì¤‘...';
                    return startLegacyCamera(mode, facingMode);
                }
                
                // ì—ëŸ¬ ë©”ì‹œì§€ ê°œì„ 
                let errorMsg = '';
                let suggestions = '';
                
                if (error.name === 'NotAllowedError') {
                    errorMsg = 'ì¹´ë©”ë¼ ê¶Œí•œì´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.';
                    suggestions = '<strong>í•´ê²° ë°©ë²•:</strong><br>' +
                        '1. ì£¼ì†Œì°½ ì™¼ìª½ ì¹´ë©”ë¼ ì•„ì´ì½˜ í´ë¦­<br>' +
                        '2. "ì¹´ë©”ë¼ í—ˆìš©" ì„ íƒ<br>' +
                        '3. í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨ í›„ ë‹¤ì‹œ ì‹œë„<br>' +
                        '4. ë˜ëŠ” íŒŒì¼ ì—…ë¡œë“œ ê¸°ëŠ¥ ì‚¬ìš©';
                } else if (error.name === 'NotFoundError') {
                    errorMsg = 'ì¹´ë©”ë¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';
                    suggestions = '<strong>í•´ê²° ë°©ë²•:</strong><br>' +
                        '1. ì¹´ë©”ë¼ê°€ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸<br>' +
                        '2. ë‹¤ë¥¸ ì•±ì—ì„œ ì¹´ë©”ë¼ë¥¼ ì‚¬ìš© ì¤‘ì¸ì§€ í™•ì¸<br>' +
                        '3. íŒŒì¼ ì—…ë¡œë“œ ê¸°ëŠ¥ ì‚¬ìš©';
                } else if (error.name === 'NotReadableError') {
                    errorMsg = 'ì¹´ë©”ë¼ê°€ ì´ë¯¸ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤.';
                    suggestions = '<strong>í•´ê²° ë°©ë²•:</strong><br>' +
                        '1. ë‹¤ë¥¸ íƒ­ì´ë‚˜ ì•±ì˜ ì¹´ë©”ë¼ ì‚¬ìš© ì¤‘ì§€<br>' +
                        '2. ë¸Œë¼ìš°ì € ì¬ì‹œì‘<br>' +
                        '3. íŒŒì¼ ì—…ë¡œë“œ ê¸°ëŠ¥ ì‚¬ìš©';
                } else if (error.name === 'NotSupportedError' || error.message.includes('HTTPS')) {
                    errorMsg = 'HTTPS ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤.';
                    suggestions = '<strong>í•´ê²° ë°©ë²•:</strong><br>' +
                        '1. https://localhost:5002 ë¡œ ì ‘ì†<br>' +
                        '2. Chrome í”Œë˜ê·¸ì—ì„œ "Insecure origins treated as secure" ì„¤ì •<br>' +
                        '3. íŒŒì¼ ì—…ë¡œë“œ ê¸°ëŠ¥ ì‚¬ìš©';
                } else {
                    errorMsg = 'ì¹´ë©”ë¼ ì ‘ê·¼ ì‹¤íŒ¨: ' + error.message;
                    suggestions = '<strong>ëŒ€ì•ˆ:</strong><br>' +
                        '1. íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜ ì‚¬ìš©<br>' +
                        '2. HTTPS ì—°ê²°ë¡œ ì ‘ì†<br>' +
                        '3. ë¸Œë¼ìš°ì € ì¬ì‹œì‘ í›„ ë‹¤ì‹œ ì‹œë„';
                }
                
                cameraStatus.innerHTML = 'âŒ ' + errorMsg + '<br><br>' + suggestions;
                cameraSection.style.display = 'block';
            }
        }
        
        // êµ¬í˜• ë¸Œë¼ìš°ì € getUserMedia ì§€ì›
        function startLegacyCamera(mode, facingMode) {
            const cameraSection = document.getElementById('cameraSection');
            const cameraStatus = document.getElementById('cameraStatus');
            
            console.log('Starting legacy API:', { mode, facingMode });
            
            // êµ¬í˜• API ë˜í¼
            navigator.getUserMedia = navigator.getUserMedia || 
                                     navigator.webkitGetUserMedia || 
                                     navigator.mozGetUserMedia || 
                                     navigator.msGetUserMedia;
            
            if (navigator.getUserMedia) {
                // Legacy API constraints - simplified settings
                const videoConstraints = {
                    width: { ideal: 640, max: 1280 },
                    height: { ideal: 480, max: 720 }
                };
                
                // facingMode support check
                if (facingMode && (facingMode === 'user' || facingMode === 'environment')) {
                    videoConstraints.facingMode = facingMode;
                }
                
                cameraStatus.innerHTML = '<span class="loading"></span> Starting camera (Legacy API)...';
                cameraSection.style.display = 'block';
                
                console.log('Legacy API constraints:', videoConstraints);
                
                navigator.getUserMedia(
                    videoConstraints,  // Legacy API only accepts video object
                    function(stream) {
                        console.log('Legacy API success:', stream);
                        
                        // ì„±ê³µ ì½œë°±
                        cameraStream = stream;
                        
                        // srcObject ë˜ëŠ” src ì„¤ì • (ë¸Œë¼ìš°ì €ë³„ í˜¸í™˜ì„±)
                        if (videoElement.srcObject !== undefined) {
                            videoElement.srcObject = stream;
                        } else {
                            // For legacy browsers (deprecated)
                            videoElement.src = window.URL.createObjectURL(stream);
                        }
                        
                        videoElement.onloadedmetadata = function() {
                            canvasElement.width = videoElement.videoWidth || 640;
                            canvasElement.height = videoElement.videoHeight || 480;
                            console.log('Legacy API video resolution:', canvasElement.width + 'x' + canvasElement.height);
                        };
                        
                        // ìº¡ì²˜ ë²„íŠ¼ ì„¤ì •
                        const captureBtn = document.getElementById('captureBtn');
                        if (mode === 'recognition') {
                            captureBtn.innerHTML = 'ğŸ¯ ì¸ì‹í•˜ê¸°';
                            cameraStatus.textContent = 'ì–¼êµ´ ì¸ì‹ ëª¨ë“œ (êµ¬í˜• API)';
                        } else {
                            captureBtn.innerHTML = 'âœ… ê²€ì¶œí•˜ê¸°';
                            cameraStatus.textContent = 'ë“±ë¡ ì í•©ì„± í…ŒìŠ¤íŠ¸ ëª¨ë“œ (êµ¬í˜• API)';
                        }
                        
                        currentCameraMode = mode;
                        currentFacingMode = facingMode;
                        
                        // ë¶€ë“œëŸ¬ìš´ ìŠ¤í¬ë¡¤
                        setTimeout(() => {
                            cameraSection.scrollIntoView({ behavior: 'smooth', block: 'center' });
                        }, 100);
                    },
                    function(error) {
                        // ì—ëŸ¬ ì½œë°±
                        console.error('êµ¬í˜• getUserMedia ì˜¤ë¥˜:', error);
                        
                        let errorMsg = 'êµ¬í˜• API ì¹´ë©”ë¼ ì ‘ê·¼ ì‹¤íŒ¨';
                        let suggestions = '<strong>í•´ê²° ë°©ë²•:</strong><br>' +
                            '1. ë¸Œë¼ìš°ì €ì—ì„œ ì¹´ë©”ë¼ ê¶Œí•œ í—ˆìš©<br>' +
                            '2. Chrome ì„¤ì • > ê°œì¸ì •ë³´ ë° ë³´ì•ˆ > ì‚¬ì´íŠ¸ ì„¤ì • > ì¹´ë©”ë¼<br>' +
                            '3. "localhost:5002" í—ˆìš©ìœ¼ë¡œ ë³€ê²½<br>' +
                            '4. í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨ í›„ ë‹¤ì‹œ ì‹œë„<br>' +
                            '5. íŒŒì¼ ì—…ë¡œë“œ ê¸°ëŠ¥ ì‚¬ìš©';
                        
                        cameraStatus.innerHTML = 'âŒ ' + errorMsg + '<br><br>' + suggestions;
                    }
                );
            } else {
                // getUserMediaê°€ ì™„ì „íˆ ì§€ì›ë˜ì§€ ì•ŠëŠ” ê²½ìš°
                console.error('êµ¬í˜• getUserMedia APIë„ ì§€ì›ë˜ì§€ ì•ŠìŒ');
                cameraStatus.innerHTML = 'âŒ ì´ ë¸Œë¼ìš°ì €ëŠ” ì¹´ë©”ë¼ ê¸°ëŠ¥ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.<br><br>' +
                    '<strong>ëŒ€ì•ˆ:</strong><br>' +
                    '1. íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜ ì‚¬ìš©<br>' +
                    '2. Chrome, Firefox, Safari ìµœì‹  ë²„ì „ ì‚¬ìš©<br>' +
                    '3. HTTPS ì—°ê²°ë¡œ ì ‘ì† (https://localhost:5002)';
                cameraSection.style.display = 'block';
            }
        }
        
        // ì¹´ë©”ë¼ API ë¯¸ë¦¬ ì²´í¬í•˜ì—¬ ë²„íŠ¼ ë¹„í™œì„±í™” ë°©ì§€
        function checkCameraSupport() {
            const hasModern = !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia);
            const hasLegacy = !!(navigator.getUserMedia || navigator.webkitGetUserMedia || navigator.mozGetUserMedia || navigator.msGetUserMedia);
            
            // ê¸°ë³¸ì ìœ¼ë¡œ APIê°€ ìˆìœ¼ë©´ ì‹œë„í•´ë³´ê¸° (HTTPì—ì„œë„)
            if (hasModern || hasLegacy) {
                return true;
            }
            
            // API ìì²´ê°€ ì—†ëŠ” ê²½ìš°ì—ë§Œ false
            const cameraButtons = document.querySelectorAll('.btn-warning, .btn-success');
            cameraButtons.forEach(btn => {
                if (btn.textContent.includes('ì¹´ë©”ë¼')) {
                    btn.style.opacity = '0.7';
                    btn.title = 'ì¹´ë©”ë¼ ë¯¸ì§€ì› - íŒŒì¼ ì—…ë¡œë“œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”';
                }
            });
            console.warn('ì¹´ë©”ë¼ ë¯¸ì§€ì› ë¸Œë¼ìš°ì €');
            return false;
        }
        
        // ì¹´ë©”ë¼ í•¨ìˆ˜ë“¤ - HTTPì—ì„œë„ ì‹œë„
        function startMobileCameraRecognition() {
            if (!checkCameraSupport()) {
                alert('ì´ ë¸Œë¼ìš°ì €ëŠ” ì¹´ë©”ë¼ë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\\n\\níŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.');
                // íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜ìœ¼ë¡œ ìŠ¤í¬ë¡¤
                const uploadSection = document.querySelector('.upload-section');
                if (uploadSection) {
                    uploadSection.scrollIntoView({ behavior: 'smooth', block: 'center' });
                }
                return;
            }
            startMobileCamera('recognition', 'environment'); // Start with back camera
        }
        
        function startMobileCameraDetection() {
            if (!checkCameraSupport()) {
                alert('ì´ ë¸Œë¼ìš°ì €ëŠ” ì¹´ë©”ë¼ë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\\n\\níŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”.');
                // íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜ìœ¼ë¡œ ìŠ¤í¬ë¡¤
                const uploadSection = document.querySelector('.upload-section');
                if (uploadSection) {
                    uploadSection.scrollIntoView({ behavior: 'smooth', block: 'center' });
                }
                return;
            }
            startMobileCamera('detection', 'environment'); // Start with back camera
        }
        
        // ì¹´ë©”ë¼ ì „í™˜
        async function switchCamera() {
            const newFacingMode = currentFacingMode === 'user' ? 'environment' : 'user';
            console.log('Camera switch: ' + currentFacingMode + ' > ' + newFacingMode);
            await startMobileCamera(currentCameraMode, newFacingMode);
        }
        
        // ê¸°ì¡´ PCìš© í•¨ìˆ˜ë“¤ (í•˜ìœ„ í˜¸í™˜ì„±)
        function startCameraRecognition() {
            startMobileCamera('recognition', 'user'); // PC uses front camera
        }
        
        function startCameraDetection() {
            startMobileCamera('detection', 'user'); // PC uses front camera
        }
        
        // ì¹´ë©”ë¼ ì¢…ë£Œ
        function stopCamera() {
            if (cameraStream) {
                cameraStream.getTracks().forEach(track => track.stop());
                cameraStream = null;
            }
            document.getElementById('cameraSection').style.display = 'none';
            document.getElementById('cameraStatus').textContent = '';
            currentCameraMode = null;
        }
        
        // ì¹´ë©”ë¼ì—ì„œ ìº¡ì²˜
        async function captureFromCamera() {
            const videoElement = document.getElementById('videoElement');
            const canvasElement = document.getElementById('canvasElement');
            const context = canvasElement.getContext('2d');
            const cameraStatus = document.getElementById('cameraStatus');
            
            // ë¹„ë””ì˜¤ í”„ë ˆì„ì„ ìº”ë²„ìŠ¤ì— ê·¸ë¦¬ê¸°
            context.drawImage(videoElement, 0, 0, canvasElement.width, canvasElement.height);
            
            // ìº”ë²„ìŠ¤ë¥¼ Base64ë¡œ ë³€í™˜
            const imageDataUrl = canvasElement.toDataURL('image/jpeg', 0.9);
            
            // ì²˜ë¦¬ ì¤‘ í‘œì‹œ
            cameraStatus.textContent = 'ì²˜ë¦¬ ì¤‘...';
            
            // API í˜¸ì¶œ
            if (currentCameraMode === 'recognition') {
                await recognizeFaceFromBase64(imageDataUrl);
                cameraStatus.textContent = 'ì¸ì‹ ì™„ë£Œ - ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”';
            } else if (currentCameraMode === 'detection') {
                await detectFaceFromBase64(imageDataUrl);
                cameraStatus.textContent = 'ê²€ì¶œ ì™„ë£Œ - ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”';
            }
        }
        
        // Base64 ì´ë¯¸ì§€ë¡œ ì–¼êµ´ ì¸ì‹
        async function recognizeFaceFromBase64(imageDataUrl) {
            try {
                const response = await fetch('/api/face/recognize', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        image: imageDataUrl
                    })
                });
                
                const data = await response.json();
                displayResult(data, response.ok);
            } catch (error) {
                displayResult({error: error.message}, false);
            }
        }
        
        // Base64 ì´ë¯¸ì§€ë¡œ ì–¼êµ´ ê²€ì¶œ
        async function detectFaceFromBase64(imageDataUrl) {
            try {
                const response = await fetch('/api/face/detect_for_registration', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({
                        image: imageDataUrl
                    })
                });
                
                const data = await response.json();
                displayResult(data, response.ok);
            } catch (error) {
                displayResult({error: error.message}, false);
            }
        }
        
        async function recognizeFace() {
            const fileInput = document.getElementById('recognizeImage');
            
            if (!fileInput.files[0]) {
                alert('ì´ë¯¸ì§€ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.');
                return;
            }
            
            const formData = new FormData();
            formData.append('image', fileInput.files[0]);
            
            try {
                const response = await fetch('/api/face/recognize', {
                    method: 'POST',
                    body: formData
                });
                
                const data = await response.json();
                displayResult(data, response.ok);
            } catch (error) {
                displayResult({error: error.message}, false);
            }
        }
        
        async function detectFace() {
            const fileInput = document.getElementById('detectImage');
            
            if (!fileInput.files[0]) {
                alert('ì´ë¯¸ì§€ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.');
                return;
            }
            
            console.log('íŒŒì¼ ì—…ë¡œë“œ ì‹œì‘:', {
                fileName: fileInput.files[0].name,
                fileSize: fileInput.files[0].size,
                fileType: fileInput.files[0].type
            });
            
            const formData = new FormData();
            formData.append('image', fileInput.files[0]);
            
            try {
                const response = await fetch('/api/face/detect_for_registration', {
                    method: 'POST',
                    body: formData
                });
                
                console.log('ì„œë²„ ì‘ë‹µ:', response.status, response.headers.get('content-type'));
                
                const data = await response.json();
                console.log('ì‘ë‹µ ë°ì´í„°:', data);
                displayResult(data, response.ok);
            } catch (error) {
                console.error('ìš”ì²­ ì˜¤ë¥˜:', error);
                displayResult({error: error.message}, false);
            }
        }
        
        function displayResult(data, isSuccess) {
            const resultDiv = document.getElementById('result');
            // ì–¼êµ´ ê°ì§€ ì‹¤íŒ¨ ì‹œì—ëŠ” error í´ë˜ìŠ¤ ì‚¬ìš© (ë¶‰ì€ìƒ‰ ë°°ê²½)
            const isDetectionFailed = data.face_detected === false;
            resultDiv.className = 'result ' + ((isSuccess && !isDetectionFailed) ? 'success' : 'error');
            
            // ì–¼êµ´ ê²€ì¶œ ê²°ê³¼ì¸ ê²½ìš° ìƒì„¸ ì •ë³´ í‘œì‹œ (API ì‘ë‹µ êµ¬ì¡°ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€)
            if (data.face_detected !== undefined && !data.matched && !data.face_saved) {
                // ì–¼êµ´ ê²€ì¶œ ì „ìš© í‘œì‹œ (ë“±ë¡/ì¸ì‹ì´ ì•„ë‹Œ ê²½ìš°)
                let html = '<div style="padding: 15px;">';
                html += '<h3 style="margin-top: 0;">ğŸ” ì–¼êµ´ ê²€ì¶œ ê²°ê³¼</h3>';
                
                // ê¸°ë³¸ ìƒíƒœ í‘œì‹œ
                html += '<div style="margin-bottom: 15px;">';
                html += '<div>âœ… ì–¼êµ´ ê°ì§€: ' + (data.face_detected ? 'ì„±ê³µ' : 'ì‹¤íŒ¨') + '</div>';
                html += '<div>ğŸ“ ë“±ë¡ ì í•©ì„±: <strong style="color:' + (data.suitable_for_registration ? 'green' : 'red') + '">' + (data.suitable_for_registration ? 'ì í•©' : 'ë¶€ì í•©') + '</strong></div>';
                html += '</div>';
                
                // í’ˆì§ˆ ì •ë³´
                if (data.quality_score !== undefined) {
                    const qualityPercent = (data.quality_score * 100).toFixed(1);
                    const qualityColor = data.quality_score >= 0.7 ? 'green' : data.quality_score >= 0.5 ? 'orange' : 'red';
                    html += '<div style="margin-bottom: 10px;">';
                    html += '<strong>í’ˆì§ˆ ì ìˆ˜:</strong> ';
                    html += '<span style="color:' + qualityColor + '; font-weight: bold;">' + qualityPercent + '%</span>';
                    html += '</div>';
                }
                
                // Liveness ì •ë³´
                if (data.liveness_score !== undefined) {
                    const livenessPercent = (data.liveness_score * 100).toFixed(1);
                    const livenessColor = data.liveness_score >= 0.6 ? 'green' : 'red';
                    html += '<div style="margin-bottom: 10px;">';
                    html += '<strong>Liveness ì ìˆ˜:</strong> ';
                    html += '<span style="color:' + livenessColor + '; font-weight: bold;">' + livenessPercent + '%</span>';
                    html += '</div>';
                }
                
                // ê¶Œì¥ì‚¬í•­
                if (data.recommendations && data.recommendations.length > 0) {
                    html += '<div style="margin-top: 15px; padding: 10px; background: #f0f8ff; border-radius: 5px;">';
                    html += '<strong>ğŸ’¡ ê°œì„  ê¶Œì¥ì‚¬í•­:</strong><ul style="margin: 5px 0; padding-left: 20px;">';
                    data.recommendations.forEach(rec => {
                        html += '<li>' + rec + '</li>';
                    });
                    html += '</ul></div>';
                }
                
                // ì²˜ë¦¬ ì‹œê°„
                if (data.processing_time_ms !== undefined) {
                    html += '<div style="margin-top: 10px; color: #666; font-size: 0.9em;">';
                    html += 'â±ï¸ ì²˜ë¦¬ ì‹œê°„: ' + data.processing_time_ms + 'ms';
                    html += '</div>';
                }
                
                html += '</div>';
                
                // ì „ì²´ JSON ë°ì´í„°ëŠ” ì ‘ì„ ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ í‘œì‹œ
                html += '<details style="margin-top: 20px;">';
                html += '<summary style="cursor: pointer; padding: 5px; background: #f5f5f5;">ğŸ“‹ ì „ì²´ ì‘ë‹µ ë°ì´í„° ë³´ê¸°</summary>';
                html += '<pre style="margin-top: 10px; background: #f9f9f9; padding: 10px; border-radius: 5px; overflow-x: auto;">' + JSON.stringify(data, null, 2) + '</pre>';
                html += '</details>';
                
                resultDiv.innerHTML = html;
            } else {
                // ê¸°ì¡´ ë°©ì‹ ìœ ì§€ (ë“±ë¡, ì¸ì‹, ì˜¤ë¥˜ ë“±)
                resultDiv.innerHTML = '<pre>' + JSON.stringify(data, null, 2) + '</pre>';
            }
            
            // íŒì—… ì•Œë¦¼
            if (isSuccess && data.matched) {
                // ì¸ì‹ ì„±ê³µ
                alert('âœ… ì–¼êµ´ ì¸ì‹ ì„±ê³µ! íšŒì›ë²ˆí˜¸: ' + data.member_id + ' ì‹ ë¢°ë„: ' + (data.similarity * 100).toFixed(1) + '%');
            } else if (!isSuccess || data.error) {
                // ì–¼êµ´ ë¯¸ê²€ì¶œ, ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜ëŠ” íŒì—… ì—†ì´ ê²°ê³¼ë§Œ í‘œì‹œ
                const silentErrors = [
                    'Face detection failed',
                    'No face detected',
                    'ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤',
                    'Missing image data',
                    'No image file provided'
                ];
                
                const isSilentError = silentErrors.some(err => 
                    data.error && data.error.includes(err)
                );
                
                if (data.error && !isSilentError) {
                    // ì‹¤ì œ ì¤‘ìš”í•œ ì˜¤ë¥˜ì¸ ê²½ìš°ë§Œ íŒì—… í‘œì‹œ
                    alert('âŒ ì˜¤ë¥˜ ë°œìƒ! ' + data.error);
                }
                // ì¼ë°˜ì ì¸ ì‹¤íŒ¨ëŠ” ê²°ê³¼ í™”ë©´ì—ë§Œ í‘œì‹œë¨
            }
        }
        
        // ì´ˆê¸° ìƒíƒœ í™•ì¸
        checkHealth();
    </script>
</body>
</html>
"""

class InsightFaceService:
    """InsightFace ê¸°ë°˜ ì–¼êµ´ ì¸ì‹ ì„œë¹„ìŠ¤"""
    
    def __init__(self, model_path: str = './models'):
        """
        ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        
        Args:
            model_path: ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
        """
        self.model_path = model_path
        
        # InsightFace ì•± ì´ˆê¸°í™”
        logger.info("InsightFace ì´ˆê¸°í™” ì¤‘...")
        self.app = FaceAnalysis(
            root=model_path,
            providers=['CPUExecutionProvider']  # GPU ì‚¬ìš©ì‹œ 'CUDAExecutionProvider'
        )
        self.app.prepare(ctx_id=0, det_size=(640, 640))
        
        # ì„ê³„ê°’ ì„¤ì •
        self.thresholds = {
            'recognition': 0.6,      # ì¸ì‹ ì„ê³„ê°’ (InsightFaceëŠ” ë‚®ì€ ê°’ ì‚¬ìš©)
            'high_quality': 0.8,     # ë†’ì€ í’ˆì§ˆ
            'min_face_size': 50,     # ìµœì†Œ ì–¼êµ´ í¬ê¸°
            'max_faces': 1           # í•œ ë²ˆì— ì²˜ë¦¬í•  ìµœëŒ€ ì–¼êµ´ ìˆ˜
        }
        
        logger.info("âœ… InsightFace ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def enhance_dark_image(self, image: np.ndarray) -> np.ndarray:
        """
        ì–´ë‘ìš´ ì´ë¯¸ì§€ ë³´ì •
        
        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€ (BGR format)
            
        Returns:
            ë³´ì •ëœ ì´ë¯¸ì§€
        """
        try:
            # ë¹ˆ ì´ë¯¸ì§€ ì²´í¬
            if image is None or image.size == 0 or image.shape[0] == 0 or image.shape[1] == 0:
                logger.warning(f"enhance_dark_image: ë¹ˆ ì´ë¯¸ì§€ ì…ë ¥ ê°ì§€")
                return image if image is not None else np.array([])
            
            # ì´ë¯¸ì§€ë¥¼ LAB ìƒ‰ê³µê°„ìœ¼ë¡œ ë³€í™˜
            lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            
            # ë°ê¸° ì±„ë„(L)ì˜ í‰ê· ê°’ ê³„ì‚°
            avg_brightness = np.mean(l)
            
            # ì´ë¯¸ì§€ê°€ ì–´ë‘ìš´ ê²½ìš° (í‰ê·  ë°ê¸°ê°€ 100 ë¯¸ë§Œ)
            if avg_brightness < 100:
                logger.info(f"ì–´ë‘ìš´ ì´ë¯¸ì§€ ê°ì§€ (ë°ê¸°: {avg_brightness:.1f}), ë³´ì • ì ìš©")
                
                # CLAHE (Contrast Limited Adaptive Histogram Equalization) ì ìš©
                clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
                l = clahe.apply(l)
                
                # ê°ë§ˆ ë³´ì • ì¶”ê°€
                gamma = 1.5 if avg_brightness < 50 else 1.2
                l = np.power(l/255.0, 1/gamma) * 255
                l = np.uint8(l)
            
            # LAB ì±„ë„ ë‹¤ì‹œ í•©ì¹˜ê¸°
            enhanced_lab = cv2.merge([l, a, b])
            
            # BGRë¡œ ë‹¤ì‹œ ë³€í™˜
            enhanced_image = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2BGR)
            
            # ë…¸ì´ì¦ˆ ê°ì†Œë¥¼ ìœ„í•œ bilateral filter ì ìš©
            enhanced_image = cv2.bilateralFilter(enhanced_image, 9, 75, 75)
            
            return enhanced_image
            
        except Exception as e:
            logger.warning(f"ì´ë¯¸ì§€ ë³´ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}, ì›ë³¸ ì´ë¯¸ì§€ ì‚¬ìš©")
            return image
    
    def extract_embedding(self, image: np.ndarray) -> Dict:
        """
        ì–¼êµ´ ì„ë² ë”© ì¶”ì¶œ
        
        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€ (BGR format)
        
        Returns:
            dict: ì¶”ì¶œ ê²°ê³¼
        """
        try:
            # ì–´ë‘ìš´ ì´ë¯¸ì§€ ë³´ì • ì ìš©
            enhanced_image = self.enhance_dark_image(image)
            
            # ì–¼êµ´ ê²€ì¶œ ë° ë¶„ì„
            faces = self.app.get(enhanced_image)
            
            if not faces:
                return {
                    'success': False,
                    'error': 'No face detected',
                    'message': 'ì–¼êµ´ì´ ì˜ ë³´ì´ì§€ ì•ŠìŠµë‹ˆë‹¤. ì¹´ë©”ë¼ë¥¼ ì •ë©´ìœ¼ë¡œ ë°”ë¼ë´ ì£¼ì„¸ìš”.'
                }
            
            if len(faces) > self.thresholds['max_faces']:
                return {
                    'success': False,
                    'error': 'Multiple faces detected',
                    'message': f'{len(faces)}ê°œì˜ ì–¼êµ´ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. í•œ ëª…ë§Œ ì´¬ì˜í•´ì£¼ì„¸ìš”.'
                }
            
            face = faces[0]
            
            # ì–¼êµ´ í¬ê¸° í™•ì¸
            bbox = face.bbox.astype(int)
            face_width = bbox[2] - bbox[0]
            face_height = bbox[3] - bbox[1]
            
            if face_width < self.thresholds['min_face_size'] or face_height < self.thresholds['min_face_size']:
                return {
                    'success': False,
                    'error': 'Face too small',
                    'message': 'ì¡°ê¸ˆ ë” ê°€ê¹Œì´ ì™€ì£¼ì„¸ìš”.'
                }
            
            # í’ˆì§ˆ í‰ê°€
            quality_score = self._evaluate_quality(image, bbox)
            
            # ì„ë² ë”© ì¶”ì¶œ (512ì°¨ì›)
            embedding = face.normed_embedding
            
            # ì¶”ê°€ ì†ì„±
            age = face.age if hasattr(face, 'age') else None
            gender = face.gender if hasattr(face, 'gender') else None
            
            # ì•ˆê²½ ê°ì§€ ì œê±° - ë¼ì´ë¸Œë‹ˆìŠ¤ ê°ì§€ë§Œ ì‚¬ìš©
            glasses_detected = False  # í•­ìƒ Falseë¡œ ì„¤ì •
            glasses_confidence = 0.0  # ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
            
            return {
                'success': True,
                'embedding': embedding.tolist(),
                'embedding_norm': float(np.linalg.norm(embedding)),
                'quality_score': float(quality_score),
                'bbox': bbox.tolist(),
                'landmarks': face.kps.tolist() if face.kps is not None else None,
                'age': int(age) if age else None,
                'gender': 'M' if gender == 1 else 'F' if gender == 0 else None,
                'glasses_detected': glasses_detected,
                'glasses_confidence': glasses_confidence,
                'face_confidence': float(face.det_score),
                'processing_time_ms': 0  # ë‚˜ì¤‘ì— ì¸¡ì •
            }
            
        except Exception as e:
            logger.error(f"ì„ë² ë”© ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")
            # OpenCV ì˜¤ë¥˜ë¥¼ ì¹œê·¼í•œ ë©”ì‹œì§€ë¡œ ë³€í™˜
            if "!_src.empty()" in str(e) or "cvtColor" in str(e):
                error_msg = 'ì¹´ë©”ë¼ í™”ë©´ì´ ì œëŒ€ë¡œ ìº¡ì²˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.'
            else:
                error_msg = 'ì–¼êµ´ì„ ì¸ì‹í•˜ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.'
            
            return {
                'success': False,
                'error': error_msg,
                'message': error_msg
            }
    
    def compare_embeddings(self, embedding1: List[float], embedding2: List[float]) -> float:
        """
        ë‘ ì„ë² ë”© ê°„ ìœ ì‚¬ë„ ê³„ì‚°
        
        Args:
            embedding1: ì²« ë²ˆì§¸ ì„ë² ë”©
            embedding2: ë‘ ë²ˆì§¸ ì„ë² ë”©
        
        Returns:
            float: ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (0~1)
        """
        # numpy ë°°ì—´ë¡œ ë³€í™˜
        emb1 = np.array(embedding1)
        emb2 = np.array(embedding2)
        
        # ì •ê·œí™” (InsightFaceëŠ” ì´ë¯¸ ì •ê·œí™”ë¨)
        emb1 = emb1 / np.linalg.norm(emb1)
        emb2 = emb2 / np.linalg.norm(emb2)
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
        similarity = np.dot(emb1, emb2)
        
        return float(similarity)
    
    def _clip_bbox(self, bbox: np.ndarray, image_shape: tuple) -> np.ndarray:
        """bboxë¥¼ ì´ë¯¸ì§€ ê²½ê³„ ë‚´ë¡œ í´ë¦¬í•‘"""
        h, w = image_shape[:2]
        x1, y1, x2, y2 = bbox
        
        # ê²½ê³„ ë‚´ë¡œ í´ë¦¬í•‘
        x1 = max(0, min(int(x1), w-1))
        y1 = max(0, min(int(y1), h-1))
        x2 = max(0, min(int(x2), w))
        y2 = max(0, min(int(y2), h))
        
        # x2, y2ê°€ x1, y1ë³´ë‹¤ ì‘ìœ¼ë©´ êµì •
        if x2 <= x1:
            x2 = x1 + 1
        if y2 <= y1:
            y2 = y1 + 1
            
        return np.array([x1, y1, x2, y2])
    
    def _evaluate_quality(self, image: np.ndarray, bbox: np.ndarray) -> float:
        """ì–¼êµ´ ì´ë¯¸ì§€ í’ˆì§ˆ í‰ê°€"""
        # bbox í´ë¦¬í•‘
        bbox = self._clip_bbox(bbox, image.shape)
        x1, y1, x2, y2 = bbox
        face_img = image[y1:y2, x1:x2]
        
        # ë¹ˆ ì´ë¯¸ì§€ ì²´í¬
        if face_img.size == 0 or face_img.shape[0] == 0 or face_img.shape[1] == 0:
            logger.warning(f"_evaluate_quality: ë¹ˆ ì–¼êµ´ ì´ë¯¸ì§€ ê°ì§€ shape={face_img.shape}")
            return 0.0
        
        scores = []
        
        # 1. í¬ê¸° ì ìˆ˜
        size_score = min((x2-x1) * (y2-y1) / (image.shape[0] * image.shape[1]) * 10, 1.0)
        scores.append(size_score)
        
        # 2. ì„ ëª…ë„ ì ìˆ˜
        gray = cv2.cvtColor(face_img, cv2.COLOR_BGR2GRAY)
        laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
        sharpness_score = min(laplacian_var / 500, 1.0)
        scores.append(sharpness_score)
        
        # 3. ë°ê¸° ì ìˆ˜
        brightness = np.mean(gray)
        brightness_score = 1.0 - abs(brightness - 127.5) / 127.5
        scores.append(brightness_score)
        
        return np.mean(scores)
    
    def _estimate_face_pose(self, landmarks: np.ndarray) -> Dict:
        """
        5ê°œ ëœë“œë§ˆí¬ë¥¼ ì´ìš©í•œ ì–¼êµ´ ê°ë„ ì¶”ì •
        
        Args:
            landmarks: 5ê°œ ì–¼êµ´ íŠ¹ì§•ì  (ì™¼ëˆˆ, ì˜¤ë¥¸ëˆˆ, ì½”, ì™¼ìª½ ì…ê¼¬ë¦¬, ì˜¤ë¥¸ìª½ ì…ê¼¬ë¦¬)
            
        Returns:
            dict: ê°ë„ ì •ë³´ (yaw, pitch, roll, is_frontal)
        """
        try:
            if landmarks is None or len(landmarks) < 5:
                return {
                    'yaw': 0.0,
                    'pitch': 0.0,
                    'roll': 0.0,
                    'is_frontal': False,
                    'error': 'Insufficient landmarks'
                }
            
            # ëœë“œë§ˆí¬ í¬ì¸íŠ¸
            left_eye = landmarks[0]
            right_eye = landmarks[1]
            nose = landmarks[2]
            left_mouth = landmarks[3]
            right_mouth = landmarks[4]
            
            # Roll ê°ë„ ê³„ì‚° (ë¨¸ë¦¬ ê¸°ìš¸ê¸°)
            eye_vector = right_eye - left_eye
            roll = np.degrees(np.arctan2(eye_vector[1], eye_vector[0]))
            
            # ì–¼êµ´ ì¤‘ì‹¬ì 
            face_center = np.mean([left_eye, right_eye, nose, left_mouth, right_mouth], axis=0)
            
            # Yaw ê°ë„ ì¶”ì • (ì¢Œìš° íšŒì „)
            # ì¢Œìš° ëˆˆê³¼ ì½”ì˜ ì‚¼ê°í˜• ëŒ€ì¹­ì„± ì´ìš©
            left_eye_nose_dist = np.linalg.norm(left_eye - nose)
            right_eye_nose_dist = np.linalg.norm(right_eye - nose)
            
            # ê±°ë¦¬ ë¹„ìœ¨ë¡œ yaw ì¶”ì • (ê²½í—˜ì  ê³µì‹)
            dist_ratio = left_eye_nose_dist / (right_eye_nose_dist + 1e-7)
            yaw = (1 - dist_ratio) * 30  # ìµœëŒ€ Â±30ë„ë¡œ ë§¤í•‘
            
            # Pitch ê°ë„ ì¶”ì • (ìƒí•˜ ê¸°ìš¸ê¸°)
            # ëˆˆ-ì½” ê±°ë¦¬ì™€ ì½”-ì… ê±°ë¦¬ì˜ ë¹„ìœ¨ ì´ìš©
            eye_center = (left_eye + right_eye) / 2
            eye_nose_dist = np.linalg.norm(eye_center - nose)
            mouth_center = (left_mouth + right_mouth) / 2
            nose_mouth_dist = np.linalg.norm(nose - mouth_center)
            
            # ì½”ì˜ Y ì¢Œí‘œ ìœ„ì¹˜ë¥¼ ì¶”ê°€ë¡œ ê³ ë ¤
            # ì•„ë˜ë¥¼ ë³¼ ë•Œ: ì½”ê°€ ëˆˆë³´ë‹¤ ì•„ë˜ë¡œ, ì…ê³¼ ì½”ì˜ ê±°ë¦¬ê°€ ê°€ê¹Œì›Œì§
            # ìœ„ë¥¼ ë³¼ ë•Œ: ì½”ê°€ ëˆˆê³¼ ê°€ê¹Œì›Œì§€ê³ , ì…ê³¼ ì½”ì˜ ê±°ë¦¬ê°€ ë©€ì–´ì§
            eye_y = eye_center[1]
            nose_y = nose[1]
            mouth_y = mouth_center[1]
            
            # ìˆ˜ì§ ìœ„ì¹˜ ê´€ê³„ë¥¼ ì´ìš©í•œ pitch ê³„ì‚°
            # ì •ë©´ì¼ ë•Œ ëˆˆ-ì½” : ì½”-ì… ë¹„ìœ¨ì€ ì•½ 1:1.2
            vertical_ratio = nose_mouth_dist / (eye_nose_dist + 1e-7)
            
            # ì½”ì˜ ìƒëŒ€ì  ìœ„ì¹˜ë¡œ ë°©í–¥ íŒë‹¨
            nose_position_ratio = (nose_y - eye_y) / (mouth_y - eye_y + 1e-7)
            
            # pitch ê³„ì‚° ê°œì„ 
            # ì•„ë˜ë¥¼ ë³¼ ë•Œ (-): vertical_ratio ì¦ê°€, nose_position_ratio ì¦ê°€
            # ìœ„ë¥¼ ë³¼ ë•Œ (+): vertical_ratio ê°ì†Œ, nose_position_ratio ê°ì†Œ
            if nose_position_ratio > 0.45:  # ì •ë©´ë³´ë‹¤ ì½”ê°€ ì•„ë˜ì— ìˆìŒ (ì•„ë˜ë¥¼ ë´„)
                pitch = -(nose_position_ratio - 0.45) * 50  # ìŒìˆ˜ (ì•„ë˜)
            else:  # ì •ë©´ë³´ë‹¤ ì½”ê°€ ìœ„ì— ìˆìŒ (ìœ„ë¥¼ ë´„)
                pitch = (0.45 - nose_position_ratio) * 50  # ì–‘ìˆ˜ (ìœ„)
            
            # pitch ê°’ ì œí•œ (-30 ~ 30ë„)
            pitch = np.clip(pitch, -30, 30)
            
            # ì •ë©´ ì—¬ë¶€ íŒë‹¨
            is_frontal = (
                abs(yaw) <= 15 and 
                abs(pitch) <= 15 and 
                abs(roll) <= 10
            )
            
            return {
                'yaw': float(yaw),
                'pitch': float(pitch),
                'roll': float(roll),
                'is_frontal': is_frontal
            }
            
        except Exception as e:
            logger.error(f"ì–¼êµ´ ê°ë„ ì¶”ì • ì˜¤ë¥˜: {str(e)}")
            return {
                'yaw': 0.0,
                'pitch': 0.0,
                'roll': 0.0,
                'is_frontal': False,
                'error': str(e)
            }
    
    def _check_face_position(self, bbox: np.ndarray, image_shape: tuple) -> Dict:
        """
        ì–¼êµ´ì´ ì´ë¯¸ì§€ ì¤‘ì•™ì— ìœ„ì¹˜í•˜ëŠ”ì§€ í™•ì¸
        
        Args:
            bbox: ì–¼êµ´ ë°”ìš´ë”© ë°•ìŠ¤ [x1, y1, x2, y2]
            image_shape: ì´ë¯¸ì§€ í¬ê¸° (height, width, channels)
            
        Returns:
            dict: ìœ„ì¹˜ ì •ë³´
        """
        h, w = image_shape[:2]
        x1, y1, x2, y2 = bbox
        
        # ì–¼êµ´ ì¤‘ì‹¬ì 
        face_center_x = (x1 + x2) / 2
        face_center_y = (y1 + y2) / 2
        
        # ì´ë¯¸ì§€ ì¤‘ì‹¬ì 
        img_center_x = w / 2
        img_center_y = h / 2
        
        # ì¤‘ì‹¬ì—ì„œì˜ ê±°ë¦¬ ë¹„ìœ¨
        x_offset_ratio = abs(face_center_x - img_center_x) / (w / 2)
        y_offset_ratio = abs(face_center_y - img_center_y) / (h / 2)
        
        # ì¤‘ì•™ 40% ì˜ì—­ ë‚´ì— ìˆëŠ”ì§€ í™•ì¸
        is_centered = x_offset_ratio < 0.4 and y_offset_ratio < 0.4
        
        # ì–¼êµ´ í¬ê¸° ë¹„ìœ¨
        face_width = x2 - x1
        face_height = y2 - y1
        face_area = face_width * face_height
        image_area = w * h
        size_ratio = face_area / image_area
        
        return {
            'is_centered': is_centered,
            'x_offset_ratio': float(x_offset_ratio),
            'y_offset_ratio': float(y_offset_ratio),
            'face_size_ratio': float(size_ratio),
            'face_width': int(face_width),
            'face_height': int(face_height)
        }
    
    def _evaluate_quality_enhanced(self, image: np.ndarray, face) -> Dict:
        """
        í–¥ìƒëœ ì–¼êµ´ í’ˆì§ˆ í‰ê°€
        
        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€
            face: InsightFace ì–¼êµ´ ê°ì²´
            
        Returns:
            dict: ìƒì„¸ í’ˆì§ˆ í‰ê°€ ê²°ê³¼
        """
        # ê¸°ë³¸ í’ˆì§ˆ ì ìˆ˜
        bbox = face.bbox.astype(int)
        basic_quality = self._evaluate_quality(image, bbox)
        
        # ê²€ì¶œ ì‹ ë¢°ë„
        detection_confidence = float(face.det_score)
        
        # ì–¼êµ´ ìœ„ì¹˜ í™•ì¸
        position_info = self._check_face_position(bbox, image.shape)
        
        # ì–¼êµ´ ê°ë„ ì¶”ì •
        pose_info = self._estimate_face_pose(face.kps)
        
        # ì¢…í•© ì ìˆ˜ ê³„ì‚°
        scores = {
            'basic_quality': basic_quality,
            'detection_confidence': detection_confidence,
            'position_score': 1.0 if position_info['is_centered'] else 0.5,
            'size_score': 1.0 if 0.15 <= position_info['face_size_ratio'] <= 0.7 else 0.5,
            'pose_score': 1.0 if pose_info['is_frontal'] else 0.3
        }
        
        # ê°€ì¤‘ í‰ê· 
        weights = {
            'basic_quality': 0.2,
            'detection_confidence': 0.2,
            'position_score': 0.15,
            'size_score': 0.15,
            'pose_score': 0.3  # ê°ë„ê°€ ê°€ì¥ ì¤‘ìš”
        }
        
        overall_score = sum(scores[k] * weights[k] for k in scores)
        
        return {
            'overall_score': float(overall_score),
            'scores': scores,
            'position_info': position_info,
            'pose_info': pose_info,
            'detection_confidence': detection_confidence
        }
    
    def _calculate_eye_aspect_ratio(self, image: np.ndarray, face) -> float:
        """ëˆˆ ì¢…íš¡ë¹„(EAR) ê³„ì‚° - ëˆˆ ê¹œë¹¡ì„ ê°ì§€ìš©"""
        try:
            # ì–¼êµ´ ì˜ì—­ ì¶”ì¶œ
            bbox = face.bbox.astype(int)
            # bbox í´ë¦¬í•‘
            bbox = self._clip_bbox(bbox, image.shape)
            x1, y1, x2, y2 = bbox
            face_img = image[y1:y2, x1:x2]
            
            # ë¹ˆ ì´ë¯¸ì§€ ì²´í¬
            if face_img.size == 0 or face_img.shape[0] == 0 or face_img.shape[1] == 0:
                logger.warning(f"_calculate_eye_aspect_ratio: ë¹ˆ ì–¼êµ´ ì´ë¯¸ì§€ ê°ì§€ shape={face_img.shape}")
                return 0.3  # ê¸°ë³¸ EAR ê°’ ë°˜í™˜
            
            # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
            gray = cv2.cvtColor(face_img, cv2.COLOR_BGR2GRAY)
            
            # ëˆˆ ì˜ì—­ ì¶”ì • (ì–¼êµ´ ìƒë‹¨ 1/3 ë¶€ë¶„)
            h, w = gray.shape
            eye_region = gray[int(h*0.2):int(h*0.5), :]
            
            # ëˆˆ ì˜ì—­ì˜ í‰ê·  ë°ê¸°ë¡œ ëˆˆ ê°œí ìƒíƒœ ì¶”ì •
            # ëˆˆì„ ê°ìœ¼ë©´ ì†ëˆˆì¹ìœ¼ë¡œ ì¸í•´ ì–´ë‘ì›Œì§
            mean_brightness = np.mean(eye_region)
            
            # ëˆˆ ì˜ì—­ì˜ ì—£ì§€ ë°€ë„
            edges = cv2.Canny(eye_region, 30, 60)
            edge_density = np.sum(edges > 0) / edges.size
            
            # EAR ì¶”ì •ê°’ (0~1 ë²”ìœ„)
            # ë°ê¸°ì™€ ì—£ì§€ ë°€ë„ë¥¼ ì¡°í•©
            ear = (mean_brightness / 255.0) * 0.5 + edge_density * 0.5
            
            return ear
            
        except Exception as e:
            logger.error(f"EAR ê³„ì‚° ì˜¤ë¥˜: {e}")
            return 0.3  # ê¸°ë³¸ê°’
    
    def _detect_blink_pattern(self, ear_values: List[float], threshold: float = 0.2) -> bool:
        """EAR ê°’ ì‹œí€€ìŠ¤ì—ì„œ ëˆˆ ê¹œë¹¡ì„ íŒ¨í„´ ê°ì§€"""
        if len(ear_values) < 3:
            return False
        
        # ëˆˆ ê¹œë¹¡ì„ íŒ¨í„´: ë†’ìŒ â†’ ë‚®ìŒ â†’ ë†’ìŒ
        blink_detected = False
        for i in range(1, len(ear_values) - 1):
            if ear_values[i] < threshold and ear_values[i-1] > threshold and ear_values[i+1] > threshold:
                blink_detected = True
                break
        
        return blink_detected
    
    def detect_eye_blink(self, frames: List[np.ndarray], min_frames: int = 5) -> Tuple[bool, float]:
        """ì—¬ëŸ¬ í”„ë ˆì„ì—ì„œ ëˆˆ ê¹œë¹¡ì„ ê°ì§€"""
        if len(frames) < min_frames:
            logger.warning(f"í”„ë ˆì„ ìˆ˜ ë¶€ì¡±: {len(frames)} < {min_frames}")
            return False, 0.0
        
        ear_values = []
        face_detected_count = 0
        
        for frame in frames:
            faces = self.app.get(frame)
            if faces and len(faces) > 0:
                face_detected_count += 1
                # ì´ë¯¸ì§€ì™€ ì–¼êµ´ ì •ë³´ë¥¼ í•¨ê»˜ ì „ë‹¬
                ear = self._calculate_eye_aspect_ratio(frame, faces[0])
                ear_values.append(ear)
        
        # ì–¼êµ´ì´ ì¶©ë¶„íˆ ê°ì§€ë˜ì§€ ì•ŠìŒ
        if face_detected_count < min_frames * 0.8:
            logger.warning(f"ì–¼êµ´ ê°ì§€ ë¶€ì¡±: {face_detected_count}/{len(frames)}")
            return False, 0.0
        
        # ëˆˆ ê¹œë¹¡ì„ íŒ¨í„´ ê°ì§€
        blink_detected = self._detect_blink_pattern(ear_values)
        confidence = 0.9 if blink_detected else 0.1
        
        logger.info(f"ëˆˆ ê¹œë¹¡ì„ ê°ì§€: {blink_detected}, ì‹ ë¢°ë„: {confidence}")
        return blink_detected, confidence
    
    def _detect_liveness(self, image: np.ndarray, face, check_blink: bool = False, frames: List[np.ndarray] = None) -> Tuple[bool, float]:
        """ì •êµí•œ Liveness Detection - PC í™”ë©´ ê°ì§€ ê°•í™”"""
        try:
            bbox = face.bbox.astype(int)
            # bbox í´ë¦¬í•‘
            bbox = self._clip_bbox(bbox, image.shape)
            x1, y1, x2, y2 = bbox
            face_img = image[y1:y2, x1:x2]
            
            # ë¹ˆ ì´ë¯¸ì§€ ì²´í¬
            if face_img.size == 0 or face_img.shape[0] == 0 or face_img.shape[1] == 0:
                logger.warning(f"_detect_liveness: ë¹ˆ ì–¼êµ´ ì´ë¯¸ì§€ ê°ì§€ shape={face_img.shape}")
                return False, 0.0
            
            # 0. í™”ë©´/ëª¨ë‹ˆí„° ê°ì§€ë¥¼ ìœ„í•œ ì¶”ê°€ ê²€ì‚¬
            # ëª¨ì•„ë ˆ íŒ¨í„´ ê²€ì¶œ
            gray = cv2.cvtColor(face_img, cv2.COLOR_BGR2GRAY)
            
            # í”½ì…€ ê²©ì íŒ¨í„´ ê²€ì¶œ (ëª¨ë‹ˆí„°ì˜ íŠ¹ì§•)
            # ê³ ì£¼íŒŒ í•„í„°ë§
            kernel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])
            kernel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])
            
            grad_x = cv2.filter2D(gray, cv2.CV_32F, kernel_x)
            grad_y = cv2.filter2D(gray, cv2.CV_32F, kernel_y)
            
            # ê²©ì íŒ¨í„´ ê°•ë„
            grid_pattern = np.abs(grad_x) + np.abs(grad_y)
            grid_score = np.std(grid_pattern) / (np.mean(grid_pattern) + 1e-7)
            
            # 1. í…ìŠ¤ì²˜ ë¶„ì„ (ì‹¤ì œ ì–¼êµ´ vs ì¸ì‡„ë¬¼/í™”ë©´)
            
            # LBP (Local Binary Pattern) íŠ¹ì§•
            def get_lbp_features(img):
                h, w = img.shape
                lbp = np.zeros_like(img)
                for i in range(1, h-1):
                    for j in range(1, w-1):
                        center = img[i, j]
                        code = 0
                        # 8ê°œ ì´ì›ƒ í”½ì…€ê³¼ ë¹„êµ
                        neighbors = [
                            img[i-1, j-1], img[i-1, j], img[i-1, j+1],
                            img[i, j+1], img[i+1, j+1], img[i+1, j],
                            img[i+1, j-1], img[i, j-1]
                        ]
                        for k, neighbor in enumerate(neighbors):
                            if neighbor > center:
                                code |= (1 << k)
                        lbp[i, j] = code
                return lbp
            
            lbp = get_lbp_features(gray)
            lbp_hist, _ = np.histogram(lbp.ravel(), bins=256, range=(0, 256))
            lbp_hist = lbp_hist.astype(float) / lbp_hist.sum()
            
            # ì‹¤ì œ ì–¼êµ´ì€ ë” ë‹¤ì–‘í•œ í…ìŠ¤ì²˜ íŒ¨í„´ì„ ê°€ì§
            texture_entropy = -np.sum(lbp_hist * np.log2(lbp_hist + 1e-7))
            texture_score = min(texture_entropy / 7.0, 1.0)  # ì—”íŠ¸ë¡œí”¼ ì •ê·œí™”
            
            # 2. ìƒ‰ìƒ ë¶„ì„ (í”¼ë¶€ìƒ‰ ë¶„í¬)
            # HSV ìƒ‰ê³µê°„ì—ì„œ í”¼ë¶€ìƒ‰ ë²”ìœ„ ê²€ì¶œ - ë” ë„“ì€ ë²”ìœ„ë¡œ ì¡°ì •
            hsv = cv2.cvtColor(face_img, cv2.COLOR_BGR2HSV)
            # ë” ë„“ì€ í”¼ë¶€ìƒ‰ ë²”ìœ„ (ë‹¤ì–‘í•œ í”¼ë¶€í†¤ í¬í•¨)
            lower_skin1 = np.array([0, 15, 60], dtype=np.uint8)
            upper_skin1 = np.array([25, 255, 255], dtype=np.uint8)
            lower_skin2 = np.array([170, 15, 60], dtype=np.uint8)  # ë¶‰ì€ìƒ‰ ê³„ì—´
            upper_skin2 = np.array([180, 255, 255], dtype=np.uint8)
            
            skin_mask1 = cv2.inRange(hsv, lower_skin1, upper_skin1)
            skin_mask2 = cv2.inRange(hsv, lower_skin2, upper_skin2)
            skin_mask = cv2.bitwise_or(skin_mask1, skin_mask2)
            skin_ratio = np.sum(skin_mask > 0) / skin_mask.size
            
            # 3. ì£¼íŒŒìˆ˜ ë¶„ì„ (ê³ ì£¼íŒŒ ì„±ë¶„) - ëª¨ë‹ˆí„° ê°ì§€ ê°•í™”
            # ì¸ì‡„ë¬¼ì´ë‚˜ í™”ë©´ì€ ëª¨ì•„ë ˆ íŒ¨í„´ì´ë‚˜ í”½ì…€ êµ¬ì¡°ë¥¼ ê°€ì§
            f_transform = np.fft.fft2(gray)
            f_shift = np.fft.fftshift(f_transform)
            magnitude_spectrum = np.abs(f_shift)
            
            # ê³ ì£¼íŒŒ ì„±ë¶„ ë¹„ìœ¨
            h, w = gray.shape
            center_h, center_w = h // 2, w // 2
            radius = min(h, w) // 4
            
            # ì¤‘ì‹¬ë¶€(ì €ì£¼íŒŒ)ì™€ ì™¸ê³½ë¶€(ê³ ì£¼íŒŒ) ë¶„ë¦¬
            y, x = np.ogrid[:h, :w]
            mask = (x - center_w)**2 + (y - center_h)**2 <= radius**2
            
            low_freq_sum = np.sum(magnitude_spectrum[mask])
            high_freq_sum = np.sum(magnitude_spectrum[~mask])
            freq_ratio = high_freq_sum / (low_freq_sum + high_freq_sum + 1e-7)
            
            # ëª¨ë‹ˆí„°ì˜ ì£¼ê¸°ì  íŒ¨í„´ ê°ì§€ (ìˆ˜í‰/ìˆ˜ì§ ë¼ì¸)
            # ì£¼íŒŒìˆ˜ ë„ë©”ì¸ì—ì„œ ìˆ˜í‰/ìˆ˜ì§ ì¶•ì˜ í”¼í¬ ê²€ì¶œ
            h_profile = np.mean(magnitude_spectrum, axis=0)
            v_profile = np.mean(magnitude_spectrum, axis=1)
            
            # ì£¼ê¸°ì  í”¼í¬ ê°ì§€
            h_peaks = len(np.where(h_profile > np.mean(h_profile) * 2)[0])
            v_peaks = len(np.where(v_profile > np.mean(v_profile) * 2)[0])
            periodic_pattern_score = (h_peaks + v_peaks) / (h + w) * 10
            
            # 4. ë°˜ì‚¬ê´‘ íŒ¨í„´ (í™”ë©´ì´ë‚˜ ì¸ì‡„ë¬¼ì˜ ê· ì¼í•œ ë°˜ì‚¬)
            # ë°ê¸° ë¶„í¬ì˜ í‘œì¤€í¸ì°¨
            brightness_std = np.std(gray)
            # ì‹¤ì œ ì–¼êµ´ì€ ë” ë‹¤ì–‘í•œ ë°ê¸° ë¶„í¬ë¥¼ ê°€ì§
            brightness_score = min(brightness_std / 50.0, 1.0)
            
            # 5. ì–¼êµ´ íŠ¹ì§•ì  ì›€ì§ì„ (ë‹¨ì¼ ì´ë¯¸ì§€ì—ì„œëŠ” ì œí•œì )
            # ëœë“œë§ˆí¬ ê°„ ê±°ë¦¬ì˜ ìì—°ìŠ¤ëŸ¬ì›€
            if face.kps is not None and len(face.kps) >= 5:
                landmarks = face.kps
                # ëˆˆ ì‚¬ì´ ê±°ë¦¬ì™€ ì½”-ì… ê±°ë¦¬ì˜ ë¹„ìœ¨
                eye_dist = np.linalg.norm(landmarks[0] - landmarks[1])
                nose_mouth_dist = np.linalg.norm(landmarks[2] - landmarks[3])
                ratio = nose_mouth_dist / (eye_dist + 1e-7)
                # ì¼ë°˜ì ì¸ ë¹„ìœ¨ ë²”ìœ„: 0.8 ~ 1.5
                ratio_score = 1.0 if 0.8 <= ratio <= 1.5 else 0.5
            else:
                ratio_score = 0.5
            
            # ì¢…í•© ì ìˆ˜ ê³„ì‚° - ì‹¤ì œ ì–¼êµ´ì— ë” ìœ ë¦¬í•˜ê²Œ ì¡°ì •
            liveness_score = (
                texture_score * 0.30 +      # í…ìŠ¤ì²˜ ì—”íŠ¸ë¡œí”¼ (ê°€ì¤‘ì¹˜ ì¦ê°€)
                skin_ratio * 0.25 +         # í”¼ë¶€ìƒ‰ ë¹„ìœ¨ (ê°€ì¤‘ì¹˜ ì¦ê°€)
                (1 - freq_ratio) * 0.15 +   # ì €ì£¼íŒŒ ìš°ì„¸ (ìì—°ìŠ¤ëŸ¬ìš´ ì–¼êµ´)
                brightness_score * 0.15 +    # ë°ê¸° ë³€í™”
                ratio_score * 0.10 +        # ì–¼êµ´ ë¹„ìœ¨
                (1 - min(grid_score * 0.7, 1.0)) * 0.05  # ê²©ì íŒ¨í„´ ì˜í–¥ ê°ì†Œ
            )
            
            # PC í™”ë©´ ê°ì§€ - ë” ê´€ëŒ€í•œ ì¡°ê±´ (ëª…í™•í•œ í™”ë©´ì¼ ë•Œë§Œ í˜ë„í‹°)
            if grid_score > 1.5 and periodic_pattern_score > 1.2:
                # ë§¤ìš° ê°•í•œ íŒ¨í„´ - í™•ì‹¤í•œ í™”ë©´
                liveness_score *= 0.3  # 70% í˜ë„í‹°
                logger.warning(f"PC í™”ë©´ í™•ì‹¤ - ê²©ì: {grid_score:.3f}, ì£¼ê¸°íŒ¨í„´: {periodic_pattern_score:.3f}")
            elif grid_score > 1.3 and periodic_pattern_score > 1.0:
                # ê°•í•œ íŒ¨í„´ - í™”ë©´ ê°€ëŠ¥ì„± ë†’ìŒ
                liveness_score *= 0.7  # 30% í˜ë„í‹°
                logger.info(f"PC í™”ë©´ ì˜ì‹¬ - ê²©ì: {grid_score:.3f}, ì£¼ê¸°íŒ¨í„´: {periodic_pattern_score:.3f}")
            
            # ë””ë²„ê¹… ë¡œê·¸
            logger.info(f"Liveness - í…ìŠ¤ì²˜: {texture_score:.3f}, í”¼ë¶€ìƒ‰: {skin_ratio:.3f}, "
                       f"ì£¼íŒŒìˆ˜: {1-freq_ratio:.3f}, ë°ê¸°: {brightness_score:.3f}, "
                       f"ë¹„ìœ¨: {ratio_score:.3f}, ê²©ì: {grid_score:.3f}, "
                       f"ì£¼ê¸°íŒ¨í„´: {periodic_pattern_score:.3f}, ìµœì¢…: {liveness_score:.3f}")
            
            # ëˆˆ ê¹œë¹¡ì„ ê²€ì‚¬ ì¶”ê°€ (ì˜µì…˜)
            blink_bonus = 0
            if check_blink and frames is not None and len(frames) >= 3:
                blink_detected, blink_confidence = self.detect_eye_blink(frames)
                if blink_detected:
                    blink_bonus = 0.2  # ëˆˆ ê¹œë¹¡ì„ ê°ì§€ ì‹œ ë³´ë„ˆìŠ¤
                    logger.info(f"ëˆˆ ê¹œë¹¡ì„ ê°ì§€ë¨! ë³´ë„ˆìŠ¤: {blink_bonus}")
                else:
                    liveness_score *= 0.8  # ëˆˆ ê¹œë¹¡ì„ ì—†ìœ¼ë©´ 20% í˜ë„í‹°
                    logger.warning("ëˆˆ ê¹œë¹¡ì„ ë¯¸ê°ì§€ - ë¼ì´ë¸Œë‹ˆìŠ¤ ì ìˆ˜ ê°ì†Œ")
            
            # ìµœì¢… ì ìˆ˜ ê³„ì‚°
            final_score = min(liveness_score + blink_bonus, 1.0)
            
            # ì„ê³„ê°’ ê¸°ë°˜ íŒë‹¨
            is_live = final_score > 0.40  # ì ì ˆí•œ ê· í˜•ì 
            
            logger.info(f"ìµœì¢… ë¼ì´ë¸Œë‹ˆìŠ¤ ì ìˆ˜: {final_score:.3f} (ì›ë˜: {liveness_score:.3f}, ê¹œë¹¡ì„ ë³´ë„ˆìŠ¤: {blink_bonus:.3f})")
            
            return is_live, final_score
            
        except Exception as e:
            logger.error(f"Liveness detection ì˜¤ë¥˜: {str(e)}")
            return True, 0.5  # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’
    
    def _detect_glasses_deprecated(self, image: np.ndarray, landmarks: np.ndarray) -> bool:
        """ê°œì„ ëœ ì•ˆê²½ ê°ì§€ (ëˆˆ ì£¼ë³€ ì—£ì§€ ê²€ì¶œ + ë°˜ì‚¬ê´‘ ê²€ì¶œ)"""
        if landmarks is None or len(landmarks) < 5:
            return False
        
        # ëˆˆ ì£¼ë³€ ì˜ì—­ ì¶”ì¶œ (ë” ë„“ì€ ì˜ì—­)
        left_eye = landmarks[0].astype(int)
        right_eye = landmarks[1].astype(int)
        
        # ëˆˆ ì‚¬ì´ ê±°ë¦¬ ê³„ì‚°
        eye_distance = np.linalg.norm(right_eye - left_eye)
        padding = int(eye_distance * 0.5)  # ëˆˆ ì‚¬ì´ ê±°ë¦¬ì˜ 50%ë¥¼ íŒ¨ë”©ìœ¼ë¡œ
        
        # ëˆˆ ì£¼ë³€ ì˜ì—­ (ì•ˆê²½í…Œê°€ ìˆì„ ìˆ˜ ìˆëŠ” ì˜ì—­)
        y_min = max(0, min(left_eye[1], right_eye[1]) - padding)
        y_max = min(image.shape[0], max(left_eye[1], right_eye[1]) + padding)
        x_min = max(0, left_eye[0] - padding)
        x_max = min(image.shape[1], right_eye[0] + padding)
        
        eye_region = image[y_min:y_max, x_min:x_max]
        
        if eye_region.size == 0 or eye_region.shape[0] == 0 or eye_region.shape[1] == 0:
            logger.warning(f"_detect_glasses_deprecated: ë¹ˆ ëˆˆ ì˜ì—­ ì´ë¯¸ì§€ ê°ì§€")
            return False
        
        # 1. ì—£ì§€ ê²€ì¶œ (ì•ˆê²½í…Œ ê°ì§€)
        gray = cv2.cvtColor(eye_region, cv2.COLOR_BGR2GRAY)
        
        # ì ì‘í˜• ì„ê³„ê°’ìœ¼ë¡œ ì—£ì§€ ê²€ì¶œ ê°œì„  - ë” ë†’ì€ ì„ê³„ê°’ìœ¼ë¡œ ì•½í•œ ì—£ì§€ ì œê±°
        edges = cv2.Canny(gray, 50, 150)  # ì„ê³„ê°’ ìƒí–¥ (30,100 -> 50,150)
        edge_density = np.sum(edges > 0) / edges.size
        
        # 2. ë°˜ì‚¬ê´‘ ê²€ì¶œ (ì•ˆê²½ ë Œì¦ˆì˜ ë°˜ì‚¬)
        # ë°ì€ í”½ì…€ ê²€ì¶œ - ë” ë†’ì€ ì„ê³„ê°’ìœ¼ë¡œ ì¼ë°˜ì ì¸ í”¼ë¶€ í•˜ì´ë¼ì´íŠ¸ ì œì™¸
        _, bright_pixels = cv2.threshold(gray, 220, 255, cv2.THRESH_BINARY)  # ì„ê³„ê°’ ìƒí–¥ (200 -> 220)
        bright_ratio = np.sum(bright_pixels > 0) / bright_pixels.size
        
        # PC í™”ë©´ì˜ ê· ì¼í•œ ë°˜ì‚¬ íŒ¨í„´ ê°ì§€
        # ë°˜ì‚¬ ì˜ì—­ì˜ ì—°ê²°ì„± ê²€ì‚¬ (í™”ë©´ì€ í° ì—°ê²°ëœ ë°ì€ ì˜ì—­ì„ ê°€ì§)
        num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(bright_pixels, connectivity=8)
        if num_labels > 1:
            # ê°€ì¥ í° ì—°ê²° ì˜ì—­ì˜ í¬ê¸°
            largest_component_size = np.max(stats[1:, cv2.CC_STAT_AREA]) if num_labels > 1 else 0
            uniform_reflection = largest_component_size / (bright_pixels.size + 1e-7)
        else:
            uniform_reflection = 0
        
        # 3. ìˆ˜í‰ì„  ê²€ì¶œ (ì•ˆê²½í…Œì˜ ìˆ˜í‰ì„ )
        # Hough ë³€í™˜ìœ¼ë¡œ ì§ì„  ê²€ì¶œ
        lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=20, minLineLength=30, maxLineGap=10)
        horizontal_lines = 0
        if lines is not None:
            for line in lines:
                x1, y1, x2, y2 = line[0]
                angle = abs(np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi)
                # ìˆ˜í‰ì„  (ê°ë„ê°€ 10ë„ ì´ë‚´)
                if angle < 10 or angle > 170:
                    horizontal_lines += 1
        
        # 4. ëŒ€ì¹­ì„± ê²€ì‚¬ (ì•ˆê²½ì€ ì¢Œìš° ëŒ€ì¹­)
        # ì¢Œìš° ëˆˆ ì˜ì—­ì˜ ì—£ì§€ íŒ¨í„´ ë¹„êµ
        eye_center_y = (left_eye[1] + right_eye[1]) // 2
        mid_x = (left_eye[0] + right_eye[0]) // 2
        
        left_region = edges[:, :mid_x - x_min]
        right_region = edges[:, mid_x - x_min:]
        
        # ì¢Œìš° ë°˜ì „ í›„ ìœ ì‚¬ë„ ê³„ì‚°
        if left_region.shape[1] > 0 and right_region.shape[1] > 0:
            # í¬ê¸° ë§ì¶”ê¸°
            min_width = min(left_region.shape[1], right_region.shape[1])
            left_region = left_region[:, -min_width:]
            right_region = right_region[:, :min_width]
            
            # ì¢Œì¸¡ ì˜ì—­ì„ ë°˜ì „
            left_flipped = np.fliplr(left_region)
            
            # ìœ ì‚¬ë„ ê³„ì‚°
            symmetry_score = np.sum(left_flipped == right_region) / (left_flipped.size + 1e-7)
        else:
            symmetry_score = 0
        
        # 5. ì½” ë‹¤ë¦¬ ë¶€ë¶„ ê²€ì‚¬ (ì•ˆê²½ì˜ íŠ¹ì§•ì ì¸ ë¶€ë¶„)
        # ë‘ ëˆˆ ì‚¬ì´, ì½” ìœ„ìª½ ì˜ì—­
        nose_bridge_y1 = eye_center_y - int(padding * 0.3)
        nose_bridge_y2 = eye_center_y + int(padding * 0.3)
        nose_bridge_x1 = left_eye[0] + int(eye_distance * 0.3)
        nose_bridge_x2 = right_eye[0] - int(eye_distance * 0.3)
        
        if (nose_bridge_y1 >= y_min and nose_bridge_y2 <= y_max and 
            nose_bridge_x1 >= x_min and nose_bridge_x2 <= x_max):
            
            nose_bridge_region = edges[
                nose_bridge_y1-y_min:nose_bridge_y2-y_min,
                nose_bridge_x1-x_min:nose_bridge_x2-x_min
            ]
            
            if nose_bridge_region.size > 0:
                nose_bridge_density = np.sum(nose_bridge_region > 0) / nose_bridge_region.size
            else:
                nose_bridge_density = 0
        else:
            nose_bridge_density = 0
        
        # ì¢…í•© íŒë‹¨ (ë” ì—„ê²©í•œ ê¸°ì¤€)
        glasses_features = {
            'edge_density': edge_density,
            'bright_ratio': bright_ratio,
            'horizontal_lines': horizontal_lines,
            'symmetry': symmetry_score,
            'nose_bridge': nose_bridge_density
        }
        
        # ì•ˆê²½ ì ìˆ˜ ê³„ì‚°
        glasses_score = 0
        
        # ì—£ì§€ ë°€ë„ (ì•ˆê²½í…Œ) - ë” ì—„ê²©í•œ ê¸°ì¤€
        if edge_density > 0.20:  # ì„ê³„ê°’ ëŒ€í­ ìƒí–¥ (0.15 -> 0.20)
            glasses_score += 0.25
        elif edge_density > 0.15:
            glasses_score += 0.10
            
        # ë°˜ì‚¬ê´‘ (ë Œì¦ˆ) - ë” ì—„ê²©í•œ ê¸°ì¤€
        if bright_ratio > 0.12:  # ì„ê³„ê°’ ëŒ€í­ ìƒí–¥ (0.08 -> 0.12)
            glasses_score += 0.15
        elif bright_ratio > 0.08:
            glasses_score += 0.05
            
        # ìˆ˜í‰ì„  (ì•ˆê²½í…Œ) - ìˆ˜í‰ì„  ê°œìˆ˜ì— ë” ë¯¼ê°í•˜ê²Œ
        if horizontal_lines >= 10:  # ë§ì€ ìˆ˜í‰ì„ ì€ ì•ˆê²½ì˜ ê°•í•œ ì‹ í˜¸
            glasses_score += 0.30
        elif horizontal_lines >= 5:
            glasses_score += 0.20
        elif horizontal_lines >= 3:
            glasses_score += 0.10
            
        # ëŒ€ì¹­ì„± (ì•ˆê²½ì˜ íŠ¹ì§•) - ë” ë†’ì€ ëŒ€ì¹­ì„± ìš”êµ¬
        if symmetry_score > 0.75:  # ì„ê³„ê°’ ìƒí–¥ (0.6 -> 0.75)
            glasses_score += 0.15
        elif symmetry_score > 0.65:
            glasses_score += 0.05
            
        # ì½” ë‹¤ë¦¬ ë¶€ë¶„ (ì•ˆê²½ì˜ íŠ¹ì§•) - ë” ëª…í™•í•œ ì½”ë‹¤ë¦¬ íŒ¨í„´ ìš”êµ¬
        if nose_bridge_density > 0.15:  # ì„ê³„ê°’ ìƒí–¥ (0.1 -> 0.15)
            glasses_score += 0.15
        elif nose_bridge_density > 0.10:
            glasses_score += 0.05
        
        # ë¡œê·¸ ì¶œë ¥
        logger.info(f"ì•ˆê²½ ê°ì§€ - ì—£ì§€: {edge_density:.3f}, ë°˜ì‚¬: {bright_ratio:.3f}, "
                   f"ìˆ˜í‰ì„ : {horizontal_lines}, ëŒ€ì¹­: {symmetry_score:.3f}, "
                   f"ì½”ë‹¤ë¦¬: {nose_bridge_density:.3f}, ì ìˆ˜: {glasses_score:.2f}")
        
        # ë” ì—„ê²©í•œ íŒë‹¨ (ì—¬ëŸ¬ íŠ¹ì§•ì´ ë™ì‹œì— ë‚˜íƒ€ë‚˜ì•¼ í•¨)
        # PC í™”ë©´ì˜ ê· ì¼í•œ ë°˜ì‚¬ëŠ” ì œì™¸
        is_screen_reflection = uniform_reflection > 0.3 and bright_ratio > 0.15
        
        is_glasses = glasses_score > 0.5 or (  # ì ìˆ˜ê°€ 0.5 ì´ìƒì´ê±°ë‚˜
            # ìˆ˜í‰ì„ ì´ ë§ìœ¼ë©´ ì•ˆê²½ìœ¼ë¡œ íŒë‹¨ (ë°˜ì‚¬ ì—†ëŠ” ì½”íŒ… ë Œì¦ˆ ëŒ€ì‘)
            (horizontal_lines >= 8 and symmetry_score > 0.7) or
            # ê¸°ì¡´ ì¡°ê±´ë“¤
            (edge_density > 0.15 and bright_ratio > 0.10 and horizontal_lines >= 2 and not is_screen_reflection) or
            (nose_bridge_density > 0.15 and horizontal_lines >= 5) or
            # ë†’ì€ ëŒ€ì¹­ì„±ê³¼ ì ë‹¹í•œ ì—£ì§€
            (symmetry_score > 0.8 and edge_density > 0.08 and horizontal_lines >= 5)
        ) and not is_screen_reflection
        
        if is_screen_reflection:
            logger.warning(f"PC í™”ë©´ ë°˜ì‚¬ ê°ì§€ - ê· ì¼ë°˜ì‚¬: {uniform_reflection:.3f}, ì•ˆê²½ìœ¼ë¡œ íŒë‹¨í•˜ì§€ ì•ŠìŒ")
        
        return is_glasses


def convert_numpy_types(obj):
    """NumPy íƒ€ì…ì„ Python ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜"""
    if isinstance(obj, np.bool_):
        return bool(obj)
    elif isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, dict):
        return {key: convert_numpy_types(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_numpy_types(item) for item in obj]
    return obj


class InsightFaceAPI:
    """Flask API ì„œë²„"""
    
    def __init__(self, face_service: InsightFaceService):
        self.face_service = face_service
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì •
        self.db_pool = None
        self.db_type = DB_TYPE
        
        try:
            if self.db_type == 'mssql':
                # MSSQLì€ ì»¤ë„¥ì…˜ í’€ì„ ì§ì ‘ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì—°ê²° í…ŒìŠ¤íŠ¸ë§Œ
                if pyodbc is None:
                    raise Exception("pyodbc not installed. Run: pip install pyodbc")
                
                # ì—°ê²° í…ŒìŠ¤íŠ¸
                test_conn = self.get_db_connection()
                test_cursor = test_conn.cursor()
                test_cursor.execute("SELECT 1")
                test_cursor.fetchone()
                test_cursor.close()
                test_conn.close()
                logger.info("âœ… MSSQL ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ")
            else:
                # MariaDB/MySQL ì»¤ë„¥ì…˜ í’€ ì‚¬ìš©
                self.db_pool = mysql.connector.pooling.MySQLConnectionPool(
                    pool_name="insightface_pool",
                    pool_size=10,
                    **DB_CONFIG
                )
                logger.info("âœ… MySQL/MariaDB ì»¤ë„¥ì…˜ í’€ ìƒì„± ì„±ê³µ")
                
                # ì—°ê²° í…ŒìŠ¤íŠ¸
                test_conn = self.get_db_connection()
                test_cursor = test_conn.cursor()
                test_cursor.execute("SELECT 1")
                test_cursor.fetchone()
                test_cursor.close()
                test_conn.close()
                logger.info("âœ… MySQL/MariaDB ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ")
            
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì • ì‹¤íŒ¨ ({self.db_type}): {e}")
            logger.error(f"âŒ DB_CONFIG: {DB_CONFIG}")
            self.db_pool = None
        
        # Flask ì•± ìƒì„±
        self.app = Flask(__name__)
        CORS(self.app, resources={r"/api/*": {"origins": "*"}})
        
        # ëª¨ë“  ìš”ì²­ì— ëŒ€í•´ IP ì²´í¬ (ë¯¸ë“¤ì›¨ì–´) - ì œê±°ë¨
        # check_ip_whitelist ë°ì½”ë ˆì´í„°ë¥¼ ëŒ€ì‹  ì‚¬ìš©í•©ë‹ˆë‹¤
        
        # IP ì ‘ê·¼ ì œì–´ ì„¤ì • ë¡œë“œ
        try:
            from config import Config
            if hasattr(Config, 'IP_ACCESS_CONTROL'):
                self.access_control_config = Config.IP_ACCESS_CONTROL
                logger.info(f"IP ì ‘ê·¼ ì œì–´ ëª¨ë“œ: {Config.IP_ACCESS_CONTROL.get('mode', 'open')}")
                if Config.IP_ACCESS_CONTROL.get('mode') == 'blacklist':
                    logger.info(f"ì°¨ë‹¨ IP ëª©ë¡: {Config.IP_ACCESS_CONTROL.get('blacklist_ips', [])}")
            else:
                # IP_ACCESS_CONTROL ì†ì„±ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
                self.access_control_config = {
                    'mode': 'open',  # ê¸°ë³¸ì ìœ¼ë¡œ ëª¨ë‘ í—ˆìš©
                    'blacklist_ips': [],
                    'internal_ranges': ['192.168.0.0/16', '172.16.0.0/12', '10.0.0.0/8', '127.0.0.1']
                }
                logger.info("IP ì ‘ê·¼ ì œì–´ ì„¤ì • ì—†ìŒ - ê¸°ë³¸ê°’ ì‚¬ìš© (ëª¨ë‘ í—ˆìš©)")
        except ImportError:
            # config.pyê°€ ì—†ìœ¼ë©´ ëª¨ë‘ í—ˆìš©
            self.access_control_config = {
                'mode': 'open',
                'blacklist_ips': [],
                'internal_ranges': ['192.168.0.0/16', '172.16.0.0/12', '10.0.0.0/8', '127.0.0.1']
            }
            logger.info("config.py ì—†ìŒ - IP ì ‘ê·¼ ì œì–´ ë¹„í™œì„±í™” (ëª¨ë‘ í—ˆìš©)")
        
        # ë¼ìš°íŠ¸ ë“±ë¡
        self._register_routes()
    
    def check_ip_whitelist(self, f):
        """IP ì ‘ê·¼ ì œì–´ ë°ì½”ë ˆì´í„° (ë¸”ë™ë¦¬ìŠ¤íŠ¸ ë°©ì‹)"""
        @wraps(f)
        def decorated_function(*args, **kwargs):
            # ì ‘ê·¼ ì œì–´ ëª¨ë“œ í™•ì¸
            access_mode = self.access_control_config.get('mode', 'open')
            
            # open ëª¨ë“œë©´ ëª¨ë“  ì ‘ì† í—ˆìš©
            if access_mode == 'open':
                return f(*args, **kwargs)
            
            # í´ë¼ì´ì–¸íŠ¸ IP ê°€ì ¸ì˜¤ê¸°
            client_ip = request.remote_addr
            if request.headers.get('X-Forwarded-For'):
                client_ip = request.headers.get('X-Forwarded-For').split(',')[0].strip()
            
            logger.info(f"[IP_CHECK] ì ‘ì† IP: {client_ip} (ëª¨ë“œ: {access_mode})")
            
            # ë¡œì»¬í˜¸ìŠ¤íŠ¸ëŠ” í•­ìƒ í—ˆìš©
            if client_ip in ['127.0.0.1', '::1']:
                logger.info(f"[IP_CHECK] ë¡œì»¬í˜¸ìŠ¤íŠ¸ ì ‘ì† í—ˆìš©: {client_ip}")
                return f(*args, **kwargs)
            
            try:
                client_ip_obj = ipaddress.ip_address(client_ip)
                
                # ë‚´ë¶€ë§ IP ëŒ€ì—­ ì²´í¬ (ë¸”ë™ë¦¬ìŠ¤íŠ¸ì—ì„œë„ ë‚´ë¶€ë§ì€ í•­ìƒ í—ˆìš©)
                for internal_range in self.access_control_config.get('internal_ranges', []):
                    if client_ip_obj in ipaddress.ip_network(internal_range):
                        logger.info(f"[IP_CHECK] ë‚´ë¶€ë§ ì ‘ì† í—ˆìš©: {client_ip} (ëŒ€ì—­: {internal_range})")
                        return f(*args, **kwargs)
                
                # ë¸”ë™ë¦¬ìŠ¤íŠ¸ ëª¨ë“œì¼ ë•Œ ì°¨ë‹¨ IP ì²´í¬
                if access_mode == 'blacklist':
                    blacklist_ips = self.access_control_config.get('blacklist_ips', [])
                    if blacklist_ips:
                        # ë¹ˆ ë¬¸ìì—´ ì œê±° ë° ê³µë°± ì œê±°
                        blacklist_ips = [ip.strip() for ip in blacklist_ips if ip.strip()]
                        if client_ip in blacklist_ips:
                            logger.warning(f"[IP_CHECK] ì ‘ì† ì°¨ë‹¨: {client_ip} (ë¸”ë™ë¦¬ìŠ¤íŠ¸)")
                            abort(403, description=f"Access denied from IP: {client_ip}")
                    
                    # ë¸”ë™ë¦¬ìŠ¤íŠ¸ì— ì—†ìœ¼ë©´ í—ˆìš©
                    logger.info(f"[IP_CHECK] ì ‘ì† í—ˆìš©: {client_ip}")
                    return f(*args, **kwargs)
                
                # ì•Œ ìˆ˜ ì—†ëŠ” ëª¨ë“œ
                logger.error(f"[IP_CHECK] ì•Œ ìˆ˜ ì—†ëŠ” ì ‘ê·¼ ì œì–´ ëª¨ë“œ: {access_mode}")
                return f(*args, **kwargs)
                
            except ValueError as e:
                logger.error(f"[IP_CHECK] IP ì£¼ì†Œ íŒŒì‹± ì˜¤ë¥˜: {client_ip} - {e}")
                abort(400, description="Invalid IP address")
        
        return decorated_function
    
    def _row_to_dict(self, cursor, row):
        """MSSQL rowë¥¼ dictionaryë¡œ ë³€í™˜"""
        if row is None:
            return None
        columns = [column[0] for column in cursor.description]
        return dict(zip(columns, row))
    
    def _rows_to_dict(self, cursor, rows):
        """MSSQL rowsë¥¼ dictionary listë¡œ ë³€í™˜"""
        if not rows:
            return []
        columns = [column[0] for column in cursor.description]
        return [dict(zip(columns, row)) for row in rows]
    
    def get_db_connection(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ê°€ì ¸ì˜¤ê¸°"""
        try:
            if self.db_type == 'mssql':
                # MSSQL ì—°ê²°
                conn_str = (
                    f"DRIVER={{{DB_CONFIG['driver']}}};"
                    f"SERVER={DB_CONFIG['server']},{DB_CONFIG['port']};"
                    f"DATABASE={DB_CONFIG['database']};"
                    f"UID={DB_CONFIG['username']};"
                    f"PWD={DB_CONFIG['password']};"
                    f"Encrypt={DB_CONFIG['encrypt']};"
                    f"TrustServerCertificate={DB_CONFIG['trust_server_certificate']};"
                    f"Connection Timeout={DB_CONFIG['timeout']};"
                )
                connection = pyodbc.connect(conn_str)
                logger.info("[DB] MSSQL ì—°ê²° ìƒì„±")
                return connection
            else:
                # MariaDB/MySQL ì—°ê²°
                if self.db_pool:
                    connection = self.db_pool.get_connection()
                    logger.info("[DB] ì»¤ë„¥ì…˜ í’€ì—ì„œ ì—°ê²° íšë“")
                    return connection
                else:
                    logger.info("[DB] ì§ì ‘ ì—°ê²° ìƒì„±")
                    connection = mysql.connector.connect(**DB_CONFIG)
                    return connection
        except Exception as e:
            logger.error(f"[DB] ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨ ({self.db_type}): {e}")
            raise
    
    def _register_routes(self):
        """API ì—”ë“œí¬ì¸íŠ¸ ë“±ë¡"""
        
        @self.app.route('/api/face/health', methods=['GET'])
        @self.check_ip_whitelist
        def health_check():
            """í—¬ìŠ¤ ì²´í¬"""
            return jsonify({
                'status': 'healthy',
                'service': 'InsightFace Recognition Service',
                'version': '1.0.0',
                'model': 'buffalo_l',
                'embedding_dimension': 512
            })
        
        @self.app.route('/api/face/register', methods=['POST'])
        @self.check_ip_whitelist
        def register_face():
            """ì–¼êµ´ ë“±ë¡"""
            try:
                # FormDataì™€ JSON ëª¨ë‘ ì§€ì›
                if request.content_type and 'multipart/form-data' in request.content_type:
                    # FormData ì²˜ë¦¬
                    mem_sno = request.form.get('mem_sno')
                    param1 = request.form.get('param1') or request.form.get('comp_cd')
                    param2 = request.form.get('param2') or request.form.get('bcoff_cd')
                    if 'image' in request.files:
                        image_file = request.files['image']
                        image_data = base64.b64encode(image_file.read()).decode('utf-8')
                    else:
                        return jsonify({
                            'success': False,
                            'error': 'No image file provided'
                        }), 400
                else:
                    # JSON ì²˜ë¦¬
                    data = request.get_json()
                    mem_sno = data.get('mem_sno') or data.get('member_id')  # í•˜ìœ„ í˜¸í™˜ì„±
                    image_data = data.get('image')
                    # íŒŒë¼ë¯¸í„° ì¶”ê°€
                    param1 = data.get('param1') or data.get('comp_cd')  # comp_cdì™€ í˜¸í™˜
                    param2 = data.get('param2') or data.get('bcoff_cd')  # bcoff_cdì™€ í˜¸í™˜
                
                if not mem_sno or not image_data:
                    return jsonify({
                        'success': False,
                        'error': 'Missing required fields (mem_sno and image)'
                    }), 400
                
                # ì´ë¯¸ì§€ ë””ì½”ë”©
                image = self._decode_image(image_data)
                
                # ì„ë² ë”© ì¶”ì¶œ
                start_time = datetime.datetime.now()
                result = self.face_service.extract_embedding(image)
                processing_time = (datetime.datetime.now() - start_time).total_seconds() * 1000
                result['processing_time_ms'] = processing_time
                
                # ì–¼êµ´ì´ ê²€ì¶œëœ ê²½ìš° liveness detection ìˆ˜í–‰
                liveness_passed = False
                liveness_score = 0.0
                if result['success']:
                    # ì–¼êµ´ ì¬ê²€ì¶œ (liveness detectionì„ ìœ„í•´)
                    faces = self.face_service.app.get(image)
                    if faces:
                        liveness_passed, liveness_score = self.face_service._detect_liveness(image, faces[0])
                        liveness_passed = bool(liveness_passed)  # NumPy boolì„ Python boolë¡œ ë³€í™˜
                        liveness_score = float(liveness_score)
                
                if not result['success']:
                    return jsonify(result), 400
                
                # notes ìƒì„±
                notes = f"InsightFace ë“±ë¡ - Quality: {result.get('quality_score', 0):.2f}, " \
                       f"Liveness: {liveness_score:.2f}"
                
                # ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ (liveness_score, glasses_confidence í¬í•¨)
                result['liveness_score'] = liveness_score
                result['glasses_confidence'] = 0.0  # ì•ˆê²½ ê°ì§€ ì‚¬ìš© ì•ˆí•¨
                save_result = self._save_face_to_db(mem_sno, result, param1, param2)
                
                # enhanced_face_serviceì™€ ë™ì¼í•œ ì‘ë‹µ í˜•ì‹
                return jsonify({
                    'success': result['success'] and save_result['db_success'],
                    'face_detected': result['success'],
                    'face_encoding': result['embedding'],
                    'quality_score': result.get('quality_score', 0),
                    'glasses_detected': False,  # ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
                    'glasses_confidence': 0.0,  # ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
                    'liveness_score': liveness_score,
                    'liveness_check': {
                        'is_live': liveness_passed,
                        'confidence': liveness_score,
                        'details': {
                            'method': 'InsightFace Advanced Liveness Detection',
                            'note': 'Multi-factor liveness analysis (texture, frequency, color)'
                        }
                    },
                    'security_warnings': [] if liveness_passed else ['Liveness check failed'],
                    'processing_time_ms': processing_time,
                    'db_message': save_result.get('message', ''),
                    'member_id': mem_sno,
                    'face_attributes': {
                        'age': result.get('age', 0),
                        'gender': result.get('gender', 'unknown')
                    },
                    'notes': notes,
                    'error': save_result.get('db_error') if not save_result['db_success'] else None
                })
                
            except Exception as e:
                logger.error(f"ë“±ë¡ ì˜¤ë¥˜: {str(e)}")
                return jsonify({
                    'success': False,
                    'error': str(e)
                }), 500
        
        @self.app.route('/api/face/recognize', methods=['POST'])
        @self.check_ip_whitelist
        def recognize_face():
            """ì–¼êµ´ ì¸ì‹"""
            try:
                # ìƒì„¸ ë¡œê¹… ì¶”ê°€
                logger.info("=" * 60)
                logger.info(f"[RECOGNIZE] API í˜¸ì¶œ ì‹œì‘")
                logger.info(f"[RECOGNIZE] Content-Type: {request.content_type}")
                logger.info(f"[RECOGNIZE] Method: {request.method}")
                
                # FormDataì™€ JSON ëª¨ë‘ ì§€ì›
                if request.content_type and 'multipart/form-data' in request.content_type:
                    logger.info(f"[RECOGNIZE] FormData ì²˜ë¦¬")
                    # FormData ì²˜ë¦¬
                    param1 = request.form.get('param1') or request.form.get('comp_cd')
                    param2 = request.form.get('param2') or request.form.get('bcoff_cd')
                    if 'image' in request.files:
                        image_file = request.files['image']
                        logger.info(f"[RECOGNIZE] ì´ë¯¸ì§€ íŒŒì¼: {image_file.filename}")
                        image_data = base64.b64encode(image_file.read()).decode('utf-8')
                        logger.info(f"[RECOGNIZE] Base64 ì¸ì½”ë”© ì™„ë£Œ: {len(image_data)} chars")
                    else:
                        logger.error(f"[RECOGNIZE] ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ")
                        return jsonify({
                            'success': False,
                            'error': 'No image file provided'
                        }), 400
                else:
                    logger.info(f"[RECOGNIZE] JSON ì²˜ë¦¬")
                    # JSON ì²˜ë¦¬
                    raw_data = request.get_data(as_text=True)
                    logger.info(f"[RECOGNIZE] Raw body length: {len(raw_data)} chars")
                    
                    data = request.get_json()
                    if data:
                        logger.info(f"[RECOGNIZE] JSON keys: {list(data.keys())}")
                        image_data = data.get('image')
                        param1 = data.get('param1') or data.get('comp_cd')
                        param2 = data.get('param2') or data.get('bcoff_cd')
                        if image_data:
                            logger.info(f"[RECOGNIZE] image í•„ë“œ ê¸¸ì´: {len(image_data)} chars")
                    else:
                        logger.error(f"[RECOGNIZE] JSON íŒŒì‹± ì‹¤íŒ¨")
                        image_data = None
                
                if not image_data:
                    logger.error(f"[RECOGNIZE] ì´ë¯¸ì§€ ë°ì´í„° ì—†ìŒ - Missing image data")
                    return jsonify({
                        'success': False,
                        'error': 'Missing image data'
                    }), 400
                
                # ì´ë¯¸ì§€ ë””ì½”ë”©
                image = self._decode_image(image_data)
                
                # ì„ë² ë”© ì¶”ì¶œ
                start_time = datetime.datetime.now()
                result = self.face_service.extract_embedding(image)
                processing_time = (datetime.datetime.now() - start_time).total_seconds() * 1000
                
                if not result['success']:
                    return jsonify(result), 400
                
                # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë§¤ì¹­ (ì•ˆê²½ ì •ë³´ ì œê±°)
                match_result = self._find_best_match(
                    result['embedding'], 
                    False,  # ì•ˆê²½ ê°ì§€ ì‚¬ìš© ì•ˆí•¨
                    param1=param1,
                    param2=param2
                )
                
                # ì²˜ë¦¬ ì‹œê°„ ì—…ë°ì´íŠ¸
                match_result['processing_time_ms'] = processing_time
                
                # ì¸ì‹ ë¡œê·¸ ì €ì¥
                if match_result.get('match_found'):
                    log_data = {
                        'mem_sno': match_result['member']['mem_sno'],
                        'confidence_score': match_result['similarity'],
                        'similarity_score': match_result['similarity'],
                        'quality_score': result.get('quality_score', 0.85),
                        'glasses_detected': False,
                        'match_category': 'recognition',
                        'success': True,
                        'processing_time_ms': processing_time,
                        'param1': param1,
                        'param2': param2
                    }
                    self._save_recognition_log(log_data)
                
                # enhanced_face_serviceì™€ ë™ì¼í•œ ì‘ë‹µ í˜•ì‹
                response = {
                    'success': True,
                    'face_detected': True,
                    'quality_score': result.get('quality_score', 0),
                    'glasses_detection': {
                        'has_glasses': False,  # í•­ìƒ False
                        'confidence': 0.0      # ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
                    },
                    'processing_time_ms': processing_time,
                    'security_details': {
                        'quality_score': result.get('quality_score', 0),
                        'liveness_score': 0.95,  # InsightFaceëŠ” ë†’ì€ ì‹ ë¢°ë„
                        'all_checks_passed': True
                    }
                }
                
                if match_result.get('match_found'):
                    response.update({
                        'face_matching': {
                            'match_found': True,
                            'similarity_score': match_result['similarity'],
                            'member': {
                                'mem_sno': match_result['member']['mem_sno'],
                                'match_type': match_result.get('match_type', 'insightface')
                            }
                        },
                        'confidence_score': match_result['similarity']
                    })
                else:
                    response.update({
                        'face_matching': {
                            'match_found': False,
                            'similarity_score': 0,
                            'error': 'No matching face found'
                        },
                        'confidence_score': 0
                    })
                
                return jsonify(response)
                
            except Exception as e:
                logger.error(f"ì¸ì‹ ì˜¤ë¥˜: {str(e)}")
                return jsonify({
                    'success': False,
                    'error': str(e)
                }), 500
                if request.content_type and 'multipart/form-data' in request.content_type:
                    # FormData ì²˜ë¦¬
                    if 'image' in request.files:
                        image_file = request.files['image']
                        image_data = base64.b64encode(image_file.read()).decode('utf-8')
                    else:
                        return jsonify({
                            'success': False,
                            'error': 'No image file provided'
                        }), 400
                else:
                    # JSON ì²˜ë¦¬ (ì—ëŸ¬ ì²˜ë¦¬ í¬í•¨)
                    import json
                    raw_data = None
                    data = None
                    image_data = None
                    
                    try:
                        # raw ë°ì´í„°ë¥¼ ë¨¼ì € ë°›ì•„ì„œ ì§ì ‘ íŒŒì‹± (Flaskì˜ BadRequest ì˜ˆì™¸ ë°©ì§€)
                        raw_data = request.get_data(as_text=True)
                        logger.info(f"Raw request data (first 100 chars): {raw_data[:100] if raw_data else 'Empty'}")
                        
                        if not raw_data:
                            raise ValueError("ë¹ˆ ìš”ì²­ ë°ì´í„°")
                        
                        # JSON íŒŒì‹± ì‹œë„ (ìë™ ìˆ˜ì • ì—†ì´ ì—„ê²©í•˜ê²Œ ì²˜ë¦¬)
                        try:
                            # ì¼ë°˜ íŒŒì‹±ë§Œ ì‹œë„ (ì¤„ë°”ê¿ˆì´ ìˆìœ¼ë©´ ì‹¤íŒ¨í•˜ë„ë¡)
                            data = json.loads(raw_data)
                        except json.JSONDecodeError as e:
                            # ì¤„ë°”ê¿ˆ ê²€ì‚¬
                            if '\n' in raw_data or '\r' in raw_data:
                                logger.warning(f"JSONì— ì¤„ë°”ê¿ˆ ë¬¸ì í¬í•¨ - ìë™ ìˆ˜ì •í•˜ì§€ ì•Šê³  ê±°ë¶€")
                                raise json.JSONDecodeError(
                                    "JSON ë¬¸ìì—´ì— ì¤„ë°”ê¿ˆì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. base64 ë°ì´í„°ëŠ” ì¤„ë°”ê¿ˆ ì—†ì´ í•œ ì¤„ë¡œ ì „ì†¡í•´ì•¼ í•©ë‹ˆë‹¤.", 
                                    raw_data, 
                                    e.pos
                                )
                            else:
                                raise  # ë‹¤ë¥¸ JSON ì˜¤ë¥˜ëŠ” ê·¸ëŒ€ë¡œ ì „ë‹¬
                        
                        # image ë°ì´í„° ì¶”ì¶œ ë° ê²€ì¦
                        image_data = data.get('image') if data else None
                        if image_data:
                            # base64 ë°ì´í„°ì— ì¤„ë°”ê¿ˆì´ ìˆëŠ”ì§€ ê²€ì‚¬
                            if '\n' in image_data or '\r' in image_data:
                                raise ValueError("base64 ì´ë¯¸ì§€ ë°ì´í„°ì— ì¤„ë°”ê¿ˆì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì¤„ë°”ê¿ˆ ì—†ì´ í•œ ì¤„ë¡œ ì „ì†¡í•´ì£¼ì„¸ìš”.")
                            # ê³µë°±ë„ base64ì—ì„œëŠ” ìœ íš¨í•˜ì§€ ì•ŠìŒ
                            if ' ' in image_data:
                                raise ValueError("base64 ì´ë¯¸ì§€ ë°ì´í„°ì— ê³µë°±ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê³µë°± ì—†ì´ ì „ì†¡í•´ì£¼ì„¸ìš”.")
                    except Exception as json_error:
                        logger.error(f"JSON íŒŒì‹± ì‹¤íŒ¨: {str(json_error)}")
                        logger.error(f"Raw data length: {len(raw_data) if 'raw_data' in locals() else 'Unknown'}")
                        
                        # êµ¬ì²´ì ì¸ ì—ëŸ¬ ë©”ì‹œì§€ ìƒì„±
                        error_detail = str(json_error)
                        data_size = len(raw_data) if 'raw_data' in locals() else 0
                        
                        if 'Unterminated string' in error_detail or 'ì¤„ë°”ê¿ˆì´ í¬í•¨' in error_detail:
                            specific_error = 'JSON ë¬¸ìì—´ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. base64 ì´ë¯¸ì§€ ë°ì´í„°ì— ì¤„ë°”ê¿ˆì´ë‚˜ ê³µë°±ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.'
                            hint = 'base64 ë°ì´í„°ëŠ” ì¤„ë°”ê¿ˆê³¼ ê³µë°± ì—†ì´ í•œ ì¤„ë¡œ ì „ì†¡í•´ì•¼ í•©ë‹ˆë‹¤. btoa() ë˜ëŠ” base64 ì¸ì½”ë”© í›„ replace(/\\s/g, "")ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.'
                        elif 'Expecting value' in error_detail:
                            specific_error = 'JSON í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. ë¹ˆ ê°’ì´ë‚˜ ì˜ëª»ëœ êµ¬ì¡°ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.'
                            hint = '{"image": "base64_data"} í˜•ì‹ìœ¼ë¡œ ì „ì†¡í•˜ì„¸ìš”.'
                        elif 'Extra data' in error_detail:
                            specific_error = 'JSON ë°ì´í„° ë’¤ì— ì¶”ê°€ ë¬¸ìê°€ ìˆìŠµë‹ˆë‹¤.'
                            hint = 'JSON ê°ì²´ê°€ í•˜ë‚˜ë§Œ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.'
                        elif 'Invalid control character' in error_detail:
                            specific_error = 'JSONì— í—ˆìš©ë˜ì§€ ì•ŠëŠ” ì œì–´ ë¬¸ìê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.'
                            hint = 'íŠ¹ìˆ˜ ë¬¸ìë¥¼ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬í•˜ì„¸ìš”.'
                        elif data_size > 10 * 1024 * 1024:  # 10MB ì´ìƒ
                            specific_error = f'ìš”ì²­ ë°ì´í„°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤ ({data_size:,} bytes). ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ì¤„ì—¬ì£¼ì„¸ìš”.'
                            hint = 'ì´ë¯¸ì§€ë¥¼ ì••ì¶•í•˜ê±°ë‚˜ í•´ìƒë„ë¥¼ ë‚®ì¶°ì£¼ì„¸ìš”.'
                        else:
                            specific_error = f'JSON íŒŒì‹± ì˜¤ë¥˜: {error_detail}'
                            hint = 'JSON í˜•ì‹ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”.'
                        
                        # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ìƒì„¸ ì‘ë‹µ
                        return jsonify({
                            'success': False,
                            'face_detected': False,
                            'error': specific_error,
                            'error_type': 'JSON_PARSE_ERROR',
                            'hint': hint,
                            'request_size': data_size,
                            'technical_detail': error_detail if logger.level <= 10 else None,  # DEBUG ëª¨ë“œì—ì„œë§Œ
                            'face_encoding': [],
                            'glasses_detected': False,
                            'glasses_confidence': 0.0,
                            'quality_score': 0.0,
                            'liveness_score': 0.0,
                            'liveness_check': {
                                'is_live': False,
                                'confidence': 0.0,
                                'details': {
                                    'method': 'InsightFace',
                                    'note': 'Request parsing failed'
                                }
                            },
                            'security_warnings': ['Invalid request format'],
                            'glasses_details': {
                                'detected': False,
                                'confidence': 0.0
                            },
                            'processing_time_ms': 0,
                            'face_attributes': {
                                'age': 0,
                                'gender': 'unknown'
                            },
                            'suitable_for_registration': False,
                            'recommendations': ['ìš”ì²­ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.']
                        }), 400
                
                if not image_data:
                    return jsonify({
                        'success': False,
                        'error': 'Missing image data'
                    }), 400
                
                # ì´ë¯¸ì§€ ë””ì½”ë”© (ì—ëŸ¬ ì²˜ë¦¬ í¬í•¨)
                try:
                    image = self._decode_image(image_data)
                except Exception as decode_error:
                    logger.warning(f"ì´ë¯¸ì§€ ë””ì½”ë”© ì‹¤íŒ¨: {str(decode_error)}")
                    return jsonify({
                        'success': False,
                        'face_detected': False,
                        'error': 'ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìœ íš¨í•œ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.',
                        'face_encoding': [],
                        'glasses_detected': False,
                        'glasses_confidence': 0.0,
                        'quality_score': 0.0,
                        'liveness_score': 0.0,
                        'liveness_check': {
                            'is_live': False,
                            'confidence': 0.0,
                            'details': {
                                'method': 'InsightFace',
                                'note': 'Image decoding failed'
                            }
                        },
                        'security_warnings': ['Invalid image format'],
                        'glasses_details': {
                            'detected': False,
                            'confidence': 0.0
                        },
                        'processing_time_ms': 0,
                        'face_attributes': {
                            'age': 0,
                            'gender': 'unknown'
                        },
                        'suitable_for_registration': False,
                        'recommendations': ['ìœ íš¨í•œ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.']
                    }), 400
                
                # ì„ë² ë”© ì¶”ì¶œ
                start_time = datetime.datetime.now()
                result = self.face_service.extract_embedding(image)
                processing_time = (datetime.datetime.now() - start_time).total_seconds() * 1000
                
                # ì–¼êµ´ì´ ê²€ì¶œëœ ê²½ìš° liveness detection ìˆ˜í–‰
                liveness_passed = False
                liveness_score = 0.0
                quality_result = None
                if result['success']:
                    # ì–¼êµ´ ì¬ê²€ì¶œ (liveness detectionì„ ìœ„í•´)
                    faces = self.face_service.app.get(image)
                    if faces:
                        liveness_passed, liveness_score = self.face_service._detect_liveness(image, faces[0])
                        liveness_passed = bool(liveness_passed)  # NumPy boolì„ Python boolë¡œ ë³€í™˜
                        liveness_score = float(liveness_score)
                        
                        # í–¥ìƒëœ í’ˆì§ˆ í‰ê°€
                        quality_result = self.face_service._evaluate_quality_enhanced(image, faces[0])
                
                if not result['success']:
                    # ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•Šì•„ë„ ëª¨ë“  í•„ìˆ˜ í•„ë“œ í¬í•¨
                    return jsonify({
                        'success': False,
                        'face_detected': False,
                        'error': result.get('error', 'Face detection failed'),
                        'face_encoding': [],
                        'glasses_detected': False,  # ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
                        'glasses_confidence': 0.0,   # ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
                        'quality_score': 0.0,
                        'liveness_score': 0.0,
                        'liveness_check': {
                            'is_live': False,
                            'confidence': 0.0,
                            'details': {
                                'method': 'InsightFace',
                                'note': 'No face detected'
                            }
                        },
                        'security_warnings': ['No face detected'],
                        'glasses_details': {
                            'detected': False,     # ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
                            'confidence': 0.0      # ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
                        },
                        'processing_time_ms': processing_time,
                        'face_attributes': {
                            'age': 0,
                            'gender': 'unknown'
                        },
                        'suitable_for_registration': False,
                        'recommendations': ['ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì¹´ë©”ë¼ë¥¼ ì •ë©´ìœ¼ë¡œ ë°”ë¼ë´ì£¼ì„¸ìš”.']
                    }), 400
                
                # ë“±ë¡ ì í•©ì„± íŒë‹¨
                suitable_for_registration = True
                recommendations = []
                
                if quality_result:
                    # ê²€ì¶œ ì‹ ë¢°ë„ ì²´í¬
                    if quality_result['detection_confidence'] < 0.8:
                        suitable_for_registration = False
                        recommendations.append('ì–¼êµ´ì´ ëª…í™•í•˜ê²Œ ë³´ì´ì§€ ì•ŠìŠµë‹ˆë‹¤. ì¡°ëª…ì„ ë°ê²Œ í•´ì£¼ì„¸ìš”.')
                    
                    # ì–¼êµ´ í¬ê¸° ì²´í¬ (15%~70%ë¡œ ë²”ìœ„ í™•ëŒ€)
                    face_size_ratio = quality_result['position_info']['face_size_ratio']
                    if face_size_ratio < 0.15:
                        suitable_for_registration = False
                        recommendations.append('ì¹´ë©”ë¼ì— ë” ê°€ê¹Œì´ ì™€ì£¼ì„¸ìš”.')
                    elif face_size_ratio > 0.7:
                        suitable_for_registration = False
                        recommendations.append('ì¡°ê¸ˆ ë’¤ë¡œ ë¬¼ëŸ¬ë‚˜ì£¼ì„¸ìš”.')
                    
                    # ì–¼êµ´ ìœ„ì¹˜ ì²´í¬
                    if not quality_result['position_info']['is_centered']:
                        suitable_for_registration = False
                        recommendations.append('ì–¼êµ´ì„ í™”ë©´ ì¤‘ì•™ì— ë§ì¶°ì£¼ì„¸ìš”.')
                    
                    # ì–¼êµ´ ê°ë„ ì²´í¬
                    pose_info = quality_result['pose_info']
                    if not pose_info['is_frontal']:
                        if abs(pose_info['yaw']) > 15:
                            recommendations.append('ì •ë©´ì„ ë°”ë¼ë´ì£¼ì„¸ìš”.')
                        if abs(pose_info['pitch']) > 15:
                            if pose_info['pitch'] > 0:
                                recommendations.append('ê³ ê°œë¥¼ ì¡°ê¸ˆ ë‚´ë ¤ì£¼ì„¸ìš”.')  # ìœ„ë¥¼ ë³´ê³  ìˆìŒ
                            else:
                                recommendations.append('ê³ ê°œë¥¼ ì¡°ê¸ˆ ë“¤ì–´ì£¼ì„¸ìš”.')  # ì•„ë˜ë¥¼ ë³´ê³  ìˆìŒ
                        if abs(pose_info['roll']) > 10:
                            recommendations.append('ê³ ê°œë¥¼ ë˜‘ë°”ë¡œ ì„¸ì›Œì£¼ì„¸ìš”.')
                        suitable_for_registration = False
                    
                    # ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ì²´í¬
                    if quality_result['overall_score'] < 0.7:
                        suitable_for_registration = False
                        if not recommendations:  # ë‹¤ë¥¸ êµ¬ì²´ì ì¸ ë¬¸ì œê°€ ì—†ìœ¼ë©´
                            recommendations.append('ì´ë¯¸ì§€ í’ˆì§ˆì´ ë‚®ìŠµë‹ˆë‹¤. ë” ë‚˜ì€ ì¡°ëª…ì—ì„œ ë‹¤ì‹œ ì´¬ì˜í•´ì£¼ì„¸ìš”.')
                
                # enhanced_face_serviceì™€ ì™„ì „íˆ ë™ì¼í•œ ì‘ë‹µ í˜•ì‹
                response_data = {
                    'success': True,
                    'face_detected': True,
                    'face_encoding': result['embedding'],
                    'glasses_detected': False,  # ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
                    'glasses_confidence': 0.0,  # ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
                    'quality_score': result.get('quality_score', 0),
                    'liveness_score': liveness_score,
                    'liveness_check': {
                        'is_live': liveness_passed,
                        'confidence': liveness_score,
                        'details': {
                            'method': 'InsightFace Advanced Liveness Detection',
                            'note': 'Multi-factor liveness analysis (texture, frequency, color)'
                        }
                    },
                    'security_warnings': [] if liveness_passed else ['Liveness check failed'],
                    'glasses_details': {
                        'detected': False,     # ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
                        'confidence': 0.0      # ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
                    },
                    'processing_time_ms': processing_time,
                    'face_attributes': {
                        'age': result.get('age', 0),
                        'gender': result.get('gender', 'unknown')
                    },
                    'embedding_dimensions': len(result['embedding']),
                    'landmark_count': 5 if result.get('landmarks') else 0,
                    'suitable_for_registration': suitable_for_registration,
                    'recommendations': recommendations
                }
                
                # ìƒˆë¡œìš´ í•„ë“œ ì¶”ê°€
                if quality_result:
                    response_data['face_pose'] = {
                        'yaw': quality_result['pose_info']['yaw'],
                        'pitch': quality_result['pose_info']['pitch'],
                        'roll': quality_result['pose_info']['roll'],
                        'is_frontal': quality_result['pose_info']['is_frontal']
                    }
                    response_data['quality_details'] = {
                        'face_size_ratio': quality_result['position_info']['face_size_ratio'],
                        'face_centered': quality_result['position_info']['is_centered'],
                        'detection_confidence': quality_result['detection_confidence'],
                        'overall_quality_score': quality_result['overall_score']
                    }
                
                # notes ìƒì„±
                notes = f"InsightFace ê²€ì¶œ - Quality: {result.get('quality_score', 0):.2f}, " \
                       f"Liveness: {liveness_score:.2f} ({'Pass' if liveness_passed else 'Fail'})"
                response_data['notes'] = notes
                
                # NumPy íƒ€ì…ì„ Python ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜
                response_data = convert_numpy_types(response_data)
                
                return jsonify(response_data)
                
            except Exception as e:
                import traceback
                error_detail = traceback.format_exc()
                logger.error(f"ì–¼êµ´ ê²€ì¶œ ì˜¤ë¥˜: {str(e)}\nìƒì„¸ ì—ëŸ¬:\n{error_detail}")
                
                # ì¹œê·¼í•œ ì—ëŸ¬ ë©”ì‹œì§€ ë°˜í™˜
                user_message = 'ì–¼êµ´ ê²€ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.'
                
                # íŠ¹ì • ì—ëŸ¬ì— ëŒ€í•œ ì²˜ë¦¬
                if 'AttributeError' in str(e):
                    user_message = 'ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì„œë²„ë¥¼ ì¬ì‹œì‘í•´ì£¼ì„¸ìš”.'
                elif 'ValueError' in str(e):
                    user_message = 'ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì´ë¯¸ì§€ë¡œ ì‹œë„í•´ì£¼ì„¸ìš”.'
                
                return jsonify({
                    'success': False,
                    'face_detected': False,
                    'error': user_message,
                    'technical_error': str(e) if logger.level <= 10 else None  # DEBUG ëª¨ë“œì—ì„œë§Œ ê¸°ìˆ ì  ì—ëŸ¬ í‘œì‹œ
                }), 500
            """ëˆˆ ê¹œë¹¡ì„ ê°ì§€ API - ë¹„ë””ì˜¤ í”„ë ˆì„ ì‹œí€€ìŠ¤ ì²˜ë¦¬"""
            try:
                data = request.get_json()
                frames_data = data.get('frames', [])
                
                if not frames_data or len(frames_data) < 3:
                    return jsonify({
                        'success': False,
                        'error': 'At least 3 frames required for blink detection'
                    }), 400
                
                # í”„ë ˆì„ë“¤ì„ ë””ì½”ë”©
                frames = []
                for frame_data in frames_data:
                    frame = self._decode_image(frame_data)
                    frames.append(frame)
                
                # ëˆˆ ê¹œë¹¡ì„ ê°ì§€
                blink_detected, confidence = self.face_service.detect_eye_blink(frames)
                
                return jsonify({
                    'success': True,
                    'blink_detected': blink_detected,
                    'confidence': float(confidence),
                    'frames_processed': len(frames),
                    'message': 'ëˆˆ ê¹œë¹¡ì„ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.' if blink_detected else 'ëˆˆ ê¹œë¹¡ì„ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'
                })
                
            except Exception as e:
                logger.error(f"ëˆˆ ê¹œë¹¡ì„ ê°ì§€ ì˜¤ë¥˜: {str(e)}")
                return jsonify({
                    'success': False,
                    'error': str(e)
                }), 500
        
        @self.app.route('/api/face/recognize_for_checkin', methods=['POST'])
        @self.check_ip_whitelist
        def recognize_for_checkin():
            """ì²´í¬ì¸ìš© ì–¼êµ´ ì¸ì‹ API (ì—„ê²©í•œ ë³´ì•ˆ ê²€ì‚¬)"""
            try:
                # JSON ë°ì´í„° ì¶”ì¶œ
                data = request.get_json()
                image_data = data.get('image')
                check_liveness = data.get('check_liveness', True)
                check_blink = data.get('check_blink', False)
                blink_count = data.get('blink_count', 0)
                # param1/param2ë¥¼ ìš°ì„ í•˜ë˜, ì—†ìœ¼ë©´ comp_cd/bcoff_cd ì‚¬ìš© (í•˜ìœ„ í˜¸í™˜ì„±)
                param1 = data.get('param1') or data.get('comp_cd')
                param2 = data.get('param2') or data.get('bcoff_cd')
                
                if not image_data:
                    return jsonify({
                        'success': False,
                        'error': 'Missing image data'
                    }), 400
                
                # ì´ë¯¸ì§€ ë””ì½”ë”©
                try:
                    image = self._decode_image(image_data)
                except ValueError as e:
                    logger.warning(f"[CHECKIN] ì´ë¯¸ì§€ ë””ì½”ë”© ì‹¤íŒ¨: {str(e)}")
                    return jsonify({
                        'success': False,
                        'face_detected': False,
                        'error': 'ì¹´ë©”ë¼ í™”ë©´ì´ ì œëŒ€ë¡œ ìº¡ì²˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.'
                    }), 200  # 400 ëŒ€ì‹  200ìœ¼ë¡œ ë°˜í™˜í•˜ì—¬ ì¹œê·¼í•œ ë©”ì‹œì§€ í‘œì‹œ
                
                # ì„ë² ë”© ì¶”ì¶œ
                start_time = datetime.datetime.now()
                result = self.face_service.extract_embedding(image)
                processing_time = (datetime.datetime.now() - start_time).total_seconds() * 1000
                
                if not result['success']:
                    return jsonify({
                        'success': False,
                        'face_detected': False,
                        'error': result.get('error', 'ì–¼êµ´ì´ ì˜ ë³´ì´ì§€ ì•ŠìŠµë‹ˆë‹¤. ì¹´ë©”ë¼ë¥¼ ì •ë©´ìœ¼ë¡œ ë°”ë¼ë´ ì£¼ì„¸ìš”.')
                    }), 200  # 400 ëŒ€ì‹  200ìœ¼ë¡œ ë³€ê²½í•˜ì—¬ í´ë¼ì´ì–¸íŠ¸ê°€ ì¹œê·¼í•œ ë©”ì‹œì§€ë¥¼ í‘œì‹œí•  ìˆ˜ ìˆë„ë¡ í•¨
                
                # ë³´ì•ˆ ê²€ì‚¬
                security_failed = False
                security_details = {
                    'liveness_passed': True,
                    'blink_passed': True,
                    'quality_passed': True,
                    'liveness_confidence': 0.0,
                    'quality_score': 0.0,
                    'security_warnings': []
                }
                
                # Liveness detection
                liveness_score = 0.0
                if check_liveness:
                    faces = self.face_service.app.get(image)
                    if faces:
                        liveness_passed, liveness_score = self.face_service._detect_liveness(image, faces[0])
                        security_details['liveness_passed'] = bool(liveness_passed)
                        security_details['liveness_confidence'] = float(liveness_score)
                        
                        if not liveness_passed:
                            security_failed = True
                            security_details['security_warnings'].append('Liveness check failed')
                            logger.warning(f"[CHECKIN] Liveness ê²€ì‚¬ ì‹¤íŒ¨: score={liveness_score}")
                
                # ëˆˆ ê¹œë¹¡ì„ ê²€ì‚¬
                if check_blink and blink_count < 2:
                    security_details['blink_passed'] = False
                    security_details['blink_count'] = blink_count
                    security_failed = True
                    security_details['security_warnings'].append('Eye blink check failed')
                    logger.warning(f"[CHECKIN] ëˆˆ ê¹œë¹¡ì„ ê²€ì‚¬ ì‹¤íŒ¨: count={blink_count}")
                
                # í’ˆì§ˆ ê²€ì‚¬
                quality_score = result.get('quality_score', 0)
                security_details['quality_score'] = quality_score
                if quality_score < 0.5:
                    security_details['quality_passed'] = False
                    security_details['quality_score'] = quality_score
                    security_failed = True
                    logger.warning(f"[CHECKIN] í’ˆì§ˆ ê²€ì‚¬ ì‹¤íŒ¨: score={quality_score}")
                
                # ë³´ì•ˆ ê²€ì‚¬ ì‹¤íŒ¨ ì‹œ ì¦‰ì‹œ ë°˜í™˜
                if security_failed:
                    # ì‹¤íŒ¨ ë¡œê·¸ ì €ì¥
                    log_data = {
                        'mem_sno': None,
                        'confidence_score': 0,
                        'similarity_score': 0,
                        'quality_score': quality_score,
                        'processing_time_ms': processing_time,
                        'glasses_detected': False,
                        'match_category': 'checkin',
                        'security_checks_passed': json.dumps(security_details),
                        'success': False,
                        'error_message': 'Security verification failed',
                        'ip_address': request.remote_addr,
                        'user_agent': request.headers.get('User-Agent', ''),
                        'session_id': request.headers.get('X-Session-Id', '') or request.headers.get('Cookie', '')[:50] if request.headers.get('Cookie') else ''
                    }
                    self._save_recognition_log(log_data)
                    
                    return jsonify({
                        'success': False,
                        'security_failed': True,
                        'security_details': security_details,
                        'error': 'Security verification failed'
                    })
                
                # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë§¤ì¹­ (ì§€ì ë³„ í•„í„°ë§ í¬í•¨)
                match_result = self._find_best_match(result['embedding'], False, 'checkin', skip_logging=True, param1=param1, param2=param2)
                
                # ì‘ë‹µ êµ¬ì„±
                response = {
                    'success': True,
                    'face_detected': True,
                    'security_failed': False,
                    'security_details': security_details,
                    'processing_time_ms': processing_time
                }
                
                if match_result.get('matched'):
                    # Pythonì€ mem_snoë§Œ ë°˜í™˜, íšŒì› ì •ë³´ëŠ” PHPì—ì„œ ì¡°íšŒ
                    response.update({
                        'face_matching': {
                            'match_found': True,
                            'similarity_score': match_result['similarity'],
                            'member': {
                                'mem_sno': match_result['member_id']
                            }
                        }
                    })
                    
                    # ì²´í¬ì¸ ë¡œê·¸ ì €ì¥
                    log_data = {
                        'mem_sno': match_result['member_id'],
                        'confidence_score': match_result['similarity'],
                        'similarity_score': match_result['similarity'],
                        'quality_score': quality_score,
                        'processing_time_ms': processing_time,
                        'glasses_detected': False,
                        'match_category': 'checkin',
                        'security_checks_passed': json.dumps(security_details),
                        'success': True,
                        'ip_address': request.remote_addr,
                        'user_agent': request.headers.get('User-Agent', ''),
                        'session_id': request.headers.get('X-Session-Id', '') or request.headers.get('Cookie', '')[:50] if request.headers.get('Cookie') else '',
                        'param1': param1,
                        'param2': param2
                    }
                    self._save_recognition_log(log_data)
                    
                else:
                    response.update({
                        'face_matching': {
                            'match_found': False,
                            'similarity_score': 0,
                            'error': 'No matching face found'
                        }
                    })
                
                return jsonify(response)
                
            except Exception as e:
                logger.error(f"ì²´í¬ì¸ ì¸ì‹ ì˜¤ë¥˜: {str(e)}")
                return jsonify({
                    'success': False,
                    'error': str(e)
                }), 500
        
        @self.app.route('/api/face/detect_for_registration', methods=['POST'])
        @self.check_ip_whitelist
        def detect_for_registration():
            """íšŒì› ë“±ë¡ìš© ì–¼êµ´ ê²€ì¶œ API (ì €ì¥í•˜ì§€ ì•ŠìŒ, ê²€ì¶œë§Œ)"""
            try:
                import datetime
                import json
                
                # ë””ë²„ê·¸ íŒŒì¼ ìƒì„± ì—¬ë¶€ í™•ì¸
                debug_enabled = config.DEBUG_OPTIONS.get('request_debug_enabled', False) if hasattr(config, 'DEBUG_OPTIONS') else False
                
                if debug_enabled:
                    # í˜„ì¬ ì‹œê°„ìœ¼ë¡œ ê³ ìœ í•œ íŒŒì¼ëª… ìƒì„±
                    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S_%f")
                    debug_folder = config.DEBUG_OPTIONS.get('debug_folder', './debug') if hasattr(config, 'DEBUG_OPTIONS') else './debug'
                    
                    # ë””ë²„ê·¸ í´ë” ìƒì„±
                    if not os.path.exists(debug_folder):
                        os.makedirs(debug_folder, exist_ok=True)
                    
                    log_file = os.path.join(debug_folder, f"request_debug_{timestamp}.txt")
                    
                    # ìƒì„¸ ë¡œê¹… ì¶”ê°€
                    logger.info("=" * 60)
                    logger.info(f"[DETECT_REG] API í˜¸ì¶œ ì‹œì‘")
                    logger.info(f"[DETECT_REG] Content-Type: {request.content_type}")
                    logger.info(f"[DETECT_REG] Headers: {dict(request.headers)}")
                    logger.info(f"[DETECT_REG] Method: {request.method}")
                    logger.info(f"[DETECT_REG] Request URL: {request.url}")
                    logger.info(f"[DETECT_REG] Remote Addr: {request.remote_addr}")
                    logger.info(f"[DETECT_REG] User Agent: {request.user_agent}")
                    logger.info(f"[DETECT_REG] Debug íŒŒì¼: {log_file}")
                    
                    # ìš”ì²­ ì •ë³´ë¥¼ íŒŒì¼ì— ì €ì¥
                    with open(log_file, 'w', encoding='utf-8') as f:
                        f.write("=== REQUEST DEBUG INFO ===\n")
                        f.write(f"Timestamp: {datetime.datetime.now()}\n")
                        f.write(f"Method: {request.method}\n")
                        f.write(f"URL: {request.url}\n")
                        f.write(f"Remote Address: {request.remote_addr}\n")
                        f.write(f"Content-Type: {request.content_type}\n")
                        f.write(f"Content-Length: {request.content_length}\n")
                        f.write(f"User-Agent: {request.user_agent}\n")
                        f.write("\n=== HEADERS ===\n")
                        for key, value in request.headers:
                            f.write(f"{key}: {value}\n")
                        f.write(f"\n=== FORM DATA ===\n")
                        f.write(f"Form keys: {list(request.form.keys())}\n")
                        f.write(f"Files keys: {list(request.files.keys())}\n")
                        f.write(f"\n=== RAW BODY ===\n")
                        raw_body = request.get_data(as_text=True)
                        f.write(f"Length: {len(raw_body)} chars\n")
                        f.write(f"Content: {repr(raw_body)}\n")
                        if len(raw_body) < 10000:  # í° ë°ì´í„°ëŠ” ì œí•œ
                            f.write(f"Raw body: {raw_body}\n")
                        f.write(f"\n=== PARSED JSON ===\n")
                        try:
                            json_data = request.get_json()
                            f.write(f"JSON: {json.dumps(json_data, indent=2, ensure_ascii=False)}\n")
                        except Exception as e:
                            f.write(f"JSON Parse Error: {str(e)}\n")
                
                # FormDataì™€ JSON ëª¨ë‘ ì§€ì›
                if request.content_type and 'multipart/form-data' in request.content_type:
                    logger.info(f"[DETECT_REG] FormData ì²˜ë¦¬ ì‹œì‘")
                    logger.info(f"[DETECT_REG] Files keys: {list(request.files.keys())}")
                    
                    # FormData ì²˜ë¦¬
                    if 'image' in request.files:
                        image_file = request.files['image']
                        logger.info(f"[DETECT_REG] ì´ë¯¸ì§€ íŒŒì¼ ë°œê²¬: {image_file.filename}")
                        image_bytes = image_file.read()
                        logger.info(f"[DETECT_REG] ì´ë¯¸ì§€ í¬ê¸°: {len(image_bytes)} bytes")
                        
                        # base64ë¡œ ì¸ì½”ë”©í•˜ê³  data URI í˜•ì‹ìœ¼ë¡œ ë§Œë“¤ê¸°
                        image_b64 = base64.b64encode(image_bytes).decode('utf-8')
                        image_data = f"data:image/jpeg;base64,{image_b64}"
                        logger.info(f"[DETECT_REG] Base64 ì¸ì½”ë”© ì™„ë£Œ: {len(image_data)} chars")
                    else:
                        logger.warning(f"[DETECT_REG] ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ - NO_IMAGE_PROVIDED")
                        return jsonify({
                            'success': False,  # ì´ë¯¸ì§€ ì—†ìŒ
                            'face_detected': False,
                            'suitable_for_registration': False,
                            'quality_score': 0.0,
                            'processing_time_ms': 0,
                            'recommendations': ['ì´ë¯¸ì§€ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.'],
                            'error_code': 'NO_IMAGE_PROVIDED',
                            'error_message': 'No image file provided'
                        }), 200
                else:
                    # JSON ì²˜ë¦¬
                    logger.info(f"[DETECT_REG] JSON ì²˜ë¦¬ ì‹œì‘")
                    
                    # request body ë¡œê¹…
                    raw_data = request.get_data(as_text=True)
                    logger.info(f"[DETECT_REG] Raw body length: {len(raw_data)} chars")
                    if len(raw_data) < 1000:  # ì‘ì€ ê²½ìš°ë§Œ ì „ì²´ ë¡œê¹…
                        logger.info(f"[DETECT_REG] Raw body: {raw_data}")
                    
                    # JSON íŒŒì‹± ì‹œ ë°”ì´ë„ˆë¦¬ ë°ì´í„° ì²˜ë¦¬
                    try:
                        # ë¨¼ì € ì›ë³¸ìœ¼ë¡œ ì‹œë„
                        data = request.get_json()
                        logger.info(f"[DETECT_REG] JSON íŒŒì‹± ì„±ê³µ (ì›ë³¸)")
                    except Exception as e:
                        logger.warning(f"[DETECT_REG] ì›ë³¸ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                        logger.error(f"[DETECT_REG] í´ë¼ì´ì–¸íŠ¸ê°€ ë°”ì´ë„ˆë¦¬ ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ JSONì— ì§ì ‘ í¬í•¨ì‹œì¼°ìŠµë‹ˆë‹¤")
                        logger.error(f"[DETECT_REG] Base64 ì¸ì½”ë”©ì´ í•„ìš”í•©ë‹ˆë‹¤")
                        
                        # í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ëª…í™•í•œ ì˜¤ë¥˜ ë©”ì‹œì§€ ë°˜í™˜
                        return jsonify({
                            'success': False,
                            'face_detected': False,
                            'suitable_for_registration': False,
                            'quality_score': 0.0,
                            'processing_time_ms': 0,
                            'recommendations': [
                                'ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ Base64ë¡œ ì¸ì½”ë”©í•˜ì—¬ ì „ì†¡í•´ì£¼ì„¸ìš”.',
                                'JSONì— ë°”ì´ë„ˆë¦¬ ë°ì´í„°ë¥¼ ì§ì ‘ í¬í•¨ì‹œí‚¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
                            ],
                            'error_code': 'INVALID_IMAGE_FORMAT',
                            'error_message': 'Binary image data in JSON. Please use Base64 encoding.',
                            'expected_format': {
                                'image': 'data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAYA... (Base64 encoded)'
                            }
                        }), 400
                    
                    if data:
                        logger.info(f"[DETECT_REG] JSON keys: {list(data.keys())}")
                        image_data = data.get('image')
                        if image_data:
                            logger.info(f"[DETECT_REG] image í•„ë“œ ë°œê²¬: {len(image_data)} chars")
                            # Base64 í—¤ë” í™•ì¸
                            if image_data.startswith('data:'):
                                logger.info(f"[DETECT_REG] Data URI í˜•ì‹ ê°ì§€")
                            else:
                                logger.info(f"[DETECT_REG] Raw Base64 í˜•ì‹")
                        else:
                            logger.warning(f"[DETECT_REG] JSONì— image í•„ë“œ ì—†ìŒ ë˜ëŠ” ë¹ˆ ê°’")
                    else:
                        logger.error(f"[DETECT_REG] JSON íŒŒì‹± ì™„ì „ ì‹¤íŒ¨")
                        image_data = None
                    
                    # ë¹ˆ ë¬¸ìì—´ ì²´í¬ ì¶”ê°€
                    if image_data == "":
                        logger.warning(f"[DETECT_REG] image í•„ë“œê°€ ë¹ˆ ë¬¸ìì—´")
                        image_data = None
                
                if not image_data:
                    logger.error(f"[DETECT_REG] ì´ë¯¸ì§€ ë°ì´í„° ì—†ìŒ - MISSING_IMAGE_DATA")
                    logger.error(f"[DETECT_REG] Content-Type: {request.content_type}")
                    logger.error(f"[DETECT_REG] Content-Length: {request.content_length}")
                    return jsonify({
                        'success': False,  # ì´ë¯¸ì§€ ë°ì´í„° ì—†ìŒ
                        'face_detected': False,
                        'suitable_for_registration': False,
                        'quality_score': 0.0,
                        'processing_time_ms': 0,
                        'recommendations': ['ì´ë¯¸ì§€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.'],
                        'error_code': 'MISSING_IMAGE_DATA',
                        'error_message': 'Missing image data'
                    }), 200
                
                # ì´ë¯¸ì§€ ë””ì½”ë”©
                logger.info(f"[DETECT_REG] ì´ë¯¸ì§€ ë””ì½”ë”© ì‹œì‘")
                image = self._decode_image(image_data)
                logger.info(f"[DETECT_REG] ì´ë¯¸ì§€ ë””ì½”ë”© ì™„ë£Œ: shape={image.shape}")
                
                # ì„ë² ë”© ì¶”ì¶œ
                start_time = datetime.datetime.now()
                result = self.face_service.extract_embedding(image)
                processing_time = (datetime.datetime.now() - start_time).total_seconds() * 1000
                
                # ì–¼êµ´ì´ ê²€ì¶œëœ ê²½ìš° liveness detection ìˆ˜í–‰
                liveness_passed = False
                liveness_score = 0.0
                quality_result = None
                if result['success']:
                    # ì–¼êµ´ ì¬ê²€ì¶œ (liveness detectionì„ ìœ„í•´)
                    faces = self.face_service.app.get(image)
                    if faces:
                        liveness_passed, liveness_score = self.face_service._detect_liveness(image, faces[0])
                        liveness_passed = bool(liveness_passed)  # NumPy boolì„ Python boolë¡œ ë³€í™˜
                        liveness_score = float(liveness_score)
                        
                        # í–¥ìƒëœ í’ˆì§ˆ í‰ê°€
                        quality_result = self.face_service._evaluate_quality_enhanced(image, faces[0])
                
                if not result['success']:
                    # ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ì„ ë•Œ success: falseë¡œ ë°˜í™˜
                    error_msg = result.get('error', 'Face detection failed')
                    recommendations = []
                    error_detail = ""
                    
                    if 'Multiple faces' in error_msg:
                        recommendations.append('ì—¬ëŸ¬ ì–¼êµ´ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. í•œ ëª…ë§Œ ì´¬ì˜í•´ì£¼ì„¸ìš”.')
                        error_detail = "MULTIPLE_FACES_DETECTED"
                    elif 'No face' in error_msg:
                        recommendations.append('ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì¹´ë©”ë¼ë¥¼ ì •ë©´ìœ¼ë¡œ ë°”ë¼ë´ì£¼ì„¸ìš”.')
                        error_detail = "NO_FACE_DETECTED"
                    else:
                        recommendations.append('ì–¼êµ´ ê²€ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.')
                        error_detail = "FACE_DETECTION_FAILED"
                    
                    return jsonify({
                        'success': False,  # ì–¼êµ´ ê²€ì¶œ ì‹¤íŒ¨
                        'face_detected': False,
                        'suitable_for_registration': False,
                        'quality_score': 0.0,
                        'processing_time_ms': processing_time,
                        'recommendations': recommendations,
                        'error_code': error_detail,  # ì—ëŸ¬ ì½”ë“œ
                        'error_message': error_msg  # ìƒì„¸ ì—ëŸ¬ ë©”ì‹œì§€
                    }), 200
                
                # ë“±ë¡ ì í•©ì„± íŒë‹¨
                suitable_for_registration = True
                recommendations = []
                
                if quality_result:
                    # ê²€ì¶œ ì‹ ë¢°ë„ ì²´í¬
                    if quality_result['detection_confidence'] < 0.8:
                        suitable_for_registration = False
                        recommendations.append('ì–¼êµ´ì´ ëª…í™•í•˜ê²Œ ë³´ì´ì§€ ì•ŠìŠµë‹ˆë‹¤. ì¡°ëª…ì„ ë°ê²Œ í•´ì£¼ì„¸ìš”.')
                    
                    # ì–¼êµ´ í¬ê¸° ì²´í¬ (15%~70%ë¡œ ë²”ìœ„ í™•ëŒ€)
                    face_size_ratio = quality_result['position_info']['face_size_ratio']
                    if face_size_ratio < 0.15:
                        suitable_for_registration = False
                        recommendations.append('ì¹´ë©”ë¼ì— ë” ê°€ê¹Œì´ ì™€ì£¼ì„¸ìš”.')
                    elif face_size_ratio > 0.7:
                        suitable_for_registration = False
                        recommendations.append('ì¡°ê¸ˆ ë’¤ë¡œ ë¬¼ëŸ¬ë‚˜ì£¼ì„¸ìš”.')
                    
                    # ì–¼êµ´ ìœ„ì¹˜ ì²´í¬
                    if not quality_result['position_info']['is_centered']:
                        suitable_for_registration = False
                        recommendations.append('ì–¼êµ´ì„ í™”ë©´ ì¤‘ì•™ì— ë§ì¶°ì£¼ì„¸ìš”.')
                    
                    # ì–¼êµ´ ê°ë„ ì²´í¬
                    pose_info = quality_result['pose_info']
                    if not pose_info['is_frontal']:
                        if abs(pose_info['yaw']) > 15:
                            recommendations.append('ì •ë©´ì„ ë°”ë¼ë´ì£¼ì„¸ìš”.')
                        if abs(pose_info['pitch']) > 15:
                            if pose_info['pitch'] > 0:
                                recommendations.append('ê³ ê°œë¥¼ ì¡°ê¸ˆ ë‚´ë ¤ì£¼ì„¸ìš”.')  # ìœ„ë¥¼ ë³´ê³  ìˆìŒ
                            else:
                                recommendations.append('ê³ ê°œë¥¼ ì¡°ê¸ˆ ë“¤ì–´ì£¼ì„¸ìš”.')  # ì•„ë˜ë¥¼ ë³´ê³  ìˆìŒ
                        if abs(pose_info['roll']) > 10:
                            recommendations.append('ê³ ê°œë¥¼ ë˜‘ë°”ë¡œ ì„¸ì›Œì£¼ì„¸ìš”.')
                        suitable_for_registration = False
                    
                    # ì „ì²´ í’ˆì§ˆ ì ìˆ˜ ì²´í¬
                    if quality_result['overall_score'] < 0.7:
                        suitable_for_registration = False
                        if not recommendations:  # ë‹¤ë¥¸ êµ¬ì²´ì ì¸ ë¬¸ì œê°€ ì—†ìœ¼ë©´
                            recommendations.append('ì´ë¯¸ì§€ í’ˆì§ˆì´ ë‚®ìŠµë‹ˆë‹¤. ë” ë‚˜ì€ ì¡°ëª…ì—ì„œ ë‹¤ì‹œ ì´¬ì˜í•´ì£¼ì„¸ìš”.')
                
                # ì‘ë‹µ ë°ì´í„° - displayResultì™€ í˜¸í™˜ë˜ëŠ” í˜•ì‹
                response_data = {
                    'success': suitable_for_registration,  # ë“±ë¡ ê°€ëŠ¥í•œ ê²½ìš°ë§Œ true
                    'face_detected': True,
                    'suitable_for_registration': suitable_for_registration,
                    'quality_score': result.get('quality_score', 0),
                    'processing_time_ms': processing_time,
                    'recommendations': recommendations
                }
                
                # ë“±ë¡ ë¶€ì í•©í•œ ê²½ìš° ì—ëŸ¬ ì½”ë“œ ì¶”ê°€
                if not suitable_for_registration:
                    error_codes = []
                    if quality_result:
                        pose_info = quality_result['pose_info']
                        if not pose_info['is_frontal']:
                            if abs(pose_info['yaw']) > 15:
                                error_codes.append('FACE_ANGLE_YAW')
                            if abs(pose_info['pitch']) > 15:
                                error_codes.append('FACE_ANGLE_PITCH')
                            if abs(pose_info['roll']) > 10:
                                error_codes.append('FACE_ANGLE_ROLL')
                        
                        face_size_ratio = quality_result['position_info']['face_size_ratio']
                        if face_size_ratio < 0.15:
                            error_codes.append('FACE_TOO_SMALL')
                        elif face_size_ratio > 0.7:
                            error_codes.append('FACE_TOO_LARGE')
                        
                        if not quality_result['position_info']['is_centered']:
                            error_codes.append('FACE_NOT_CENTERED')
                        
                        if quality_result['detection_confidence'] < 0.8:
                            error_codes.append('LOW_DETECTION_CONFIDENCE')
                        
                        if quality_result['overall_score'] < 0.7:
                            error_codes.append('LOW_QUALITY_SCORE')
                    
                    response_data['error_code'] = ','.join(error_codes) if error_codes else 'REGISTRATION_UNSUITABLE'
                    response_data['error_message'] = 'Face detected but not suitable for registration'
                
                # ì¶”ê°€ í•„ë“œë“¤
                if quality_result:
                    response_data['face_pose'] = {
                        'yaw': quality_result['pose_info']['yaw'],
                        'pitch': quality_result['pose_info']['pitch'],
                        'roll': quality_result['pose_info']['roll'],
                        'is_frontal': quality_result['pose_info']['is_frontal']
                    }
                    response_data['quality_details'] = {
                        'face_size_ratio': quality_result['position_info']['face_size_ratio'],
                        'face_centered': quality_result['position_info']['is_centered'],
                        'detection_confidence': quality_result['detection_confidence'],
                        'overall_quality_score': quality_result['overall_score']
                    }
                
                # NumPy íƒ€ì…ì„ Python ê¸°ë³¸ íƒ€ì…ìœ¼ë¡œ ë³€í™˜
                response_data = convert_numpy_types(response_data)
                
                return jsonify(response_data)
                
            except Exception as e:
                logger.error(f"ì–¼êµ´ ê²€ì¶œ ì˜¤ë¥˜: {str(e)}")
                import traceback
                logger.error(f"Traceback: {traceback.format_exc()}")
                # ì˜¤ë¥˜ ë°œìƒ ì‹œ success: falseë¡œ 200 ë°˜í™˜
                return jsonify({
                    'success': False,  # ì²˜ë¦¬ ì‹¤íŒ¨
                    'face_detected': False,
                    'suitable_for_registration': False,
                    'quality_score': 0.0,
                    'processing_time_ms': 0,
                    'recommendations': ['ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.'],
                    'error_code': 'PROCESSING_ERROR',
                    'error_message': str(e)  # ì—ëŸ¬ ë©”ì‹œì§€
                }), 200
        
        @self.app.route('/', methods=['GET'])
        @self.check_ip_whitelist
        def index():
            """í…ŒìŠ¤íŠ¸ ì¸í„°í˜ì´ìŠ¤"""
            return render_template_string(TEST_INTERFACE_HTML)
    
    def _decode_image(self, image_data: str) -> np.ndarray:
        """Base64 ì´ë¯¸ì§€ ë””ì½”ë”©"""
        try:
            # base64 í—¤ë” ì œê±°
            if ',' in image_data:
                image_data = image_data.split(',')[1]
            
            # ë””ì½”ë”©
            image_bytes = base64.b64decode(image_data)
            image = Image.open(io.BytesIO(image_bytes))
            
            # ì´ë¯¸ì§€ê°€ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
            image_array = np.array(image)
            if image_array.size == 0:
                raise ValueError("ë¹ˆ ì´ë¯¸ì§€ì…ë‹ˆë‹¤")
            
            # OpenCV í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            image = cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR)
            
            return image
        except Exception as e:
            logger.error(f"ì´ë¯¸ì§€ ë””ì½”ë”© ì˜¤ë¥˜: {str(e)}")
            raise ValueError(f"ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")
    
    def _save_face_to_db(self, member_id: str, face_data: dict, param1: str = None, param2: str = None) -> dict:
        """ë°ì´í„°ë² ì´ìŠ¤ì— ì–¼êµ´ ë°ì´í„° ì €ì¥"""
        connection = self.get_db_connection()
        cursor = connection.cursor()
        
        try:
            # notes ìƒì„± - ë“±ë¡ ì‹œ ì •ë³´ ê¸°ë¡
            notes = f"InsightFace ë“±ë¡ - Quality: {face_data['quality_score']:.2f}, " \
                   f"Liveness: {face_data.get('liveness_score', 0.95):.2f}"
            
            # ê¸°ì¡´ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
            if self.db_type == 'mssql':
                cursor.execute("""
                    SELECT TOP 1 face_id FROM member_faces 
                    WHERE mem_sno = ? AND is_active = 1
                """, (member_id,))
            else:
                cursor.execute("""
                    SELECT face_id FROM member_faces 
                    WHERE mem_sno = %s AND is_active = 1
                    LIMIT 1
                """, (member_id,))
            existing_face = cursor.fetchone()
            
            if existing_face:
                # ê¸°ì¡´ ë°ì´í„° ì—…ë°ì´íŠ¸
                face_id = existing_face[0]
                if self.db_type == 'mssql':
                    cursor.execute("""
                        UPDATE member_faces 
                        SET face_encoding = ?,
                            quality_score = ?,
                            glasses_detected = ?,
                            security_level = ?,
                            liveness_score = ?,
                            last_updated = GETDATE(),
                            notes = ?,
                            param1 = ?,
                            param2 = ?
                        WHERE face_id = ?
                    """, (
                        json.dumps(face_data['embedding']),
                        face_data['quality_score'],
                        0,  # ì•ˆê²½ ê°ì§€ ì‚¬ìš© ì•ˆí•¨
                        3,  # ë³´ì•ˆ ë ˆë²¨
                        face_data.get('liveness_score', 0.95),
                        notes,
                        param1,
                        param2,
                        face_id
                    ))
                else:
                    cursor.execute("""
                        UPDATE member_faces 
                        SET face_encoding = %s,
                            quality_score = %s,
                            glasses_detected = %s,
                            security_level = %s,
                            liveness_score = %s,
                            last_updated = NOW(),
                            notes = %s,
                            param1 = %s,
                            param2 = %s
                        WHERE face_id = %s
                    """, (
                    json.dumps(face_data['embedding']),
                    face_data['quality_score'],
                    0,  # ì•ˆê²½ ê°ì§€ ì‚¬ìš© ì•ˆí•¨
                    3,  # ë³´ì•ˆ ë ˆë²¨
                    face_data.get('liveness_score', 0.95),
                    notes,
                    param1,
                    param2,
                    face_id
                ))
                logger.info(f"[DB] ê¸°ì¡´ ì–¼êµ´ ë°ì´í„° ì—…ë°ì´íŠ¸ - face_id: {face_id}, mem_sno: {member_id}")
            else:
                # ìƒˆ ë°ì´í„° ì‚½ì…
                if self.db_type == 'mssql':
                    cursor.execute("""
                        INSERT INTO member_faces 
                        (mem_sno, face_encoding, quality_score, glasses_detected, 
                         security_level, liveness_score, is_active, registered_date, notes, param1, param2)
                        VALUES (?, ?, ?, ?, ?, ?, ?, GETDATE(), ?, ?, ?)
                    """, (
                        member_id,
                        json.dumps(face_data['embedding']),
                        face_data['quality_score'],
                        0,  # ì•ˆê²½ ê°ì§€ ì‚¬ìš© ì•ˆí•¨
                        3,  # ë³´ì•ˆ ë ˆë²¨
                        face_data.get('liveness_score', 0.95),
                        1,  # is_active
                        notes,
                        param1,
                        param2
                    ))
                else:
                    cursor.execute("""
                        INSERT INTO member_faces 
                        (mem_sno, face_encoding, quality_score, glasses_detected, 
                         security_level, liveness_score, is_active, registered_date, notes, param1, param2)
                        VALUES (%s, %s, %s, %s, %s, %s, %s, NOW(), %s, %s, %s)
                    """, (
                    member_id,
                    json.dumps(face_data['embedding']),
                    face_data['quality_score'],
                    0,  # ì•ˆê²½ ê°ì§€ ì‚¬ìš© ì•ˆí•¨
                    3,  # ë³´ì•ˆ ë ˆë²¨
                    face_data.get('liveness_score', 0.95),
                    1,  # is_active
                    notes,
                    param1,
                    param2
                ))
                face_id = cursor.lastrowid
                logger.info(f"[DB] ìƒˆ ì–¼êµ´ ë°ì´í„° ì‚½ì… - face_id: {face_id}, mem_sno: {member_id}")
            
            # ë¡œê·¸ ì €ì¥ (enhanced_face_service.py ë°©ì‹)
            try:
                logger.info(f"[LOG] face_recognition_logs ì €ì¥ ì‹œì‘ - mem_sno: {member_id}")
                
                # ìš”ì²­ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                ip_address = request.remote_addr or request.environ.get('HTTP_X_FORWARDED_FOR', '127.0.0.1')
                user_agent = request.headers.get('User-Agent', '')
                
                # ì„¸ì…˜ ID ê°€ì ¸ì˜¤ê¸° (ì¿ í‚¤ì—ì„œ ì„¸ì…˜ ID ì¶”ì¶œ)
                session_id = ''
                if 'ci_session' in request.cookies:
                    session_id = request.cookies['ci_session']
                elif 'session_id' in request.cookies:
                    session_id = request.cookies['session_id']
                else:
                    # Flask ì„¸ì…˜ ID ì‚¬ìš©
                    from flask import session
                    session_id = session.get('session_id', '')
                
                logger.info(f"[LOG] Request Info - IP: {ip_address}, User-Agent: {user_agent[:50]}..., Session ID: {session_id[:20]}...")
                logger.info(f"[LOG] Available cookies: {list(request.cookies.keys())}")
                
                # SQL ì¿¼ë¦¬ì™€ íŒŒë¼ë¯¸í„° ë¡œê¹…
                if self.db_type == 'mssql':
                    log_query = """
                        INSERT INTO face_recognition_logs 
                        (mem_sno, confidence_score, similarity_score, quality_score,
                         processing_time_ms, glasses_detected, match_category, 
                         security_checks_passed, success, error_message, 
                         ip_address, user_agent, session_id, recognition_time, param1, param2)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, GETDATE(), ?, ?)
                    """
                else:
                    log_query = """
                        INSERT INTO face_recognition_logs 
                        (mem_sno, confidence_score, similarity_score, quality_score,
                         processing_time_ms, glasses_detected, match_category, 
                         security_checks_passed, success, error_message, 
                         ip_address, user_agent, session_id, recognition_time, param1, param2)
                        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, NOW(), %s, %s)
                    """
                log_params = (
                    member_id,
                    1.0,  # ë“±ë¡ì‹œ confidenceëŠ” 1.0
                    1.0,  # ë“±ë¡ì‹œ similarityëŠ” 1.0
                    face_data['quality_score'],
                    face_data.get('processing_time_ms', 0),
                    0,  # ì•ˆê²½ ê°ì§€ ì‚¬ìš© ì•ˆí•¨
                    'registration',
                    json.dumps({
                        'liveness_passed': face_data.get('liveness_score', 0.95) >= 0.6,
                        'liveness_confidence': face_data.get('liveness_score', 0.95),
                        'quality_score': face_data['quality_score'],
                        'glasses_confidence': 0.0,  # ì•ˆê²½ ê°ì§€ ì‚¬ìš© ì•ˆí•¨
                        'security_warnings': []
                    }),
                    1,  # success
                    None,  # error_message
                    ip_address,
                    user_agent,
                    session_id,
                    param1,
                    param2
                )
                
                logger.info(f"[LOG] SQL Query: {log_query}")
                logger.info(f"[LOG] SQL Params: {log_params}")
                
                cursor.execute(log_query, log_params)
                logger.info(f"[LOG] face_recognition_logs ì €ì¥ ì„±ê³µ - ì˜í–¥ë°›ì€ í–‰: {cursor.rowcount}")
            except Exception as log_error:
                logger.error(f"[LOG] face_recognition_logs ì €ì¥ ì‹¤íŒ¨: {str(log_error)}")
                logger.error(f"[LOG] Error Type: {type(log_error).__name__}")
                logger.error(f"[LOG] Full Error: {repr(log_error)}")
                import traceback
                logger.error(f"[LOG] Traceback: {traceback.format_exc()}")
                # ë¡œê·¸ ì €ì¥ ì‹¤íŒ¨í•´ë„ ì–¼êµ´ ë“±ë¡ì€ ê³„ì† ì§„í–‰
            
            connection.commit()
            
            return {
                'db_success': True,
                'face_id': face_id,
                'message': 'ì–¼êµ´ ë“±ë¡ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.'
            }
            
        except Exception as e:
            connection.rollback()
            logger.error(f"DB ì €ì¥ ì˜¤ë¥˜: {str(e)}")
            return {
                'db_success': False,
                'db_error': str(e),
                'message': f'ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
            }
        finally:
            cursor.close()
            connection.close()
    
    def _find_best_match(self, test_embedding: List[float], glasses_detected: bool = False, match_category: str = 'recognition', skip_logging: bool = False, comp_cd: str = None, bcoff_cd: str = None, param1: str = None, param2: str = None) -> dict:  # glasses_detectedëŠ” ì‚¬ìš© ì•ˆí•¨
        """ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ìµœì  ë§¤ì¹­ ì°¾ê¸° (ì§€ì ë³„ í•„í„°ë§ ì§€ì›)"""
        connection = self.get_db_connection()
        
        # DB íƒ€ì…ì— ë”°ë¥¸ cursor ìƒì„±
        if self.db_type == 'mssql':
            cursor = connection.cursor()
        else:
            cursor = connection.cursor(dictionary=True)
        
        try:
            # íŒŒë¼ë¯¸í„° ìš°ì„ ìˆœìœ„: param1/param2ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ comp_cd/bcoff_cd ì‚¬ìš©
            use_param1 = param1 if param1 is not None else comp_cd
            use_param2 = param2 if param2 is not None else bcoff_cd
            
            # íŒŒë¼ë¯¸í„° ê¸°ë°˜ í•„í„°ë§
            if use_param1 and use_param2:
                # param1ê³¼ param2 ëª¨ë‘ ìˆëŠ” ê²½ìš°
                if self.db_type == 'mssql':
                    cursor.execute("""
                        SELECT face_id, mem_sno, face_encoding, glasses_detected
                        FROM member_faces
                        WHERE is_active = 1
                        AND param1 = ?
                        AND param2 = ?
                    """, (use_param1, use_param2))
                else:
                    cursor.execute("""
                        SELECT face_id, mem_sno, face_encoding, glasses_detected
                        FROM member_faces
                        WHERE is_active = 1
                        AND param1 = %s
                        AND param2 = %s
                    """, (use_param1, use_param2))
                logger.info(f"[RECOG] param1={use_param1}, param2={use_param2}ë¡œ í•„í„°ë§")
                
            elif use_param1:
                # param1ë§Œ ìˆëŠ” ê²½ìš°
                if self.db_type == 'mssql':
                    cursor.execute("""
                        SELECT face_id, mem_sno, face_encoding, glasses_detected
                        FROM member_faces
                        WHERE is_active = 1
                        AND param1 = ?
                    """, (use_param1,))
                else:
                    cursor.execute("""
                        SELECT face_id, mem_sno, face_encoding, glasses_detected
                        FROM member_faces
                        WHERE is_active = 1
                        AND param1 = %s
                    """, (use_param1,))
                logger.info(f"[RECOG] param1={use_param1}ë¡œ í•„í„°ë§")
                
            else:
                # íŒŒë¼ë¯¸í„°ê°€ ì—†ëŠ” ê²½ìš° - ì „ì²´ ì¡°íšŒ
                cursor.execute("""
                    SELECT face_id, mem_sno, face_encoding, glasses_detected
                    FROM member_faces
                    WHERE is_active = 1
                """)
                logger.info("[RECOG] ì „ì²´ ì–¼êµ´ ë°ì´í„° ì¡°íšŒ")
            
            faces = cursor.fetchall()
            
            best_match = None
            best_similarity = 0
            match_type = None
            
            for face in faces:
                try:
                    # MSSQLì€ tupleë¡œ ë°˜í™˜í•˜ë¯€ë¡œ ì¸ë±ìŠ¤ë¡œ ì ‘ê·¼
                    if self.db_type == 'mssql':
                        face_id = face[0]
                        mem_sno = face[1]
                        face_encoding = face[2]
                        glasses_detected_db = face[3]
                    else:
                        face_id = face['face_id']
                        mem_sno = face['mem_sno']
                        face_encoding = face['face_encoding']
                        glasses_detected_db = face['glasses_detected']
                    
                    stored_embedding = json.loads(face_encoding)
                    
                    # InsightFace ì„ë² ë”©ì¸ì§€ í™•ì¸ (512ì°¨ì›)
                    if len(stored_embedding) == 512:
                        similarity = self.face_service.compare_embeddings(
                            test_embedding, 
                            stored_embedding
                        )
                        match_type = 'insightface'
                    else:
                        # MediaPipe ì„ë² ë”©ê³¼ëŠ” ë¹„êµí•˜ì§€ ì•ŠìŒ (ì°¨ì›ì´ ë‹¤ë¦„)
                        continue
                    
                    # ì•ˆê²½ ìƒíƒœì— ë”°ë¥¸ ê°€ì¤‘ì¹˜ ì ìš©
                    if glasses_detected_db == glasses_detected:
                        similarity *= 1.05  # ë™ì¼ ì•ˆê²½ ìƒíƒœ ë³´ë„ˆìŠ¤
                    else:
                        similarity *= 0.95  # ë‹¤ë¥¸ ì•ˆê²½ ìƒíƒœ í˜ë„í‹°
                    
                    if similarity > best_similarity:
                        best_similarity = similarity
                        if self.db_type == 'mssql':
                            best_match = {
                                'face_id': face_id,
                                'mem_sno': mem_sno,
                                'face_encoding': face_encoding,
                                'glasses_detected': glasses_detected_db
                            }
                        else:
                            best_match = face
                        
                except Exception as e:
                    if self.db_type == 'mssql':
                        logger.error(f"ì–¼êµ´ ë¹„êµ ì˜¤ë¥˜ (face_id: {face_id}): {e}")
                    else:
                        logger.error(f"ì–¼êµ´ ë¹„êµ ì˜¤ë¥˜ (face_id: {face['face_id']}): {e}")
                    continue
            
            # ì„ê³„ê°’ í™•ì¸
            if best_match and best_similarity >= self.face_service.thresholds['recognition']:
                # ì¸ì‹ ë¡œê·¸ ì €ì¥ (skip_loggingì´ Trueë©´ ê±´ë„ˆë›°ê¸°)
                if not skip_logging:
                    log_data = {
                        'mem_sno': best_match['mem_sno'],
                        'confidence_score': best_similarity,
                        'similarity_score': best_similarity,
                        'glasses_detected': glasses_detected,
                        'match_category': match_category,
                        'success': True
                    }
                    self._save_recognition_log(log_data)
                
                return {
                    'matched': True,
                    'member_id': best_match['mem_sno'],
                    'similarity': float(best_similarity),
                    'confidence': 'high' if best_similarity >= 0.8 else 'medium',
                    'match_type': match_type
                }
            else:
                # ì‹¤íŒ¨ ë¡œê·¸ ì €ì¥ (skip_loggingì´ Trueë©´ ê±´ë„ˆë›°ê¸°)
                if not skip_logging:
                    log_data = {
                        'mem_sno': None,
                        'confidence_score': best_similarity if best_similarity else 0,
                        'similarity_score': best_similarity if best_similarity else 0,
                        'glasses_detected': glasses_detected,
                        'match_category': match_category,
                        'success': False,
                        'error_message': 'No match found above threshold'
                    }
                    self._save_recognition_log(log_data)
                
                return {
                    'matched': False,
                    'similarity': float(best_similarity) if best_similarity > 0 else 0,
                    'message': 'ë“±ë¡ëœ íšŒì› ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íšŒì›ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.',
                    'threshold': self.face_service.thresholds['recognition']
                }
                
        except Exception as e:
            logger.error(f"ë§¤ì¹­ ì˜¤ë¥˜: {e}")
            return {
                'matched': False,
                'error': str(e),
                'message': 'ì–¼êµ´ ë§¤ì¹­ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.'
            }
        finally:
            cursor.close()
            connection.close()
    
    # def _get_member_info(self, mem_sno: str) -> Dict:
    #     """íšŒì› ì •ë³´ ì¡°íšŒ - PHPì—ì„œ ì²˜ë¦¬í•˜ë„ë¡ ë³€ê²½ë¨"""
    #     # Pythonì€ ì–¼êµ´ ì¸ì‹ ê²°ê³¼(mem_sno)ë§Œ ë°˜í™˜
    #     # íšŒì› ì •ë³´ ì¡°íšŒëŠ” PHPì—ì„œ ì§ì ‘ ì²˜ë¦¬
    #     pass
    
    def _save_recognition_log(self, log_data: Dict):
        """ì¸ì‹ ë¡œê·¸ ì €ì¥ (ê°œì„ ëœ ë²„ì „)"""
        connection = None
        cursor = None
        try:
            connection = self.get_db_connection()
            cursor = connection.cursor()
            
            # ìš”ì²­ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            ip_address = request.remote_addr or request.environ.get('HTTP_X_FORWARDED_FOR', '127.0.0.1')
            user_agent = request.headers.get('User-Agent', '')
            
            # ì„¸ì…˜ ID ê°€ì ¸ì˜¤ê¸°
            session_id = ''
            if 'ci_session' in request.cookies:
                session_id = request.cookies['ci_session']
            elif 'session_id' in request.cookies:
                session_id = request.cookies['session_id']
            else:
                from flask import session
                session_id = session.get('session_id', '')
            
            # ê¸°ë³¸ê°’ ì„¤ì •
            mem_sno = log_data.get('mem_sno')
            confidence_score = log_data.get('confidence_score', 0)
            similarity_score = log_data.get('similarity_score', 0)
            quality_score = log_data.get('quality_score', 0.85)
            glasses_detected = log_data.get('glasses_detected', False)
            match_category = log_data.get('match_category', 'recognition')
            security_checks_passed = log_data.get('security_checks_passed', '{}')
            success = log_data.get('success', False)
            error_message = log_data.get('error_message', None)
            processing_time_ms = log_data.get('processing_time_ms', 0)
            
            # IPì™€ User-AgentëŠ” ì „ë‹¬ë°›ì€ ê°’ ìš°ì„ , ì—†ìœ¼ë©´ í˜„ì¬ ìš”ì²­ì—ì„œ ì¶”ì¶œ
            ip_address = log_data.get('ip_address', ip_address)
            user_agent = log_data.get('user_agent', user_agent)
            session_id = log_data.get('session_id', session_id)
            
            # param1, param2 ì¶”ê°€
            param1 = log_data.get('param1', None)
            param2 = log_data.get('param2', None)
            
            if self.db_type == 'mssql':
                log_query = """
                    INSERT INTO face_recognition_logs 
                    (mem_sno, confidence_score, similarity_score, quality_score,
                     glasses_detected, match_category, security_checks_passed,
                     success, error_message, ip_address, user_agent, session_id,
                     recognition_time, processing_time_ms, param1, param2)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, GETDATE(), ?, ?, ?)
                """
            else:
                log_query = """
                    INSERT INTO face_recognition_logs 
                    (mem_sno, confidence_score, similarity_score, quality_score,
                     glasses_detected, match_category, security_checks_passed,
                     success, error_message, ip_address, user_agent, session_id,
                     recognition_time, processing_time_ms, param1, param2)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, NOW(), %s, %s, %s)
                """
            log_params = (
                mem_sno,
                confidence_score,
                similarity_score,
                quality_score,
                1 if glasses_detected else 0,
                match_category,
                security_checks_passed,
                1 if success else 0,
                error_message,
                ip_address,
                user_agent,
                session_id,
                processing_time_ms,
                param1,
                param2
            )
            
            logger.info(f"[RECOG_LOG] ì¸ì‹ ë¡œê·¸ ì €ì¥ ì‹œì‘ - mem_sno: {mem_sno}, success: {success}")
            logger.info(f"[RECOG_LOG] SQL Query: {log_query}")
            logger.info(f"[RECOG_LOG] SQL Params: {log_params}")
            
            cursor.execute(log_query, log_params)
            connection.commit()
            
            logger.info(f"[RECOG_LOG] ì¸ì‹ ë¡œê·¸ ì €ì¥ ì„±ê³µ - ì˜í–¥ë°›ì€ í–‰: {cursor.rowcount}")
            
        except Exception as e:
            logger.error(f"[RECOG_LOG] ë¡œê·¸ ì €ì¥ ì˜¤ë¥˜: {e}")
            logger.error(f"[RECOG_LOG] Error Type: {type(e).__name__}")
            import traceback
            logger.error(f"[RECOG_LOG] Traceback: {traceback.format_exc()}")
            if connection:
                connection.rollback()
        finally:
            if cursor:
                cursor.close()
            if connection:
                connection.close()
    
    def run(self, host='0.0.0.0', port=5000, debug=False):
        """ì„œë²„ ì‹¤í–‰"""
        logger.info(f"ğŸš€ InsightFace API ì„œë²„ ì‹œì‘: http://{host}:{port}")
        
        # ë“±ë¡ëœ ë¼ìš°íŠ¸ ì¶œë ¥
        logger.info("ğŸ“ ë“±ë¡ëœ API ì—”ë“œí¬ì¸íŠ¸:")
        for rule in self.app.url_map.iter_rules():
            if 'face' in rule.rule:
                logger.info(f"  - {rule.rule} [{', '.join(rule.methods)}]")
        
        self.app.run(host=host, port=port, debug=debug)


# ë©”ì¸ ì‹¤í–‰
if __name__ == '__main__':
    # configì—ì„œ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    try:
        from config import Config
        HOST = Config.HOST
        PORT = Config.PORT
        DEBUG = Config.DEBUG
    except ImportError:
        # config.pyê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©
        HOST = '0.0.0.0'
        PORT = 5002
        DEBUG = True
    
    # ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    face_service = InsightFaceService()
    api = InsightFaceAPI(face_service)
    
    # ì„œë²„ ì‹¤í–‰
    logger.info(f"ì„œë²„ ì„¤ì • - HOST: {HOST}, PORT: {PORT}, DEBUG: {DEBUG}")
    api.run(host=HOST, port=PORT, debug=DEBUG)